[{"content":"Epiphany Most revelations seem trivial or obvious after the fact. This is one of those moments.\nFor a long time, mixing and mastering seemed like the same thing, or rather, too similar to be truly different things. It first hit me when I realized what automation (see previous post here) actually automates—the movement of someone\u0026rsquo;s hands as they used a mixer!\nMixing In the older days, mixing was done in realtime. Talk about pressure! Literally someone moved their fingers adjusting settings on a soundboard while playing back all the tracks. Similar to live sound in a way. This process reduces N tracks into 2 track stereo (typically).1\nSure, there may be channel EQ and compression settings during the mixing phase (like in live sound), but for the most part, the focus during mixing is on the relative volume of the tracks to each other.\nMastering Mastering, then, applies final EQ and compression to the stereo mix so that it provides an overall style/color and conforms to broadcast standards.2 There are so many different directions one can go in after the mix is done which is why mastering is its own phase.\nReferences I learned this from talking with an older recording engineer who recorded abroad. He brough his own mics but recorded and mixed tracks using other peoples\u0026rsquo; equipment on-site. He dubbed the stereo mix output to his portable recorder and took it back with him to master.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSlate\u0026rsquo;s new Virtu mastering engine has good documentation on common mastering styles. https://support.slatedigital.com/hc/en-us/articles/17554883409171-Audio-Settings\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2023-09-15T00:00:00Z","permalink":"http://localhost:1313/post/audio/2023/mixing-vs-mastering/","title":"Mixing vs. Mastering: The Music Production Lifecycle"},{"content":"TL;DR Command line magic to the rescue!\nffmpeg -i input0.wav -i input1.wav \\ -filter_complex \\ \u0026#34;[1] aeval = -val(0) | -val(1) [a]; \\ [0][a] amerge = inputs=2,pan=stereo|c0\u0026lt;c0+c2|c1\u0026lt;c1+c3 [b]\u0026#34; \\ -map \u0026#34;[b]\u0026#34; -c:a pcm_s16le output.wav Explanation Sometimes when working on mixes I forget what has changed between versions. I keep notes, but they can be subtle or hard to verify.\nThe above FFmpeg command1 outputs the differences between two files. It works on both WAV and AIF input files. I haven\u0026rsquo;t tried too many variations2, but it\u0026rsquo;s working for stereo 16-bit 44.1k and 48k files just fine.\nNote the command outputs the differences in BOTH input files to the output. For example if something was nudged over by 1 beat, you\u0026rsquo;ll hear the original start and the new one start 1 beat later over each other. It\u0026rsquo;s still helpful in drawing attention to what has changed though.\nReferences Thanks to Stack Exchange, upvote the OP if you can! https://video.stackexchange.com/questions/36396/can-ffmpeg-perform-audio-phase-subtraction/36398#36398?newreg=4755d58e081b4fd28871c887fd04a4c8\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMore output formats can be specified from this list https://trac.ffmpeg.org/wiki/audio%20types\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2023-09-04T00:00:00Z","permalink":"http://localhost:1313/post/audio/2023/subtracting-mixes-to-find-diffs/","title":"Subtracting Audio Files with FFmpeg"},{"content":"To Hack or not to Hack Here is how I toed the line between performance tuning a jailbroken gaming console and using it officially with Nintendo Online.\nFor context, after realizing how mucher smoother and quicker Overcooked runs on other consoles, I took it as a challenge to find a way to bring that same experience to my Switch—and not get banned.\nDocked Nintendo Switch running Overcooked at 720p 60 FPS\nTerminology Tegra = the NVIDIA chipset that Nintendo uses inside the Switch RCM = Recovery Mode CFW = Custom Firmware OFW = Original Firmware eMMC/sysNAND = the internal system memory (terms are loosely used interchangeably) emuMMC/emuNAND = emulated system memory (terms are loosley used interchangeably) This is written to an SD card, since SD card contents are never readable by Nintendo for privacy EMC = Embedded Memory Controller i.e. the RAM on the device MEM = another term for the RAM NX = the original codename for the Switch, first publicly mentioned in March 20151 HOS = Horizon OS, the internal name for the stock Nintendo firmware Erista/Mariko = codenames for the non-OLED Switch models. The original Erista can be soft-modded because of the Tegra exploit, but latter chipsets need a surrogate chip installed to re-enable the exploit.2 Objectives Overclock the CPU/GPU/Memory so that performance of various games is improved Continue to play online with friends/family Continue to use Nintendo Save Data Cloud Prevent the Switch from getting banned Prevent my Nintendo Online account from getting banned Imperatives These naturally follow from my objectives.\nImperative TL;DR The Switch will not be used for game piracy. This immediately lowers ban risk. Buy games. Game cheats/mods (when applied to certain games) can leave their trace behind in save files. When these are seen by Nintendo, they can causes bans.3 Do not use game cheats or mods. Install CFW to the internal sysNAND to play online. This ensures the device always contacts Nintendo\u0026rsquo;s servers with its original signature and serial number.4 Install CFW to the internal sysNAND to play online. Simply using the overclocking program sys-clk does not result in bans, even during online play.5 Overclocking is not a bannable activity. As long as your save game files are clean, Nintendo\u0026rsquo;s automatic save backup on the sysNAND is perfectly safe.6 Do not cheat and continue to use Nintendo Save Data Cloud. There are two types of bans: device bans and account bans. Unless you cheat online, at worst, only the device will be banned, but your Nintendo Online account will still be fine. Play fair, don\u0026rsquo;t be a jerk7, and don\u0026rsquo;t cheat online. Many guides online include the cheat module EdiZon-SE on the SD card. This will AUTOMATICALLY load games with cheats, unless you hold the R trigger when selecting a game. This seems easy to forget. Omit the cheat module from the SD card, and disable automatic loading of cheats in the /atmosphere/system_settings.ini file to be extra safe. 3 NAND backups (and even key backups) are not traceable by Nintendo and pose no ban risk. Backup! All guides emphasize the importance of creating an initial backup of the eMMC/sysNAND, but few discuss restoring from it. With time, the original backup will age and likely be on older firmware. If you suddenly need to restore the original backup and the firmware versions are different, it is a red flag and Nintendo will trigger a ban.8 9 Take regular, frequent backups of the internal eMMC/sysNAND in case the need to restore it ever arises. The Switch\u0026rsquo;s internal device logs are not wiped even during a factory reset. Understand that your internal logs will stay with you. It is kind of like the odometer when buying a used car: it provides continuity. Never wipe your internal logs, or you will get banned.10 Do not customize your Nintendo Switch home screen with custom apps or themes. It\u0026rsquo;s debated territory and carries undue risk. 6 11 Never add custom apps or themes to your home screen. If you overclock your RAM too much, it can get corrupted aka \u0026ldquo;binning\u0026rdquo; and then it kind of dies.12 See more on this later. Don\u0026rsquo;t worry too much, but find the balance overclocking games that need it. Design Hekate is the bootloader, and Atmosphère is the CFW. RCM is used to enter the bootloader, and the bootloder is used to launch the CFW. There are two ways to load Atmosphère from Hekate: (a) the \u0026ldquo;side-chain\u0026rdquo; approach using payload or (b) using Hekate\u0026rsquo;s launch configs using ff0.13 14 The latter is better because Hekate has specific flags to force sysNAND vs emuNAND whereas the side-chain approach can accidentally boot into sysNAND.4 Ever since Atmosphère 1.0.0, fusee-primary and fusee-secondary no longer exist. It was rewritten.15 When reading old guides, the files were renamed as follows: fusee-primary.bin -\u0026gt; fusee.bin and fusee-secondary.bin -\u0026gt; package3 Customized Playbook There are few chief resources out there, sometimes with contradictory instructions.\nhttps://switch.homebrew.guide (update 2024: now retired indefinitely) https://rentry.org/SwitchHackingIsEasy https://switch.hacks.guide/ Since my goals are slightly different than most online guides, the following is my own secret sauce.\nMac vs PC When writing to the SD card, the Mac can tend to leave extra files. It also can mess with the archive bit on files and folders, which can prevent Atmosphère to boot up at launch sometimes.16\nHowever, Hekate has an option under Tools \u0026gt; Arch bit • RCM • Touch • Partition \u0026gt; Fix Archive Bit to scan the whole SD card and fix the archive bit. I simply do this after copying stuff. For me this is a better compromise than using a program like Android File Transfer, which has its own quirks, or busting out a spare PC.17\nThere are also some safe eject scripts18 the community has made for Mac, but I haven\u0026rsquo;t needed to really use these.\nWhat to Download Like all tech stacks, getting the right versions to play together is important. Here is what I have tried and tested.\nNote: for Atmosphère, be sure to download fusee.bin as well as the .zip file!\nTool Purpose HOS 17.0.0 HOS 18.1.0 Hekate/Nyx Bootloader 6.0.7 6.2.1 Atmosphère OS 1.6.1-prerelease 1.7.1 nx-ovlloader Tesla Framework 1.0.7 1.0.7 Tesla-Menu Tesla Menu GUI 1.2.3 1.2.3 sys-clk Overclocking Framework 2.0.0-rc 2.0.0-rc Status Monitor (Overlay) Overclocking GUI 0.9.2 1.0.4 SaltyNX FPS Framework 0.7.0 0.8.1 ReverseNX-RT (Overlay) Toggle between 720p and 1080p at will 2.0.0 2.0.0 FPSLocker (Overlay) Force higher FPS 1.2.5 2.0.0 Last but not least, we need a way to flash the Hekate payload. My favorite does neither requires installing additional dependencies nor requires Gatekeeper exemptions. Instead I use the browser-based web-fusee-launcher, which requires nothing other than Chrome on MacOS.\nDownload my fork from https://github.com/NaanProphet/web-fusee-launcher, open index.html and enjoy!\nPreparing the SD Card Although Nintendo\u0026rsquo;s instructions19 recommend using the official SD Memory Card Formatter (Apple Silicon compatible!), this will likely format larger SD cards as exFAT. We will reformat the card as FAT32 later using Hekate itself (because it is for better performance and compatibility.20 21 22)\nFor now, just insert the SD card into the computer and copy files normally. To merge folders, holding Option while dragging and dropping.\nUnzip hekate*.zip and copy the bootloader folder to the root of the SD card. Unzip atmosphere-x.x.x-master.zip and copy the atmosphere folder, switch folder, and hbmenu.nro to the root of the SD card. Place the file named fusee.bin in your /bootloader/payloads/ folder. Merge the contents of nx-ovlloader.zip into the atmosphere folder Merge the contents of ovlmenu.zip into the switch folder (this will copy over the switch/.overlays/ folder) Unzip sys-clk-*.zip and merge the atmosphere, config and switch folders Unzip Status-Monitor-Overlay.zip and merge the config and switch folders Unzip SaltyNX-*.zip and merge the atmosphere folder. Copy over the SaltySD folder (new). Copy ReverseNX-RT-ovl.ovl into the switch/.overlays/ folder (you may need to show hidden files in Finder) Copy FPSLocker.ovl into the switch/.overlays/ folder (you may need to show hidden files in Finder) Copy Lockpick_RCM.bin into your /bootloader/payloads/ folder, if you want it. See the Lockpick section below for more info. Note: here we skip SigPatches, because we are not interesting in pirating games.\nBooting Into Hekate Factory reset the Switch by going to System Settings \u0026gt; System \u0026gt; Formatting Options \u0026gt; Restore Factory Settings After it reboots, set up the device like normal (connect to WiFi, Nintendo Account, etc.) Connect to the Nintendo eShop to make sure the console starts unbanned! Now DISABLE cloud save and Wi-Fi (as a safety precaution), and turn off the Switch. Enter the coveted RCM by first inserting your RCM Jig23. While holding the Volume Up button, press the Power button. The screen will stay black if successful. Use a USB-C cable to connect the device to your computer. Launch Chrome and open index.html from web-fusee-launcher. Send the initial test payload fusee-test.bin. Now boot into Hekate by flashing the actual payload hekate_ctcaer_6.0.3.bin (or similar name) Setup date/time using the touchscreen, woo! You will now have bootloader/hekate_ipl.ini and bootloader/nyx.ini files.\nStep 2.\nInsert the SD card into the Nintendo Switch Flash the hekate payload using web-fusee-launcher Formatting the SD card using Hekate automatically backs up the bootloader folder only. the switch and backups folder got wiped. Any other partition will be wiped!withDon\u0026rsquo;t BackupandOK. Press OK. Partition Manager: Your files will be backed up and restored! Any other partition will be wiped!`\nFinalizing the SD Card First off, we need to re-format the SD card using Hekate. Navigate to Tools \u0026gt; Partition SD Card.\nA dialog will popup either saying The SD Card files will be backed up automatically! or The SD Card cannot be backed up automatically!. It should be the former, because there is hardly anything on the SD card at this point, and the internal Switch 32 GB storage should have enough to temporarily backup/restore. Select OK.\nDrag the FAT32 slider all the way to the right. Select Next Step and then Start.\nThe re-format and restore should be successful! This will rename the SD card to SWITCH SD woo!\nNext, navigate to Tools \u0026gt; Backup and backup both eMMC BOOT0 \u0026amp; BOOT1 and eMMC RAW GPP (15 mins for the 32 GB model). Eject the SD card while Hekate is running. A popup will say SD card was removed! Nyx will reload after inserting it. That is fine. (Otherwise enter USB storage mode Tools \u0026gt; USB Tools \u0026gt; SD Card which is about 3x slower.)\nCopy the new backup folder\u0026rsquo;s contents from the SD card to a safe location (5 mins). Delete the backup folder from the SD card after, if desired.\nThe original /bootloader/hekate_ipl.ini should read as follows.\nOriginal\n[config] autoboot=0 autoboot_list=0 bootwait=3 backlight=100 noticker=0 autohosoff=0 autonogc=1 updater2p=0 bootprotect=0 Now add the following secret sauce at the bottom.\n[CFW (sysNAND)] payload=bootloader/payloads/fusee.bin emummc_force_disable=1 icon=bootloader/res/icon_payload.bmp [Stock] fss0=atmosphere/package3 stock=1 emummc_force_disable=1 icon=bootloader/res/icon_switch.bmp Note: we will be leave AutoRCM OFF. This is the default. This means if you reboot the Switch without the RCM Jig, it will go back to vanilla HOS. I find this helpful for when you want to still play/upgrade firmware (without overclocking).\nAlso: we skip exosphere and hosts blocking because our sysNAND needs to communicate with Nintendo\u0026rsquo;s servers to play online.\nPlace the SD card back into the Switch.\nLastly, go to Tools \u0026gt; Arch bit • RCM • Touch • Partition \u0026gt; Fix Archive Bit to sanity-check the SD card before booting.\nReturn to the home menu, select Launch and then boot into the CFW (sysNAND) entry\nRe-enable WiFi, and enjoy!\nTo enter the Tesla overlay menu, press L+DDOWN+RSTICK. To exit hold down L+DDOWN+RSTICK.\nResults It\u0026rsquo;s been really fun tweaking the clock speeds and seeing the FPS in realtime on various games! Surprisingly a lot of upper tier games are already at 60 FPS.\n| Title | Default | Tweaked | | \u0026ndash; | | \u0026ndash; | \u0026ndash; | | Overcooked | 30 FPS @ 1080p | 60 FPS @ 720p (this is an acceptable tradeoff for me) | | Prince of Persia: The Lost Crown | 60 FPS @ 1080p gameplay, 30 FPS @1080p cutscenes | | | Mario Kart | 60 FPS @ 1080p | | | Super Mario 3D World | 60 FPS @ 1080p | |\nKeeping Updated In order to use Nintendo Cloud Save, the Switch needs to have the latest official firmware. However, sometimes there is a lag before matching Hekate/Atmosphère versions are released. So I either wait until the matching CFW comes out — or just simply update and boot into the vanilla firmware, temporarily forsaking any overclocking.\nAlso note that if you have two Switch consoles, one vanilla and another with CFW, in order to use Nintendo Save Data Cloud, both have to be on the latest Nintendo version.\nLastly, remember again to use the merge feature in Finder when updating software on the SD card by holding Option while dragging and dropping.\nAppendix emuNAND Here are some additional notes on emuNAND that I learned while researching my build.\nIf an ADDITIONAL emuNAND partition is desired (for cheats/mods), it is crucial that Nintendo\u0026rsquo;s servers are blocked and never contacted on the emuNAND. Otherwise, when Nintendo sees the emulated signature and compares it to the stock signature (assuming the stock Switch has already gone online at least once), it will trigger a ban. ䷏ CFW on an external emuNAND must never, ever contact the internet. Never mix same gave files from your emuNAND and sysNAND, especially if there are mods/cheats in the emuNAND. This is largely uncharted and full of unnecessary risk. ䷏ Isolate the emuNAND as a completely separate entity with its own save files. KISS. Lockpick If you wish to play your own LEGALLY owned games via an emulator, you will need Lockpick to extract the private keys from the Switch. The keys change with each Horizon OS version, so it is good to extract them regularly.\nWhile still in USB mode, copy Lockpick_RCM.bin (into bootloader/payloads). Select Dump from SysNAND to extract the keys.\nNote that I didn\u0026rsquo;t get any title.keys written, similar to this post.24 It turns out those are only for digital games.\nSee these guides for download links and for more info:\nhttps://rentry.org/DumpingKeys https://github.com/Ryujinx/Ryujinx/wiki/Keys Safe Limits Here is the cheat sheet of official and max safe clock speeds from sys-clk manager. In summary, on a docked Erista, the CPU can be increased by 75%, GPU by 20%, and MEM by 20%.\nIt is possible to push the system too hard and cause the internal corruption. This is called memory binning. One Reddit post25 cautions against this:\nMy understanding is that unstable memory clocks can cause Horizon to corrupt itself. An annoyance at best with emuNAND, and a brick if you\u0026rsquo;re daft enough to do it on sysNAND. Caveat emptor.\nLucky for us, we ARE intentionally \u0026ldquo;daft enough\u0026rdquo; to install CFW on the sysNAND. 😛 However, sys-clk, by default, limits the available options only to the safe limits.\nReferences https://www.reddit.com/r/NintendoNX/comments/53zhc7/the_meaning_of_nintendo_nx/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nYou can check if your Switch is hackable by visiting https://ismyswitchpatched.com\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nChange dmnt_cheats_enabled_by_default = u8!0x1 to dmnt_cheats_enabled_by_default = u8!0x0 https://gbatemp.net/threads/edizon-cheats-are-always-active.535104/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWriting CFW to the internal memory by itself does not trigger a ban. https://www.reddit.com/r/SwitchPirates/comments/rqhjek/accidental_boot_in_cfw_on_sysnand/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThis is a circuitous thread, but the main mic drop regarding using sys-clk online is in this post https://gbatemp.net/threads/anyone-use-sysclk-for-online-gaming.607565/page-2#post-9769783\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.reddit.com/r/SwitchPirates/comments/119xzbz/question_about_turning_on_automatic_save_backup/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThese folks managed to cheating online with Pokemon, ruins it for everyone https://projectpokemon.org/home/forums/topic/63032-is-it-possible-to-transfer-your-save-file-from-a-non-hacked-switch-to-a-hacked-one-edit-it-and-then-put-it-back-to-my-non-hacked-switch-safely/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://gbatemp.net/threads/restored-emummc-backup-on-sysmmc-without-realizing.609984/page-2#post-9788164\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://gbatemp.net/threads/questions-about-nand-backups-restores-cfw-and-more-on-switch.564944/#post-9052343\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://gbatemp.net/threads/dirty-logs-on-the-switch-can-there-be-anything-done.538929/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://gbatemp.net/threads/questions-about-nand-backups-restores-cfw-and-more-on-switch.564944/#post-9052230\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.reddit.com/r/SwitchPirates/comments/13j75zs/if_your_struggling_with_totk_performance_then/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.reddit.com/r/SwitchPirates/comments/tb2r6c/comment/i057znj/?utm_source=share\u0026utm_medium=web2x\u0026context=3\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://github.com/CTCaer/hekate/blob/master/README.md#boot-entry-keyvalue-combinations\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://github.com/Atmosphere-NX/Atmosphere/releases/tag/1.0.0\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://gbatemp.net/threads/tesla-the-nintendo-switch-overlay-menu.557362/page-85#post-10176299 I finally figured it out! After digging around, I found out that the problem was due to macOS using \u0026ldquo;.\u0026rdquo; to make files invisible. So, the .overlays didn\u0026rsquo;t copy over as intended. This effected Atmosphere not being able to properly recognize the .overlays folder. The solution I came up with was to use Atmosphere\u0026rsquo;s USB File Transfer and create an .overlay folder using Android File Transfer. I then transferred the overlays (olvEdiZon.ovl, ovlmenu.ovl, and ovlSysmodules.ovl) into the newly created .overlays folder, rebooted Atmosphere, and everything worked as it should! Here is the link to the thread on GitHub that helped me figure out what was wrong: https://github.com/WerWolv/Tesla-Menu/issues/62 Thanks everyone for your patience and help! I hope this is helpful to any Mac users out there who have also run into this issue.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nIf you use Android File Transfer, remember to quit Dropbox first (crazy right26). Also keep in mind that Android File Transfer requires Intel/Rosetta, and FWIW the Apple Silicon variant openmtp on GitHub did not work for me.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSee the commands in these safe eject scripts: https://gist.github.com/idolpx/949f437f861b27e7d5812dc498429ad8 and https://gist.github.com/jepebe/5cb470e2686c09b6380615a8969ad9e6\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://en-americas-support.nintendo.com/app/answers/detail/a_id/220/kw/sd%20formatter\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nFrom the Hektate release notes FAQ: \u0026ldquo;It is also suggested to format your sd card via hekate. That\u0026rsquo;s because it prepares it for performance. something that many partitioning tools neglect.\u0026rdquo; https://github.com/CTCaer/hekate/releases\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026ldquo;The general idea is fat32 for 32GB or less, and exFAT for greater than 32GB. However, I\u0026rsquo;d recommend going fat32 for cards used in Switch regardless of capacity because Nintendo\u0026rsquo;s implementation of exfat is pretty bad and can possibly lead to corruption.\u0026rdquo; https://gamefaqs.gamespot.com/boards/189706-nintendo-switch/77705543\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nFrom 2023, \u0026ldquo;I had exfat for a while. then after a while it got corrupted. Been on fat32 ever since.\u0026rdquo; https://www.reddit.com/r/SwitchPirates/comments/13724wj/are_we_all_still_sticking_with_fat32_over_exfat/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nI bought a cute little RCM Jig but there are few options listed on the NH Switch Guide here https://nh-server.github.io/switch-guide/user_guide/emummc/entering_rcm/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://gbatemp.net/threads/just-make-a-backup-with-lockpickrcm-for-the-first-time-am-i-missing-something.555308/.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.reddit.com/r/SwitchPirates/comments/13j75zs/if_your_struggling_with_totk_performance_then/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.reddit.com/r/GooglePixel/comments/z3d4ok/pixel_7_could_not_connect_to_device_error_usb/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2023-07-01T00:00:00Z","permalink":"http://localhost:1313/post/tech/2023/overclocking-nintendo-switch/","title":"Overclocking the Nintendo Switch for Online Play"},{"content":"Why Upgrade Older iMacs can\u0026rsquo;t be upgraded to MacOS 10.14 Mojave (or higher) because the stock GPU it has doesn\u0026rsquo;t support Metal. The last, officially supported non-Metal MacOS for the 2011 iMac is 10.13 High Sierra.1 Time to go unofficial.\nApple Logic Pro X 10.52 requires Mojave, and at the time I was collaborating on some projects created in Logic 10.5. To use them on the iMac, I need to swap the GPU with one that supports Metal and then install Mojave unofficially.3\nSince I\u0026rsquo;m already performing computer surgery, I might as well upgrade the CPU as well. Music production can be particularly CPU intensive, especially when using software instruments or synths.4\nBut Why DIY The most straightforward route would have been to purchase a new machine that supported Mojave. However the DIY appealed to me for a few reasons:\nLess cost 💰 Less e-waste ♻️ Fun, new challenge (haven\u0026rsquo;t done something like this before) 🔧 Good trailblazing by the community 🤓 Sentimental 🖥️ Artistic 👨🏽‍🎨 iMac Specs Stock machine (full OEM specs listed on Everymac):\nMid 2011 27\u0026quot; iMac 12,2 A1312 EMC 2429 2.7 GHz Intel Quad Core i5-2500S with Turbo Boost 3.7 GHz AMD Radeon HD 6770M 512 MB In addition, some previous upgrades were:\n32 GB DDR3-1333 RAM Dual Drive (via extra SATA port5, still retains optical drive) 256 GB Samsung 840 PRO Series SATA III 6 Gbps 1 TB 7200 RPM WDC WD1001FALS-403AA0 SATA II 3 Gbps New Parts Both the CPU and GPU will be upgraded. The MacintoshMen upgrade guide is an excellent starting point for reviewing available CPU and GPU options.\nIntel Quad Core i7-2600 CPU ($80 eBay) Nvidia Quadro K610M 1024 MB ($22 eBay) Artic Silver Combo Kit for CPU/GPU dies ($15) K5 PRO Thermal Paste for GPU VRAM ($11) CPU Here is the original CPU the iMac came with.\n2.7 GHz Intel Quad Core i5-2500S with Turbo Boost 3.7 GHz (link) The new CPU I chose was offered in 2011 as an Apple-supported upgrade, making it a plug-in replacement.6 It uses the same Sandy Bridge architecture and the LGA 1155 socket as the original.\n3.4 GHz Intel Quad Core i7 (i7-2600) with Turbo Boost 3.8 GHz (link) It\u0026rsquo;s now known (since my initial research in 2019) that Sandy Bridge Xeon chips also work, so another option could have been the Xeon 1290.\n3.6 GHz Intel Xeon Quad Core E3-1290 with Turbo Boost 4.0 GHz (link) GPU The old GPU is from AMD and does not support Metal.\nAMD Radeon HD 6770M 512 MB The new GPU is from a used Dell/Alienware laptop.\nNvidia Quadro K610M 1024 MB (MXM-A form factor) Note: the K610M is the least powerful upgrade, but it is the most straightforward7 without requiring any heatsink8 or temperature sensor9 modifications. Since this machine will be used primarily for audio production (rather than video), a simple GPU card is OK.\nSourcing Finding a CPU on eBay was easy. On the other hand, the GPU was reported to be hit/miss.\nLuckily my K610M from eBay worked the first time!\nOutline Community support is chiefly found on two Mac Rumors pages: CPU Upgrade iMac Mid 201110 and 2011 iMac Graphics Card Upgrade11.\nSome of these steps (like upgrading to High Sierra) could be performed earlier, but here is what I did.\nOpen the iMac and get to the motherboard Physically install the new CPU Reboot, confirm it still works Upgrade to High Sierra and confirm latest Mac firmware is present Prepare GPU vBIOS USB boot drive Open the iMac again Physically install the new GPU that supports Metal Built-in screen no longer works 😱 Turn on the iMac and flash the new GPU vBIOS using another computer and SSH Built-in screen works again 🥳 but brightness control and sleep won\u0026rsquo;t work yet 😅 Use OpenCore12 to restore brightness control13 and sleep functionality Install Mojave unofficially, since the iMac now supports Metal 🥳 Steps I. CPU Install Follow steps 1-32 of the iFixit guide Installing iMac Intel 27\u0026quot; EMC 2429 Dual Drive Kit (HDD or SSD) Follow steps 43-end of the iFixit guide iMac Intel 21.5\u0026quot; EMC 2428 CPU Replacement (it\u0026rsquo;s the same for the 27\u0026quot;) Release the CPU and seat the new one. Clean and apply thermal paste to the CPU, consulting the Artic Silver guide for reference. The i7-2600 is 2nd generation and therefore needs a single vertical line. Pictures\nTaking the display off Removing the main circuit board. CPU pictured left, GPU pictured right. So long already-expired warranty Releasing the old CPU Installing the new CPU (thermal application not shown) Reboot success! (I was running Sierra at the time) II. High Sierra The new GPU will need OpenCore to restore native keyboard brightness control. OpenCore in turn requires the latest MacOS firmware, so first make sure the computer has it.14 Upgrade the iMac boot rom firmware to the latest version by installing High Sierra on an internal disk, including all recent Apple software updates. Confirm the firmware version is up to date using the Eclectic Light Company\u0026rsquo;s firmware lookup table.15 Open System Preferences and enable High Sierra for remote access, screen sharing and remote login (SSH) just in case after the GPU replacement the display remains black! III. Preparing the vBIOS vBIOS stands for video BIOS. Most of the aftermarket GPUs come from Dell/Alienware laptops, so they need to be re-flashed. Without this, the iMac boots to a nice, black screen.\nThere are a few options for flashing the new vBIOS, but the easiest, non-Windows way is via SSH and a USB flash drive.16\nNote: I did this back in June 2020, and since then there is an updated USB image (Mac_GPU_Flash.zip md5 7d9e19926da009f2565597542089360d) with different instructions.17 I followed Q3 in the old FAQ.\nDownload the file 2011_imac_usb.zip (md5 18e02e92844ebed8fc0fcf3ca039c754) for the USB image from here. There are strikethroughs to indicate deprecation, but the links still work. Download the K610M vBIOS from here to restore the display and show the boot picker18 Use Disk Utility to format the USB drive with GPT + FAT32. Copy the files to the new flash drive (no fancy flashing required). Lastly copy the vBIOS file onto there inside a folder. Eject the USB drive and keep this ready for later. IV. GPU Install A nice summary of the process is here https://forums.macrumors.com/threads/2011-imac-graphics-card-upgrade.1596614/page-596?post=29967927#post-29967927.\nFollow the CPU removal guide to get to the GPU. Apply the GPU thermal paste. The K610M has one die and four VRAM chips. Use the same thermal paste for the die as for the CPU (Artic Silver), but use the goopier thermal paste for the four VRAM chips (K5 PRO). GPU is same dimensions as the original so pop it back in. DO NOT fully put the computer back together yet (see next step). Pictures\nPreparing/cleaning the new GPU Applying all required thermal paste/compounds V. GPU vBIOS Flash Instructions for this section are stitched together partly from the OP16 but also from the new GMRL flash GitHub page.19\nThe iMac should still be half open. Disconnect any SATA hard drive cables on the iMac. This makes it easier to load from the USB! Connect the iMac ethernet port to your router—no wireless connections!! Plug the USB flash drive from Part III into the iMac. Turn the iMac on. The screen will be black, but it would have booted into the USB drive. Lookup the DHCP IP of the iMac by checking your router, etc. Find another computer/Mac and SSH into iMac. ssh root@YOURIP and password flash Find/change into the working directory cd /lib/live/mount/medium/flash (Optional) Backup the old vBIOS ./nvflash --save Backups/OldNVBios.rom Remove the guard rails ./nvflash --protectoff Write the new ROM to the vBIOS ./nvflash -6 NVIDIA/NewNVBIOS.rom (Optional) Verify it worked ./nvflash -6 NVIDIA/NewNVBIOS.rom Reboot and enjoy the monitor again! Note: after the vBIOS flash, the monitor will always be at full brightness until OpenCore kicks in. This means even after OpenCore patches are applied to the boot EFI, entering Recovery Mode or the like will have the iMac display at full brightness.\nPictures\nUsing another machine to initiate an SSH-based nvflash Flash success, ignore the warnings Internal screen works again! VI. Installing OpenCore via OCLP Next we install OpenCore via OpenCore Legacy Patcher (OCLP). From the WikiPost11:\nAfter installing OpenCore your system will be qualified to run the stock installer programs provided by Apple.\nOwners of NVIDIA/AMD cards with a working EFI Boot screen can install the EFI folder directly to the EFI partition of the internal disk (process described in the OCLP docs). Having an EFI Boot screen one can always boot without OpenCore just by pressing alt/option on boot and selecting a supported macOS version like High Sierra.\nPlease do not change any of default values (like SIP). You will only break the installation. The tool auto-detects hardware and will auto-configure the optimal OpenCore settings.\nHistory: Catalina Loader (CL) was another solution based on OpenCore to be installed on USB or SD devices and maintained more easily on visible file systems than on hidden EFI partitions. The solution was helpful in times without an EFI boot picker. Since we now fully support EFI boot with all AMD cards there is no need for this out of date solution.\nDownload OCLP on the iMac from https://dortania.github.io/OpenCore-Legacy-Patcher/ Open OpenCore-Patcher.app Click Settings and navigate to Advanced \u0026gt; Graphics Override. Select Nvidia Kepler to indicate the custom GPU installation. (This step may not be necessary, but I did it just to be safe.) Click Return to return to the main menu, and then select Build and Install OpenCore. This will write files to a temp folder in /var Select Install to disk to persist changes. Select the appropriate disk with MacOS. Select the single EFI partition, already present Reboot to take effect! Note the instruction to hold down the option key. Note: to change the boot picker options, rebuild changing the Show OpenCore Boot Picker setting. \u0026ldquo;Upgrading\u0026rdquo; from Catalina Loader to OCLP\nThe original instructions from a few years ago required a USB boot drive called Catalina Loader. This drive would always be plugged into the iMac. However, it\u0026rsquo;s really easy to cutover to OpenCore Legacy Patcher now: simply build, install, and remove the old USB! This is what I did in 2023.\nIt turned out sleep was broken afterwards, however, that was because I had to custom-install sleep extensions (intelsandybridgegraphics.zip md5 c8acb3e1e462e189d5f5383308bdc772) a few years ago. OCLP doesn\u0026rsquo;t like those, so I just deleted them.\nVII. Upgrading to Mojave Previous techniques required patching the MacOS installer using dosdude (what I did in 2020). However with OCLP, no customization is needed to the MacOS installer anymore!\nOpen OpenCore-Patcher.app again Select Create macOS Installer Boot from the new Flash drive and install MacOS Reopen OpenCore-Patcher.app and check for any available Post-Install Root Patches Final state! Tradeoffs The iMac has been very stable on Mojave. After a few years here is my summary of the quality of life.\nOnly one of the two Thunderbolt/MiniDisplay ports work to connect to another monitor. I don\u0026rsquo;t use an additional monitor so this doesn\u0026rsquo;t affect my workflow Brightness is full blast at the very beginning of the boot process (before OpenCore loads) and other places like Recovery Mode and Target Disk Mode This kind of bothers me (looking at you midnight hour) I would like to try this hardware mod13 to restore native brightness control everywhere someday Target Disk Mode works perfectly, though I don\u0026rsquo;t use it much Target Display Mode works for the most part. Luna Display is better With OCLP, unsupported combinations20 of MacOS are supported! For example a MBP running Catalina can use the iMac running Mojave as a monitor Exiting Target Display Mode is buggy. Have to unplug the cable to exit, and then the iMac screen goes black even though it\u0026rsquo;s still running.21 Have to use keyboard shortcuts to put the iMac to sleep and wake it back up to get the display on again. Instead, I find the Luna Display hardware dongle much more effective. It can use the same Thunderbolt cable (for low lag) and even allows you to use your iMac\u0026rsquo;s keyboard/trackpad to control the other computer! Footnotes OWC always maintains the best Mac compatibility matrix https://eshop.macsales.com/guides/Mac_OS_X_Compatibility\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026ldquo;Logic Pro X 10.5 is supported only on macOS 10.14.6 or later.\u0026rdquo; https://www.logicprohelp.com/forums/topic/130435-lpx-105-mac-compatibility/ And Logic Pro X 10.6 requires Mac OS 10.15. https://www.logicprohelp.com/forums/topic/137704-os-high-sierra-10136-and-logic-pro-x-105/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nOpenCore Legacy Patcher (OCLP) has come a long way to support non-Metal cards in later version of MacOS, but as of June 2023 it is still WIP. Also it doesn\u0026rsquo;t mention Mojave support necessarily. https://github.com/dortania/OpenCore-Legacy-Patcher/issues/108\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026ldquo;Software synths and plugin effects use up CPU. These don\u0026rsquo;t use much hard disk speed, but they require ridiculous amounts of calculations per second.\u0026rdquo; https://www.logicprohelp.com/forums/topic/79918-will-an-ssd-cure-the-system-overload-issue/?do=findComment\u0026comment=452195\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nCustom kit exploits an extra SATA port unused on the iMac logic board https://www.ifixit.com/products/imac-intel-21-5-mid-2011-dual-hard-drive-kit\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nAll DIY attempts to 3.4 GHz / 3.9 GHz i7-3770 Ivy Bridge CPUs have failed. https://forums.macrumors.com/threads/2011-imac-cpu-upgrade-possibilities.1225483/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nApparently, I should have checked and used either a 0.5mm or 1mm copper shim between the GPU and the heat sink. I can\u0026rsquo;t recall doing this, and as far as I can tell GPU temps are fine for my use. https://forums.macrumors.com/threads/2011-imac-graphics-card-upgrade.1596614/page-320?post=28696585#post-28696585\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nI do have a 2 pipe GPU heatsink, but we\u0026rsquo;re sticking with the MXM-A form factor! \u0026ldquo;If you have a 2 pipe heatsink that came with the lower end GPUs on these iMacs and want to use an MXM-B Card, you\u0026rsquo;ll have to buy a 3 pipe heatsink to cool cards properly. Using a (battery powered) Dremel with tungsten carbide grinding cutters work fast and give you smooth result. Do not try other cutters!\u0026rdquo; https://forums.macrumors.com/threads/2011-imac-graphics-card-upgrade.1596614\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026ldquo;Step 9. Now relocate the ODD temperature sensor and glue it on the sink (not needed with K610M and M4000). Finally install the GPU and sink back in your iMac!\u0026rdquo; https://forums.macrumors.com/threads/2011-imac-graphics-card-upgrade.1596614/page-596?post=29967927#post-29967927\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://forums.macrumors.com/threads/cpu-upgrade-imac-mid-2011.2230813/?post=28362520#post-28362520\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://forums.macrumors.com/threads/2011-imac-graphics-card-upgrade.1596614 Note: a lot has changed in the sticky post since June 2020, but the instructions I followed are still present here in the WikiPost History https://forums.macrumors.com/edit-history/3885949/view\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWhen I originally performed this upgrade in 2020, I used a USB boot drive called \u0026ldquo;Catalina Loader\u0026rdquo; to patch the iMac before booting into the OS. Since then, OpenCore Legacy Patcher (OCLP) is the new, fully-featured and incredibly simpler way to patch the boot EFI partition requiring no additional USB drives. https://dortania.github.io/OpenCore-Legacy-Patcher/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMac Rumors member Lottosmp has actually found a hardware route to restore native brightness control, without requiring OpenCore. This would restore it everywhere, including Recovery Mode, etc. https://forums.macrumors.com/threads/2011-imac-graphics-card-upgrade.1596614/page-261?post=28471675#post-28471675 https://github.com/thingsapart/imac-esp32-pwm-brightness https://medium.com/@fixingthings/imac-2009-2010-2011-gpu-upgrade-fixing-led-lcd-pwm-brightness-with-an-esp32-bc32da61a0e7\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nAnother reason to upgrade the iMac firmware, is because in May 2011 Apple unlocked 6Gb/s (SATA III) with the two external Thunderbolt ports!!! https://eshop.macsales.com/blog/10002-2011-imacs-no-sata-6gbs-yes-to-multiple-drives https://eshop.macsales.com/blog/10050-firmware-update-enables-6gbs-in-2011-imacs/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nFor the 12,2 iMac, the last firmware version is 87.0.0.0.0. https://eclecticlight.co/2018/10/31/which-efi-firmware-should-your-mac-be-using-version-3/ There is also a tool called SilentKnight that they offer which can check the firmware and a few other things. https://eclecticlight.co/lockrattler-systhist/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nGeekbench has some 2011 iMacs with i7-3930K and i7-3960X CPUs, but these are Hackintoshes that use different sockets (LGA 2011 vs LGA 1155). https://forums.macrumors.com/threads/imac-27-early-2011-insta-6-core-cpu.1352021/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n2021 vBIOS flashing guide https://forums.macrumors.com/threads/2011-imac-graphics-card-upgrade.1596614/page-545?post=29723850#post-29723850\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThe current version of the WikiPost11 does not list a BIOS for the K610M, but it was definitely needed!\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://github.com/Ausdauersportler/GRML-FLASH#nvidia-graphcis-card-flashing\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nApple only supports Target Display Mode for older machines https://support.apple.com/en-us/HT204592\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nI haven\u0026rsquo;t tried upgrading the K610m\u0026rsquo;s vBIOS yet to see if fixes the Target Display Mode unplugging problem.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2023-06-14T00:00:00Z","permalink":"http://localhost:1313/post/tech/2023/imac-2011-upgrade/","title":"Mid-2011 iMac Upgrade"},{"content":"TL;DR If you see error: failed to push some refs to 'https://dev.azure.com/...' use the following workaround and try again.\ngit config http.version HTTP/1.1\nLast tested with git version 2.32.0 and git-lfs version 2.13.3 on Mac OS X 10.14.6 Mojave.\nExplanation Azure Dev Repos is a wonderful place to version control Logic projects, because it has unlimited storage and support LFS.1\nA particularly large project (20 GB, largest file 225 MB) was failing to push to the server. I\u0026rsquo;ve seen two variations of this error: either an HTTP 413 or an HTTP 503 error while pushing a project. To add salt to the wound, it was happening in the final 1%.\n$ git push --set-upstream origin master Uploading LFS objects: 99% (678/686), 18 GB | 2.0 MB/s, done. Fatal error: Server error: https://username@dev.azure.com/my-logic-project/info/lfs/objects/1181a8d96cf25bb980a9d59130420a12d50a9b08905135217d7ac77fda10a14f from HTTP 503 Fatal error: Server error: https://username@dev.azure.com/my-logic-project/info/lfs/objects/73bcb141b8ec7287ede335c42cc1e4a668220aa55bd878c7e5a2c1d9f57fba42 from HTTP 503 LFS: Client error: https://username@dev.azure.com/my-logic-project/info/lfs/objects/a36859394739a5c5e076d21169373d2d5719a903e75630678697beb669a58a2d from HTTP 413 error: failed to push some refs to \u0026#39;https://dev.azure.com/my-logic-project\u0026#39; Apparently this is a known problem, specific to Azure Dev Repos only.2 The workaround is to downgrade the HTTP protocol used by Git so that the large files go through.\n$ git push --set-upstream origin master Uploading LFS objects: 100% (686/686), 20 GB | 2.6 MB/s, done. Enumerating objects: 805, done. Counting objects: 100% (805/805), done. Delta compression using up to 8 threads Compressing objects: 100% (794/794), done. Writing objects: 100% (803/803), 5.74 MiB | 1.82 MiB/s, done. Total 803 (delta 31), reused 0 (delta 0), pack-reused 0 remote: Analyzing objects... (803/803) (2601 ms) remote: Storing packfile... done (182 ms) remote: Storing index... done (40 ms) To https://dev.azure.com/my-logic-project 5d884b1..3b9e73d master -\u0026gt; master Branch \u0026#39;master\u0026#39; set up to track remote branch \u0026#39;master\u0026#39; from \u0026#39;origin\u0026#39;. $ I would recommend issuing the command without the -g flag, so that the http.version override is local to the git project only. If needed, revert changes using git config --unset http.version.\nReferences That\u0026rsquo;s why I made this: https://github.com/NaanProphet/git-logic-init\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nApparently a lot of Azure devs live with this workaround https://developercommunity.visualstudio.com/t/git-lfs-push-got-413-error/867488\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2023-05-14T00:00:00Z","permalink":"http://localhost:1313/post/audio/2023/git-lfs-with-azure-repos/","title":"Azure Git LFS failed to push refs Fix"},{"content":"I learned some hard lessons about hiring a videographer in 2022 for our wedding. A friend who\u0026rsquo;s getting married asked for advice. Here\u0026rsquo;s what I shared.\nCommunication is Key Our photographer pulled in his favorite videographer. The photographer was excellent so we extended a lot of trust.\nI initially called the videographer and inquired about his workflow before signing the contract. I saw his Vimeo page and the work he posted. I inquired about his recording techniques, the gear he uses, and so on.\nI distinctly remember asking if he would record and sync audio from the mixer during the wedding. He seemed to downplay the importance of it (\u0026ldquo;shotgun mic would be good enough\u0026rdquo;) and I deferred\u0026hellip;what a mistake that was! More on that later.\nAfter about ten minutes, he said he had to go and that I should route future details through the photographer. It seemed like he did not wish to be directly contacted. Overall we did not hit it off like two videographers connecting to each other.\nIn retrospect, I should have seen that the videographer didn\u0026rsquo;t understand what was important to me. Maybe he didn\u0026rsquo;t take me seriously. I knew I had qualms about moving forward, but I didn\u0026rsquo;t know how to go about it.\nCould I do it again, I would not have let what I knew I wanted be downplayed so easily. I also would have asked better questions such as:\nHow do they record in multicam and how do they sync the angles? Who are the people that will be filming? (Are they a tight knit team or more like a body shop?) Do they keep some cameras rolling the whole time? Will you be onsite? If not, what is your role? What other types of events have you filmed? If the answers were not satisfactory or it seemed like he was not really listening to my asks, I should have had the confidence to walk away and politely share that I\u0026rsquo;m looking for a higher standard.\nIn the end, they were largely going to do what they always do: a lather-rinse-repeat wedding job. It didn\u0026rsquo;t matter that we politely informed them (from the very beginning) I was a freelance videographer too or that I shared my site with him. I\u0026rsquo;m a \u0026ldquo;kid\u0026rdquo; getting married after all, and they\u0026rsquo;re the \u0026ldquo;experts.\u0026rdquo;\nMistake #1.\nHighlight Videos are not Everything I really wanted to delegate and find a professional. Trust others. Find good talent and pay for it. It\u0026rsquo;s your wedding after all.\nThe editing sucked. How else can I say it?\nFast, jarring pans Cuts between cameras that jump forward/backward in time Out of focus subjects Boomy audio not synced with the mixer A curious, pervasive fuzzy quality in the edited videos (more on that below) I sincerely do not believe the folks who edited the videos would have watched them if it were their own event. The job was perfunctory. They obviously claimed otherwise.\n\u0026ldquo;Can all these be better? Yes, absolutely. But is it horrible and not even worth watching? I disagree with that.\u0026rdquo;\nFrom this, I realized editing is inherently subjective and thus difficult to shape. This is especially true when the other person sees their many years of experience as a reason to remain rigid.\n\u0026ldquo;We\u0026rsquo;ve done hundreds of weddings, and we have not once received remarks like this. We understand everyone has different expectations,\u0026rdquo; BUT [insert statement that negates everything that came before the word BUT].\nIt was a way of invalidating my concern in a pseduo-democratic fashion, a tactful way to make you feel like you\u0026rsquo;re the one with the problem.\nAs a reader you may say, \u0026ldquo;Krishna, surely you reviewed their work before hiring them. Didn\u0026rsquo;t you know what you were getting into?\u0026rdquo;\nThat is the realization: I didn\u0026rsquo;t review all their work. I only reviewed what they shared\u0026hellip;the highlight videos posted on their Vimeo page. These looked good, and we also saw one of our previous friends hire them. However the highlight reels offered very little insight into how they record/sync footage for the ceremonies.\nWhen making highlight videos, you don’t sweat what you don’t record, only choose the best parts, and create something nice for 15 minutes. That\u0026rsquo;s entirely a different product from recording a two hour ceremony in multicam.\nIf there are multiple work products you are paying for, ask to review examples of all of them. If privacy is a concern (reasonable), ask if you can request permission from one or more of their recent clients.\nMistake #2.\nRaw Footage is Great, if it\u0026rsquo;s Recorded To some extent, I reluctantly anticipated the quality of the edited videos would be a gamble. Turned out it was, but I made peace with that.\nAs part of the contract, I had the foresight of requesting raw multicam footage of the events on a 2 TB hard drive provided by me. I specifically recall confirming that the space would be more than enough.\nCan you believe it? The cameras weren\u0026rsquo;t even recording the whole time during events. Like even when people are talking. I synced all the raw footage provided (PluralEyes ftw) and there are parts where only one camera is rolling. We paid for it, and we didn\u0026rsquo;t get it.\nWhat\u0026rsquo;s worse, sometimes the single camera went out of focus. I specifically cited an example where a camera goes in and out of focus eight times within 45 seconds, so I can\u0026rsquo;t edit around it. Was the cameraman learning on the job or something? An out of focus camera, with no secondary angle, is not acceptable.\nAgain, would this have been a problem if it were footage for a highlight video? Not at all. Just snip-snip, edit around it, and no one is the wiser. Sadly for me, there is no way to salvage those moments now.\nIt\u0026rsquo;s clear to me now that filming concerts gave me a completely different mindset for shooting in multicam. Every moment is precious. These people didn\u0026rsquo;t know or care how to shoot in multicam. What I didn\u0026rsquo;t realize at the time of talking to the videographer was that his downplay of recording audio from the mixer indicated a more serious lack of expertise in syncing multiple angles of video together! People tend to downplay what they don\u0026rsquo;t know/find important.\nAt one point they argued that it takes up a lot of space to keep the cameras rolling the whole time. Isn\u0026rsquo;t that what they\u0026rsquo;re paid for? They didn\u0026rsquo;t record audio from the mixer for the main wedding ceremony either, and that is peanuts in storage compared to video. The most rational explanation is that someone forgot—or thought they knew better.\nIf you request multicam, ask if they will keep the cameras rolling the whole time. Find out how much DELTA there is between what they always do vs. what you\u0026rsquo;re asking, because otherwise the person you hire may just wing it. If they downplay or minimize the ask, it might be because it cuts into their margin and they need to hire more people, or they don\u0026rsquo;t know how.\nMistake #3.\nTimespan of Project Files I also asked for the project files as part of the contract. We signed on it. Then afterwards\u0026hellip;\n\u0026ldquo;Sorry, the software we use creates really big project files. So we delete the project after every export to make edits faster and save space.\u0026rdquo;\nWhat? 😲\nYou mean to say you delete the project even before the client has received and approved the work? That\u0026rsquo;s dumbfounding. Then they patronized me with the most brilliant editing advice I have received.\n\u0026ldquo;I am sure you can easily load edited videos in Premiere Pro and replace any shots you want with raw files he provided.\u0026rdquo;\nWhat?? 😱\nTHAT gave me real insight into their editing process: if you ask for a change, they must re-ingest the H264 export (which is already compressed), chop it up, do whatever, then EXPORT and compress it again. No timecode, no real syncing. This is why somehow, mysteriously, the edited videos were not as crisp as the raw footage.\nMistake #4.\nContracts Can Break What do you do if you\u0026rsquo;ve trusted someone with your contract and they don\u0026rsquo;t fulfill it?\nNothing, really: it\u0026rsquo;s extremely disappointing to have asked for something, paid for it, and have it ignored.\n\u0026ldquo;You definitely held us at the highest standards, and I am extremely sorry that I couldn\u0026rsquo;t meet the expectations.\u0026rdquo;\nThis is another clever way of shifting the responsibility and making it about \u0026ldquo;me\u0026rdquo; and \u0026ldquo;my standards.\u0026rdquo; I think the lowest standard was they film and capture all the raw footage. They signed on it, and they didn\u0026rsquo;t do it.\nI always considered myself a passionate amateur until this point, but now I realize how wide the spread in \u0026ldquo;professional\u0026rdquo; really is.\nAnother friend told me the other day that she never even got her edited wedding videos, just the raw footage. It seems the norm for a lot of wedding professionals is to be paid in full on the day of the event, leaving no accountability. It might have been tricky, but respectfully negotiating different payment terms is something we should have done.\nMistake #5.\nMoving Forward I hope these reflections are useful to anyone who may be looking to hire a videographer on their own. I wish my future self advice my former self on what to look out for and what questions to ask.\nIt really hurts to be minimized and taken advantage of. It leaves impressions that remain etched for a long time. One of the most insightful commentaries of this is Dave Chappelle: Unforgiven | Exposing Comedy Central at 2:20 where he describes how a grown adult stole a joke from 15 year-old Dave Chappelle (warning language). I know it will be a continous practice to internalize and overcome this. I know it will make me a better person.\nFor now, I have what footage I have. I will be creative, work out of happiness, and make the best of it. Our wedding was magical, and I will make something magical to share to with those I love.\nUpdate: One Year Later It\u0026rsquo;s true that I have not yet re-edited the videos. Each time I tried to start, the negative feels were just too strong. That is slowly changing though.\nWhat I have observed about myself is that I have become more confident about my own abilities. Not in a way that puts others down, but in a way in which others cannot put me down so easily. I trust and value myself in a way now that I may not have been able to otherwise, and I share that value with others.\nThat\u0026rsquo;s a pretty nice wedding gift from the universe.\n","date":"2022-07-19T00:00:00Z","permalink":"http://localhost:1313/post/video/2022/videographers-guide-to-hiring-videographers/","title":"A Videographer's Guide to Hiring a Videographer"},{"content":"TL;DR Use Export for stems. If Bypass Effect Plug-ins is unchecked, it will use effects.\nExplanation There are tons of articles on this already, but I forgot the difference.\nThe use case is a Logic Pro X project with a bunch of tracks, and I want to export stems/submixes to Ableton so that we can perform them live.\nHere is the cheatsheet:\nUse Export \u0026gt; Tracks as Audio Files... ⌘E for an individual file/track Use Export \u0026gt; All Tracks as Audio Files... ⇧⌘E for a single file for a whole group of tracks Double check if any Volume Automation \u0026ldquo;mixing\u0026rdquo; is present in the track (press A to toggle the Automation view). Select Include Volume/Pan Automation if desired Double check the Range settings and use Export Cycle Range Only if desired Specify a custom prefix for stem filenames for good housekeeping ","date":"2021-07-23T00:00:00Z","permalink":"http://localhost:1313/post/audio/2021/bouncing-vs-exporting-to-ableton/","title":"Bouncing vs. Exporting From Logic to Ableton"},{"content":"There are a lot of guides out there, but I found this one especially helpful: https://productionadvice.co.uk/using-eq/.\nExcerpted below for convenience. Lot more helpful info at the link.\n50-60 Hz\nThump in a kick drum Boom in a bassline Too much and you’ll have flapping speakers and a flabby mix Too little, and the mix will never have enough weight or depth 100-200 Hz\nThis EQ band adds punch in a snare Gives richness or “bloom” to almost anything Too much makes things boomy or woolly Too little sounds thin and cold 200-500 Hz\nCrucial for warmth and weight in guitars, piano and vocals Too much makes things sound muddy or congested Too little makes them thin and weak 500-1000 Hz\nOne of the trickiest areas Gives body and tone to many instruments Too much sounds hollow, nasal or honky Too little sounds thin and harsh 2 kHz\nGives edge and bite to guitars and vocals Adds aggression and clarity Too much is painful! Too little will sound soft or muted 5-10 kHz\nAdds clarity, open-ness and life Important for the top end of drums, especially snare Too much sounds gritty or scratchy Too little will lack presence and energy 16 kHz\nCan add air, space or sparkle Almost too high to hear Too much will sound artificial, hyped or fizzy Too little will sound dull and stifled ","date":"2020-03-21T00:00:00Z","permalink":"http://localhost:1313/post/audio/2020/eq-cheat-sheet/","title":"EQ Cheat Sheet"},{"content":"Not sure how I didn\u0026rsquo;t know this before. Adjust track height with ⌥ (option) + up/down and timeline width with ⌥ + left/right.\nLot more helpful navigation shortcuts here: https://masteringinlogic.com/10-shortcuts-to-working-faster-in-logic-pro-x/\n","date":"2020-03-21T00:00:00Z","permalink":"http://localhost:1313/post/audio/2020/pinch-zoom-in-logic/","title":"Pinch Zoom in Logic Like a Pro"},{"content":"TL;DR Programming refers to managing dynamics and articulation on software instruments to make passages sound more authentic. Often these settings are scripted based on phrasing into JavaScript or Python scripts, hence the term.\nProfessional libraries like Cinematic Studio or Spitfire have incredibly vast degrees of freedom for adjusting nuance and articulation than starter libraries do. The Thanos Script is popular for adjusting articulation and delays for Cinematic Strings Logic X.\nShout out to my mentors Sanchit Malhotra and Samarth Srinivasan for dropping knowledge. 🎤\nCrash Course on Programming (with Cinematic Studio) Programming isn\u0026rsquo;t just about switching sample libraries. The big thing is fine tuning expression and dynamics with MIDI Control Change (CC) messages so that the passages actually sound better. Swapping libraries is like changing orchestras; programming a library is like rehearsing.\nTradeoffs of Sample Libraries Entry level libraries (like Logic X MIDI Strings or Native Instruments Session Strings Pro) don\u0026rsquo;t offer the same level of expressiveness. The samples recorded are not detailed enough to capture fine nuances of attack transients, color nonlinearites, etc.1 However, starter libraries do have an advantage when arranging/prototyping: they are smaller, take less RAM, and sometimes easier to work with punch out ideas.\nHave a listen of these two embedded factory demos to hear the difference yourself.\nNative Instruments Session Strings Pro\nhttps://www.native-instruments.com/fileadmin/ni_media/producer/kontaktsoundpack/SESSION_STRINGS_PRO/audio/02_City_Of_Lights.mp3\nCinematic Studio Strings New Dawn, by Alex Walbank\nhttps://cinematicstudioseries.com/wp-content/uploads/2020/01/alex-wallbank-new-dawn.mp3\nThe same of course applies for other instruments as well!\nProgramming as Orchestrating Programming can also involve orchestration—splitting a general \u0026ldquo;legato strings\u0026rdquo; into a different tracks for first chair, first violins, second violins, etc. The process is similar to taking a piano score and setting it for orchestra!\nRefining Sound via MIDI Most libraries respect certain CC values to mean certain things by convention.\nLong/legato patches CC1 = dynamics or dynamic layer. Also known as modulation or mod. The value of CC1 will choose the appropriate sample (and/or crossfade samples, depending on how many samples it has) for the dynamic level you want. Think sfzorando vs. piano vs. pizzacatto. CC11 = expression. Technically speaking, CC11 is a volume control that shapes the sample already chosen by the dynamic layer. It\u0026rsquo;s like a second-order dynamics shaper within the CC1 sample chosen. Also called phrase shaping. Short patches/articulations Controlled by MIDI velocity Typically you would broadly define the shape of a legato phrase with CC1 and micro changes with CC11.\nFor example if you\u0026rsquo;re at CC1 = 70 which is mezzoforte, CC11 values 0-127 will go from no volume up to mezzo forte. CC11 can be used for breaths between notes or rounding off each note, depends how detailed you want to get.\nLogic X MIDI Programming Techniques CC11 isn\u0026rsquo;t super necessary for CSS Split legato and staccatto passages on different tracks Match the velocity of stacatto to the CC1 modulation levels of legato if playing at the same time Copy CC1 levels to other tracks by copying the region and then deleting the notes after Merge modulation across tracks by selection regions and pressing J. Only works if there isn\u0026rsquo;t mod data in the other regions though. Scripting Changes with the Thanos Plugin Adjusting notes manually in Logic X via the Piano Roll looks something like this. Convenient for a passage here or there, but imagine this x15 and say hello to mental fatigue and carpal tunnel syndrome.\nOn the other hand, scripting changes looks like this. Obama says it all.\nhttps://www.youtube.com/watch?v=CBwcuBjVK4U\nMore on the Thanos plugin for Cinematic Studio Strings on the official forum page here.\nNegative Delays for Attack Transients As mentioned in the video, the Thanos script also adjusts the delay of the notes so that they speak on the beat they were quantized on. This was something I didn\u0026rsquo;t realize at first, until certain formerly snappy Session Strings passages started dragging (hence the discussion on tradeoffs above on how simpler libraries are easier to prototype with)!\nReading the CSS Manual:\nWhen a musician transitions from one note to another, there is a subtle timbral and dynamic shift as the players prepare for the new note. This effect can be heard while listening to a solo bassoon or a group of violins, and is a crucial factor in creating a realistic sounding performance with samples. CSS has been programmed to include these subtle swells before each new triggered legato note, and the end result is a smooth, expressive sound. In practical terms, this means there is a delay whenever you trigger a new legato note in any CSS instrument. The amount of delay is determined by the velocity at which you play each new legato note. There are three velocity zones: 0-64, 65-100, and 101-127, which correspond to three legato speeds respectively: slow, medium and fast, as pictured below.\nSlow has the most delay, approximately 1/3 of a second (333ms), medium is about 1/4s (250ms), and fast has a small delay - approximately 100ms.\u2029And for fast notes:\nPlease note that there is a short delay of 60ms from the beginning of the short note samples to their “rhythmic peak.” We left this in the samples intentionally as we believe this adds a significant degree of realism, and most importantly, it ensures that the timing across all short note types is consistent. So make sure you account for this when quantising short note tracks, either by applying a negative 60ms delay to the whole track, or moving the the notes back manually.\u2029References For a good read see this NY Times article To Save the Sound of a Stradivarius, a Whole City Must Keep Quiet\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2020-03-21T00:00:00Z","permalink":"http://localhost:1313/post/audio/2020/programming-midi-instruments-explained/","title":"Programming MIDI Instruments Explained"},{"content":"Recap The previous post detailed how Rclone can reliably upload large files with their checksums to Backblaze unlike other programs. This post will outline the workflow and some gotchas to keep in mind when doing massive data loads over the internet.\nWith trial and error, I was able to archive 8 TB of footage from my Synology NAS to Backblaze B2 in about a month.\nTo Keep in Mind First, the overall workflow.\nRemote to Remote is Possible Keep in mind Rsync supports copying between two remotes directly. The computer running Rclone will stream data in RAM as it shuttles data between the two.\nIn fact that\u0026rsquo;s what I mainly did: transferred assets from a personal B2 bucket to the organization\u0026rsquo;s new B2 bucket. Pretty neat!\nList Folders Syntax: lsd After setting up your remote with rclone config, use the list directory command lsd to double check your source/target folders.\nFor example, if the B2 remote name is called b2-remote1 then the command to list the root is:\nrclone lsd b2-remote1: Note the : at the end.\nIf a folder contains spaces, you use double quotes like this rather than backticks \\.\nrclone lsd b2-remote1:Videos/\u0026#34;Subfolder With Spaces/\u0026#34; Also use trailing forward slashes / instead of asterisks * to indicate the files inside.\nConsider copy instead of sync From the docs1:\nrclone copy - Copy files from source to dest, skipping already copied. rclone sync - Make source and dest identical, modifying destination only. Depending on your intention, copy may be better.\nExpect Errors and Verify Although Rclone automatically retries upload errors (by default up to 10 times) there are few reasons why files never get uploaded. See the appendix for various scenarios.\nTherfore, in a nutshell, always verify your transfer after (see below).\nBeware Quota Restrictions Unexpected EOF (end of file) errors can occur when streaming from a remote because of Backblaze quota restrictions.\n2018/08/09 16:53:44 DEBUG : CAM A/private/M4ROOT/CLIP/C0001.MP4: Cancelling large file upload due to error: unexpected EOF 2018/08/09 16:53:45 DEBUG : CAM A/private/M4ROOT/CLIP/C0001.MP4: Received error: unexpected EOF - low level retry 1/10 Double Check the Source Supports (and has) Checksums Since Backblaze only supports SHA-1 checksums, the Rclone docs indicate the source must also support SHA-1 checksums.2\nFor a large file to be uploaded with an SHA1 checksum, the source needs to support SHA1 checksums. The local disk supports SHA1 checksums so large file transfers from local disk will have an SHA1. See the overview for exactly which remotes support SHA1.\nSo B2 to B2 syncs should always populate checksums, right? Wrong. It will only if the source B2 bucket had checksums.\nAs detailed in the previous post, that means if the large files were copied with Rclone would they have checksums.\nRclone Browser is Great (but Deprecated) for Local \u0026lt;-\u0026gt; Remote Rclone Browser is a wrapper that the same config as the CLI. Rclone Browser does not support direct remote to remote syncs, but it is good for normal use. Unfortunately the program deprecated in favor of the WebGUI, but the latter doesn\u0026rsquo;t let you yet upload things. 🤷🏾‍♂️\nOn Mac, Rclone Browser can be installed with Homebrew via brew cask install rclone-browser\n⬆︎ Reliability by ⬆︎ Chunk Size (using ⬆︎ RAM) The default settings seem to be optimized for small files, like webpages.\nSingle part upload cutoff of 200 MB Chunk size of 96 MB Four concurrent transfers For whatever reason, the error rate with these defaults was higher than I expected (see below).\nInstead, I found better stability for large video files with:\nCutoff of 1G 1G \u0026lt;= chunk size \u0026lt;=4G Two concurrent transfers Note that all concurrent chunks are buffered into memory, so there is significantly more RAM usage with larger chunk sizes. Hence the downgrade to two transfers.\nMore specifics in the sync section below.\nMeasure Twice, Cut Once: dryrun Before discussing the sync command, it\u0026rsquo;s imperative mention the --dryrun flag for the following reasons.\nBackblaze bills by usage/throughput B2 doesn\u0026rsquo;t support renaming files after they are uploaded Therefore, when running rclone sync always use the --dryrun option first.\nThe sync command My goto sync (orcopy) command is:\nrclone sync \u0026lt;source\u0026gt; \u0026lt;dest\u0026gt; --exclude .DS_Store -vv --b2-upload-cutoff 1G --b2-chunk-size 1G --transfers 2\nExplanation of Flags --exclude .DS_Store to excluding Mac specific files -vv to enable DEBUG logging for visibility into chunk retries, etc. --b2-upload-cutoff files above this size will switch to a multipart chunked transfer --b2-chunk-size the size of the chunks, buffered in memory --transfers number of simulatenous transfers. b2-chunk-size x transfers must fit in RAM Phased Approach with --max-size Sometimes I found it helpful to transfer all files under a certain size limit first, say 1 GB, and then re-run the command for larger files.\nTo do so, add --max-size 1G to the rclone sync command.\nThe check command Always verify after a sync. Even if you think you don\u0026rsquo;t need to. The command is straightforward:\nrclone check \u0026lt;source\u0026gt; \u0026lt;dest\u0026gt; --exclude .DS_Store\nIf there are discrepancies the output will look like:\n2018/09/05 07:45:04 ERROR : CAM 2/AVF_INFO/AVIN0001.BNP: File not in Local file system at /Volumes/Scratch/ToB2 2018/09/05 07:45:04 ERROR : CAM 2/AVF_INFO/AVIN0001.INP: File not in Local file system at /Volumes/Scratch/ToB2 2018/09/05 07:45:04 ERROR : CAM 2/AVF_INFO/AVIN0001.INT: File not in Local file system at /Volumes/Scratch/ToB2 2018/09/05 07:45:04 ERROR : CAM 2/AVF_INFO/PRV00001.BIN: File not in Local file system at /Volumes/Scratch/ToB2 Use error output to create diff file By massaging the rclone check standard output into a new file with just the file names, it is possible to re-sync just these files. This saves us Backblaze read transactions on the files already copied.\nAssuming a file mydiff.txt:\nCAM 2/AVF_INFO/AVIN0001.BNP CAM 2/AVF_INFO/AVIN0001.INP CAM 2/AVF_INFO/AVIN0001.INT CAM 2/AVF_INFO/PRV00001.BIN the sync command is:\nrclone sync \u0026lt;source\u0026gt; \u0026lt;dest\u0026gt; --files-from mydiff.txt \u0026lt;other flags\u0026gt; Then, run rclone check again on all the files.\nThe cleanup command If your buckets are created with default settings, the file lifecyle is set to Keep all versions.\nTo purge deleted files, use a similar syntax to the lsd command.\nrclone lsd b2-remote1:Videos/\u0026#34;Subfolder With Spaces/\u0026#34; Also note that3:\nNote that cleanup will remove partially uploaded files from the bucket if they are more than a day old.\nAppendix Performance Logs The exact command I used at first was\nrclone sync b2-krish:Footage/\u0026#34;SD Card Archives/\u0026#34; b2-org:RawFiles/\u0026#34;Offloaded Video\u0026#34; -vv --exclude .DS_Store and it completed, roughly 3 days later with a 5% error rate.\n2018/08/12 19:46:55 INFO : Transferred: 1.674 TBytes (6.491 MBytes/s) Errors: 63 Checks: 2173 Transferred: 1123 Elapsed time: 75h6m1.4s Transferring: * CAM 1/PRIVATE/XDROOT/Clip/Clip0026.MXF: 99% /53.023G, 4.727M/s, 42s ... 2018/08/12 19:47:23 ERROR : Attempt 3/3 failed with 63 errors and: unexpected EOF 2018/08/12 19:47:23 Failed to sync: unexpected EOF $ Instead, by using a chunk size 1G and two max transfers (total 2G in RAM at a time) transfers were noticeably more stable.\n2018/09/01 22:40:13 INFO : Transferred: 52.430 GBytes (5.752 MBytes/s) Errors: 0 Checks: 232 Transferred: 776 Elapsed time: 2h35m33.8s 2018/09/01 22:40:13 DEBUG : 14 go routines active 2018/09/01 22:40:13 DEBUG : rclone: Version \u0026#34;v1.42\u0026#34; finishing with parameters [\u0026#34;rclone\u0026#34; \u0026#34;copy\u0026#34; \u0026#34;b2-org:RawFiles/Offloaded Video/\u0026#34; \u0026#34;b2-org:RawFiles/SD Cards/\u0026#34; \u0026#34;--exclude\u0026#34; \u0026#34;.DS_Store\u0026#34; \u0026#34;-vv\u0026#34; \u0026#34;--transfers\u0026#34; \u0026#34;2\u0026#34; \u0026#34;--b2-chunk-size\u0026#34; \u0026#34;1G\u0026#34; \u0026#34;--b2-upload-cutoff\u0026#34; \u0026#34;1G\u0026#34; \u0026#34;--max-size\u0026#34; \u0026#34;1G\u0026#34;] $ Upload cutoffs of \u0026ldquo;5G\u0026rdquo; During my experiments, I once tried a 5G single-part cutoff: --b2-chunk-size 2G --b2-upload-cutoff 5G --max-size 5G. The docs state This value should be set no larger than 4.657GiB (== 5GB) however it threw this error.\n2018/09/03 13:56:01 Failed to copy: File size too big: 5022908174 (400 bad_request) So apparently 5G is too high. 4G worked fine though.\n500 Internal Server Error Something is wrong with Backblaze, usually a transient problem. Rclone will retry, by default up to 10 times with built-in rate limiting (pacer) as shown with the incident a7691a3d7f71-e47fc872d7ba below.\n2018/08/09 16:53:12 DEBUG : CAM A/private/M4ROOT/CLIP/C0002.MP4: Error sending chunk 2 (retry=true): incident id a7691a3d7f71-e47fc872d7ba (500 internal_error): \u0026amp;api.Error{Status:500, Code:\u0026#34;internal_error\u0026#34;, Message:\u0026#34;incident id a7691a3d7f71-e47fc872d7ba\u0026#34;} 2018/08/09 16:53:12 DEBUG : CAM A/private/M4ROOT/CLIP/C0002.MP4: Clearing part upload URL because of error: incident id a7691a3d7f71-e47fc872d7ba (500 internal_error) 2018/08/09 16:53:12 DEBUG : pacer: Rate limited, increasing sleep to 20ms 2018/08/09 16:53:12 DEBUG : pacer: low level retry 1/10 (error incident id a7691a3d7f71-e47fc872d7ba (500 internal_error)) 2018/08/09 16:53:12 DEBUG : CAM A/private/M4ROOT/CLIP/C0002.MP4: Sending chunk 2 length 100663296 References https://rclone.org/docs/#subcommands\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://rclone.org/b2/#sha1-checksums\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://rclone.org/b2/#versions\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2020-03-18T00:00:00Z","permalink":"http://localhost:1313/post/video/2020/rclone-b2-pro-tips/","title":"Rclone Cloud Archival Pro Tips"},{"content":"Why Trim Sometimes it\u0026rsquo;s a live gig and I\u0026rsquo;m doing multiple things, like camera and sound. Throw in some stage delays and out of a 56 minute clip, half is not needed. On a Sony AX100 shooting at 1080p XAVCS 30fps, that\u0026rsquo;s 11 out of 22 GB extra.\nNow if space isn\u0026rsquo;t a concern then no need to read the rest of this.1 But in practice there are cases when this is a real use case for me.\nThe challenge of course is how to trim the file losslessly. Yes there\u0026rsquo;s Lossless Cut, FameRing SmartCutter, SimpleMovieX and other similar apps, but the reality is after trying these programs the MP4 container seems so vast and varied that prosumer formats aren\u0026rsquo;t properly supported by these third party tools.\nHello PlayMemories Sony actually makes a free app called PlayMemories Home. The UI is a little clunky, exports are single threaded, and I can\u0026rsquo;t choose the output directory of the destination file. However, at the end of the day, this is an application I can trust to trim files from the SD card—and do it well. No keyframe issues, no risk.\nSlow But Useful At the end of the day, using PlayMemories to trim footage is slow and thus challenging to fold into a normal ingest workflow. However, when occassion warrants its use, it will get the job done without error.\nFootnotes Of course, if you\u0026rsquo;re making a highlight reel then losing part of the performance doesn\u0026rsquo;t matter either.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2020-03-15T00:00:00Z","permalink":"http://localhost:1313/post/video/2020/lossless-trim-with-play-memories/","title":"Lossless Trimming of XAVC-S with PlayMemories"},{"content":"The Task Backblaze B2 is an incredibly cost-effective cloud-based archival platform. I had a few TBs of large file video footage stored on a Synology NAS that I wanted to archive to B2, in case anything happened to my local array.1\nSynology Cloud Sync Synology offers a built-in tool that syncs to many cloud providers, called Cloud Sync. In fact, it worked great and I created a bunch of jobs to archive nearly 8 TBs.\nCloud Sync even offers an Advanced consistency check option to compare checksums! All good right?\nHash me Not Although I had selected the checksum option I was surprised to realize not all files uploaded had their checksums written in B2. Only the small ones did.\nThat meant all the actual video files didn\u0026rsquo;t have checksums sent to B2. Yikes.\nDesign \u0026ldquo;Feature\u0026rdquo; Not knowing this limitation was my mistake, as I did not understand the Cloud Sync documentation2 thoroughly beforehand.\nWith Enable advanced consistency check ticked, Cloud Sync compares the hash (in addition to file size and last modified time) of each file between the public cloud and the NAS to enhance the integrity check of the sync results. This will require more time and system resources, and depends on the public clouds\u0026rsquo; support for advanced attributes. Please refer to the bottom of the page for more information.\nAnd what the bottom of the page say?\nHash values are not available for files uploaded to Backblaze B2 via b2_upload_part upload.\nb2_upload_part upload\u0026hellip; After consulting the B2 API documentation3, that command is used for uploading large files in segments. As you can see I had it set to 512 MB; the maximum is 4 GB.\nWhose Limitation is it Anyway? To be clear, the checksum limitation is on the Synology end. Cloud Sync is simply not sending SHA-1 checksums to Backblaze. B2 in fact supports and encourages4 sending checksums for large files— and they can even be sent at the end!\nSo what can upload to B2 with checksums for large files?\nRclone FTW Rclone is a command line workhorse for syncing files with cloud storage. It\u0026rsquo;s actively maintained, and writes and verifies checksums with B2 perfectly5. However, it\u0026rsquo;s only for folks not afraid of the terminal.\nInstalling rclone is super simple on the Synology.6\nLogin via SSH as an admin Run curl https://rclone.org/install.sh | sudo bash Verify it is installed with rclone -V and rclone -h Run rclone config , enter cloud credentials, etc. How to use the rclone sync and rclone verify commands are deatiled in Rclone B2 docs. Best practices of using rclone with using B2 coming soon.\nConclusion If you care about checksums for files over 4 GB, don\u0026rsquo;t use Synology Cloud Sync. Instead roll up your sleeves are get cracking with rclone on the Synology.\nHistory [This article was originally drafted in September 2018. At long last\u0026hellip;]\nFootnotes https://www.backblaze.com/blog/the-3-2-1-backup-strategy/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.synology.com/en-us/knowledgebase/DSM/help/CloudSync/cloudsync\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.backblaze.com/b2/docs/b2_upload_part.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://help.backblaze.com/hc/en-us/articles/218020298-Does-B2-require-a-SHA-1-hash-to-be-provided-with-an-upload-\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://rclone.org/overview/#features\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://bitbucket.org/fusebit/plex-and-google-drive/wiki/Install%20rclone%20on%20Synology%20NAS\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2020-03-15T00:00:00Z","permalink":"http://localhost:1313/post/video/2020/missing-checksums-with-synology-b2-cloud-sync/","title":"Missing Checksums in NAS Cloud Archives"},{"content":"Always Conform iPhone Footage for NLEs—even from FiLMiC I knew that normal iPhone videos are variable frame rate. Learned that the hard way, once when I was given a concert recorded on an iPhone to sync up to mastered audio. #superfail #ididntrecordthis\nBut I wondered if FiLMiC Pro footage was different? Nope, FiLMiC is also VBR.1\nNo Drop Frame Another thing I learned is FilMiC frame rates are non-drop frame. That is 24 really means \u0026ldquo;shoot approximately 24 frames per second.\u0026rdquo;\nIt\u0026rsquo;s interesting to note how minimum and maximum frame rates of the footage, as revealed by MediaInfo.\n\u0026ldquo;One Hop\u0026rdquo; in Compressor Interestingly, unlike Wirecast footage, I can successfully conform and modify the framerate for FiLMiC files in one pass with Compressor. The conversion is from H.264 (FiLMiC Extreme bitrate) to ProRes 422.\nTo do so:\nDrop the default ProRes preset of your choice Set the frame rate from Automatic (in this case 24) to the required drop frame 23.976. Import the transcoded file into NLE (Final Cut, etc.) Remember, Only Compressor Recall don\u0026rsquo;t use EditReady for this. EditReady isn\u0026rsquo;t designed for conforming since it intentionally just \u0026ldquo;adjusts the playback rate of your media.\u0026rdquo;\nCheers!\nReferences When you shoot video on iOS (including iPhone, iPad and iPod Touch), framerates don’t work the way they do on conventional camcorders, which use CFR (constant frame rate). That’s because iOS video recording uses VFR (variable frame rate) with only approximate targets, not exact framerates. This is true, whether you shoot on iOS with FiLMiC Pro or MoviePro. https://www.provideocoalition.com/filmic-pro-framerates-vfr-status-workflow-reaffirmed-at-nab-2019/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2020-03-14T00:00:00Z","permalink":"http://localhost:1313/post/video/2020/conforming-filmic-footage/","title":"Conforming FiLMiC Video for NLEs"},{"content":"Problem Sometimes, if I replace/relink an audio file during launch, the project seems to hang without loading.\nWhat is actually happening is there is another dialog prompt (for another missing file) but it is hidden behind the Finder prompt!\nWorkaround (Ratchet) Move the Finder dialog off to the side selecting a file with Open. That way, the dialog will appear in the usual place and you can still see it. Press Use to continue.\nIf you have multiple files that need relinking, be careful to move the dialogs away in a consistent manner—otherwise it may look like this!\nNotes This post was an extension of Replacing/Relinking Audio Files in Logic.\n","date":"2019-10-15T00:00:00Z","permalink":"http://localhost:1313/post/audio/2019/logic-prompt-hidden-behind-finder-window-workaround/","title":"Logic Prompt Hidden Behind Finder Window Workaround"},{"content":"TL;DR Do individually calibrated headphones from Sonarworks make a difference? Yea!\nStereo imaging is clearer Vocals are not over-pronounced Bass (especially in \u0026lt;= 200Hz range) is clearer/louder Is it worth the $149? IMO yes, especially because of how it cleans up the sound. (It is worth noting that not all headphones normalize with EQ calibration well, but the HD 650s do.)\nCalibration Curves Below is a comparison of the average calibration curve to the individually tailored one.\nThe corrections in the 10kHz range are particularly interesting!\nSonarworks\u0026rsquo; Average of all HD650s Calibrated Individually Calibrated L/R\nIndividually Calibrated L Only\nIndividually Calibrated R Only\n","date":"2019-10-14T00:00:00Z","permalink":"http://localhost:1313/post/audio/2019/sonarworks-headphones-calibration-audition/","title":"Individually Calibrated HD 650s"},{"content":"TL;DR Should I get one? Probably not for 300 Ohm headphones.\nAn Analysis of Impedance Below is a conversation I had with a friend who asked me if I used a DAC for my HD 650 mixing headphones.\nI do have a DAC (Apogee One) and was experimenting between using it and my MacBook/iMac\u0026rsquo;s output. Kinda can\u0026rsquo;t hear a differece yet in audio quality.\nThe output impedance (of the computer/audio jack) must always be lower than the consumer\u0026rsquo;s (headphone\u0026rsquo;s) impedance. This priciple also true in live sound: when plugging a mic into a mixer, the mic\u0026rsquo;s impedance must be lower than the mixer\u0026rsquo;s receiving impedance—otherwise you use a DI box.\nThe rule of thumb for this ratio is a factor of 8. Most consumer headphones have an impedance of 16-32 ohms, so the output impedance of the MBP\u0026rsquo;s/iMac\u0026rsquo;s jack is probably 2-4 ohms.\nIf the ratio is not safe—suppose the MBP jack had an output impedance of 10 ohms—then the frequency response will be altered in the headphones. This could lead to a different spatial response/altered EQ/etc. and depends on the actual headphone design.\nIn comparison, the HD 650 has a nominal impedance of 300 Ohms — so it\u0026rsquo;s ratio is 100x! Quite safe from distortion there.\nWhat you/I will notice is that for the same volume setting on the laptop, the volume will be sofer on the HD650s — because of the nearly 100x impedance ratio. It requires more power to drive it. But as long as it\u0026rsquo;s loud enough, I think you will be fine.\nHi end mixing headphones have high impedances for the same reason high quality guitar mics have high impedances — they have more coils in the wire, allowing for a better high frequency response. Having the high impedance also makes them conistent—no matter what they\u0026rsquo;re plugged into, they easily meet the rule of thumb of 8x, so the sound will be identical with no distortion.\nHeadphone amps work the other way: they basically create a near zero output impedance so that no matter what headphones you use, there will be no distortion.\nAdditional Reading http://nwavguy.blogspot.com/2011/02/headphone-amp-impedance.html http://nwavguy.blogspot.com/2011/02/gain-and-headphone-ampsdacs.html ","date":"2019-10-14T00:00:00Z","permalink":"http://localhost:1313/post/audio/2019/thoughts-on-headphone-amplifiers/","title":"Thoughts on Headphone Amplifiers - Should I Get One?"},{"content":"Problem Purchased a Waves bundle. Only want to install three plugins.\nSolution Don\u0026rsquo;t choose Easy Install Select Install Products Select All Waves Products and choose the plugins you want Navigate to Manage Licenses Activate your bundle\u0026rsquo;s license Screenshots ","date":"2019-09-30T00:00:00Z","permalink":"http://localhost:1313/post/audio/2019/install-select-plugins-from-waves-bundle/","title":"How to Install Individual Plugins from a of Waves Bundle"},{"content":"Problem I know this project is using a plugin, because it requires it when the project loads (Kontakt 5). However in the mixer I can\u0026rsquo;t find any Kontakt instruments!\nSolution The track using the plugin is probably hidden. Toggle All in the mixer console to see hidden tracks.\nAlternatively, unhide the tracks by pressing H or clicking the H button in the Main Window.\n","date":"2019-09-30T00:00:00Z","permalink":"http://localhost:1313/post/audio/2019/plugin-loaded-but-not-visible/","title":"Plugin not Visible in Logic Project"},{"content":"Problem Installed VerbSuite via a Slate Digital All-Access plan. Two errors show up when Logic scans the plugin in.\nI don\u0026rsquo;t have a Gobbler account, so I couldn\u0026rsquo;t follow the guide on Slate\u0026rsquo;s FAQ page How To Access the VerbSuite FG-224 Expansion Installers.\nSolution Contacted Slate support and they provided me with direct links for the VerbSuite Expansion installers in one business day.\n","date":"2019-09-30T00:00:00Z","permalink":"http://localhost:1313/post/audio/2019/missing-slate-plugins/","title":"Unable to Find Slate FG-224 and FG-224XL Plugins"},{"content":"Problem Sometimes Logic is very helpful when a missing Kontakt instrument is missing.\nOther times, it is not!\nHow to determine which instrument is missing?\nSolution Unfortunately, this seems to be because of third party instruments. You might have some luck with the approach described in How to Decode Shortened Plugin Names in Logic but otherwise ask the person whose project you\u0026rsquo;re opening.\nIn this case, it turned out to be instruments from the Cinematic Studio series.\n","date":"2019-09-30T00:00:00Z","permalink":"http://localhost:1313/post/audio/2019/missing-kontakt-instrument-name-explained/","title":"Unhelpful Missing Kontakt Instrument Message Explained"},{"content":"Problem Loading a project from a friend. Logic says it can\u0026rsquo;t find a plugin, but the plugin name is abbreviated! How to find out what it is?\nFor example is Supercharge Supercharger or Supercharger GT? Which version is Guitar Rig (note the space at the end)?\nSolution Open the bundled ProjectData file in a text editor and perform a case sensitive search. The file is technically an encrypted SQLite database, so it needs to be interpreted as ASCII. Many of the columns appear to be unencrypted making search possible.\nRight click the Logic project Select Show Package Contents Go into the Alternatives folder and find the corresponding version folder (000, 001, etc.) Copy the ProjectData file to your Desktop (to be safe) Open ProjectData from your Desktop in your favorite code editor (Atom, VSCode, etc.) TextEdit will work but may be slow I perfer a text editor over a hex editor because of the syntax highlighting Note: since this a hack, YMMV. For example iZotope Ozo turned out to be iZotope Ozone 7 Advanced, and I only determined that through manual trial and error by installing various trial versions.\nScreenshots Links https://www.logicprohelp.com/forum/viewtopic.php?t=126933 ","date":"2019-09-25T00:00:00Z","permalink":"http://localhost:1313/post/audio/2019/decode-logic-shortened-plugin-names/","title":"How to Decode Shortened Plugin Names in Logic"},{"content":"Problem The Melodyne 4 Trial defaults to the Polyphonic algorithm when loading a new file. Only noticed the artifacts after making a bunch of edits.\nNotice how it almost sounds like a chord (i.e. polyphony) at the end of each phrase.\nSolution Don\u0026rsquo;t use the Polyphonic algorithm for vocal editing. Use Melodic instead.\nNote: there is a setting in the menu bar so set the default algorithm, but it doesn\u0026rsquo;t seem to persist after quitting the application.\n","date":"2019-09-24T00:00:00Z","permalink":"http://localhost:1313/post/audio/2019/dont-melodyne-vocal-with-polyphonic/","title":"Don't Melodyne Vocals with Polyphonic"},{"content":"Not sure why something like this isn\u0026rsquo;t on Celemony\u0026rsquo;s site, but PluginFox has a nice comparison chart.\nhttps://pluginfox.co/pages/compare-melodyne-versions\n","date":"2019-09-24T00:00:00Z","permalink":"http://localhost:1313/post/audio/2019/melodyne-comparison-chart/","title":"Melodyne Comparison Chart"},{"content":"Observation This may sound really weird, but I find the built-in iMac speakers are nicer for adjusting pitch than mixing headphones. Some headphones smooth things out and make it harder to identify intonation issues.\nUsing speakers also helps prevent ear fatigue too—which is really important to me.\nMixing headphones are a must though for clinically reviewing the edits after. I only caught the issues documented in Don\u0026rsquo;t Melodyne Vocals with Polyphonic because of good mixing headphones (HD 650)!\nWorkflow Use speakers to Melodyne intonation Use a shruti box/tanpura app in the background for raaga-based music Optionally use a tone generator for reference.1 The tone generator\u0026rsquo;s sound is very similar to the Melodyne note preview (click and hold) Verify the exports afterwards using mixing headphones Links A customized 22 shruti Peterson Sweetener for Indian raagas \u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2019-09-24T00:00:00Z","permalink":"http://localhost:1313/post/audio/2019/melodyne-with-speakers/","title":"Try Melodyne Pitch First with Speakers"},{"content":"Problem This message keeps coming, even though the Battery 4 plugin and library is installed and I point it to the folder.\nSolution Turns out the dialog will appear for each plugin instance in the project.\nFirst make sure the libraries can be loaded.\nOpen the standalone Battery 4 app (in /Applications) Have it scan your library files (e.g. /Users/Shared/Battery 4 Factory Library) There\u0026rsquo;s now a bunch of kits visible. Close the application. Then select Apply to other Battery Instances first and use Point to Folder. It will automatically apply the same settings.\nOnce the project is saved, the settings will persist.\n","date":"2019-09-17T00:00:00Z","permalink":"http://localhost:1313/post/audio/2019/cannot-find-battery-libraries-over-and-over/","title":"Cannot Find Battery Libraries Over and Over"},{"content":"Problem ⌘Z doesn\u0026rsquo;t undo Mixer changes!\nSolution It\u0026rsquo;s disabled by default, although Logic is still recording everything in the background.\nClick \u0026ldquo;Include Mixer Undo Steps in Project Undo History” under the Mixer\u0026rsquo;s Edit menu.\nLinks https://support.apple.com/en-us/HT208438 ","date":"2019-09-16T00:00:00Z","permalink":"http://localhost:1313/post/audio/2019/include-mixer-to-undo-history/","title":"Include Mixer Changes to the Undo History"},{"content":"Use Cases Round tripping audio edits between workstations. Renaming the file helps with version control.\nMethod This is like \u0026ldquo;Relinking Files\u0026rdquo; in video editing.\nFind the original file in the Audio Files folder Zip it up Delete it Close the Project (because the file is already loaded in RAM) Reopen the Project A warning will appear saying the file is missing Select Locate Choose the new file A confirmation window will appear saying the file is changed Links https://www.logicprohelp.com/forum/viewtopic.php?t=71041 ","date":"2019-09-16T00:00:00Z","permalink":"http://localhost:1313/post/audio/2019/replace-audio-in-logic/","title":"Replacing/Relinking Audio Files in Logic"},{"content":"Shortlist Again this is for mixing only—not recording.\nIncrease Buffer Size Increase Process Buffer Range Remove Inputs to Audio Tracks (not from buses/submixes) Ensure a non Software-Instrument Track is selected Freeze Tracks (aka defeat). Move project to an SSD for max disk performance Links https://whylogicprorules.com/system-overloads/ ","date":"2019-09-16T00:00:00Z","permalink":"http://localhost:1313/post/audio/2019/system-overload-tips/","title":"System Overload Tips for Mixing"},{"content":"What It Is Automation in audio editing is like keyframes in video editing. It allows for parametrization of any effect you can think of — volume, panning, etc.\nOpen Automation Press a\nExpand the track if you don\u0026rsquo;t see the automation curve/data\nModes By hand - using the Pencil Tool to draw in your automation (works in any mode) By feel - Touch mode (falls back to existing curve once released) By feel - Latch mode (overwrites everything to the right once released) Links https://support.apple.com/kb/PH13171 https://support.apple.com/kb/PH13172 ","date":"2019-09-16T00:00:00Z","permalink":"http://localhost:1313/post/audio/2019/basic-daw-automation/","title":"Using Basic Automation in Logic X"},{"content":"TL;DR When you log into iLok Cloud on one machine, it automatically logs you out of the other machine.\nOpen iLok License Manager and Sign In Open Cloud Session (⌘⇧C) About iLok Cloud iLok Cloud is only supported by some plugins. For example Slate\u0026rsquo;s plugins do, but Anteres Auto Tune does not (yet).\nWith a Cloud session the iLok USB dongle is not necessary, but the machine needs to be continously connected to the internet, because it keeps polling every few minutes.\nYou can opt to use the USB dongle instead by selecting Close Cloud Session and then activating it to a physical iLok device instead.\nLinks https://slatedigital.zendesk.com/hc/en-us/articles/360009910054-Activate-and-Use-my-Plugins-with-iLok-Cloud ","date":"2019-09-15T00:00:00Z","permalink":"http://localhost:1313/post/audio/2019/ilok-cloud-basics/","title":"iLok Cloud Basics"},{"content":"Soundtoys 5 installs all plugin formats to the following locations. It has no customize option.\nAAX:\t/Library/Application Support/Avid/Audio/Plug-Ins/Soundtoys/ AU:\t/Library/Audio/Plug-Ins/Components/ VST:\t/Library/Audio/Plug-Ins/VST/Soundtoys/ Manually delete the AAX and VST versions using Finder after the install if you only need AU.\n","date":"2019-09-15T00:00:00Z","permalink":"http://localhost:1313/post/audio/2019/soundtoys-au-only-install/","title":"Soundtoys Remove Unneeded Formats"},{"content":"Problem Can\u0026rsquo;t turn on/off a plugin (another person\u0026rsquo;s project). The edit window also doesn\u0026rsquo;t appear.\nSolution The track is freezed. Unfreeze the track.\nLinks https://youtu.be/VP0A2g_hTx8?t=40 ","date":"2019-09-15T00:00:00Z","permalink":"http://localhost:1313/post/audio/2019/unable-to-edit-plugin-track/","title":"Unable to Turn Plugin On/Off in Logic ❄️"},{"content":"TL;DR When installing plugins for LogicPro X, only Audio Unit (AU) is needed.\nBreakdown Slate\u0026rsquo;s installer actually has awesome descriptions of various formats!\nAAX Pro Tools plugin format, Pro Tools 10 (32 bit) and later (64 bit) RTAS is for older Pro Tools AudioUnit is Apple\u0026rsquo;s plugin format, used in Logic, Studio One, Ableton Live and many more. This is what Audio Hijack uses as well. VST [aka VST2] is Steinberg\u0026rsquo;s plugin format, used in Cubase, Studio One, Ableton Live, Reaper and many more. The original GOAT. Can be 32 or 64 bit, depending on the plugin. VST3 is Steinberg\u0026rsquo;s new plugin format, used in Cubase, Studio One and Wavelab. Supported in Ableton Live 10 onwards. Links https://www.musicradar.com/tuition/tech/the-quick-guide-to-plugin-formats-and-compatibility-620406 ","date":"2019-09-14T00:00:00Z","permalink":"http://localhost:1313/post/audio/2019/which-plugin-type-for-logic/","title":"Which Plugin Format for Logic X"},{"content":"Updated Oct 14, 2019 with HD 650s.\nK701 vs Q701 K701 feels muddier than the Q701. Less clarity in low bass Q701 made the mix sound less boomy than I think it actually is Q701 pulls the vocals out, brighter than K701 Q701 appears to have slightly higher impedance (sounds softer for same volume setting) Kind of feel like I can\u0026rsquo;t trust either yet. Need to try another model.\nDT 990 PRO (250 Ohms) Bass not muddy! Definitely more powerful though, similar to what I remember in the car Easier to identify areas that need to be balanced This wins over both K701 and Q701 I kind of feel like these fatigue my ears slightly faster than the AKGs. The Q701s were easiest to listen to HD 600s Easier than the DT 990 PRO to identify where levels and EQ are not balanced!! Endrum Mix_v2 - Transition at 2:46 In contrast, the DT 990 PRO smooths this out! Want to keep this one 💙 HD 650s Not a HUGE jump between this and the 600s Feels nicer on my head than the 600s though Doesn\u0026rsquo;t tire my ears as fast as the 600s — important for long mixing sessions My friend described his HD 650 unboxing as:\nWhen I first put them on, I was actually somewhat unimpressed. I thought to myself, \u0026ldquo;Wow is this it?\u0026rdquo; But then I compared it to my HD 280s (noticed a little difference), put the 650s back on, and the difference was immediately apparent. It was a huge relief actually. Everything just sounds so natural and how it’s supposed to sound. I think that’s why I was initially unimpressed. Everything just sounds like it’s supposed to sound. No extra coloration or anything.\nIt\u0026rsquo;s worth noting that Sonarworks has an HD 650 review and uses the 650s themselves but an HD 600 review isn\u0026rsquo;t present.\nHD 650 definitely feels like the gold standard. 💙++\nEQ Curves Soundworks calibration curves for further insight.\n","date":"2019-09-13T00:00:00Z","permalink":"http://localhost:1313/post/audio/2019/mixing-headphones-audition/","title":"Mixing Headphones Audition"},{"content":"Problem I was surprised by this warning when I was opened a stereo project.\nTurns out an effect was using binaural panning. This means when using headphones, the listener will hear a simulated surround sound (after all you only have two ears for real surround sound too).\nInterestingly even with the setting disabled in Preferences, I can still hear the effect with headphones as I drag around the puck\u0026hellip;\nSolution I\u0026rsquo;m leaving it disabled since I don\u0026rsquo;t need all the actual surround features listed in Logic Pro X: Surround features overview. Hopefully that\u0026rsquo;ll also make Logic run faster.\nLinks https://www.logicprohelp.com/forum/viewtopic.php?t=123448 https://youtu.be/Xi332sZ4VCc ","date":"2019-09-12T00:00:00Z","permalink":"http://localhost:1313/post/audio/2019/enabling-surround-for-effects/","title":"An additional option is required. Enable Surround?"},{"content":"Realtime Proxy Editing via Wirecast I\u0026rsquo;ve recently been experimenting with realtime editing of live events. That way I can speed up turnaround times for multicam edits, especially for 2+ hour events like typical Indian classical dances and concerts.\nThe on location setup goes as follows:\nTwo cameras, each recording to SD cards Feed the HDMI output of both cameras into Wirecast on a MacBook Pro Assign Wirecast keyboard shortcuts to both cameras Record to Disk at 480p ProRes 422 to an external USB 3.0 hard drive Cut between two cameras using a wireless MIDI controller and Keyboard Maestro (pretty sweet) Then at home, the workflow goes like:\nUse DaVinci Resolve to detect the cuts and output an EDL (edit document list) with the timestamps1 2 Multicam sync the SD card footage along with the livestream MP4 Use the EDL to cut between the HD/4K footage, using the livestream angle for reference Conforming Variable Frame Rate Footage I was already anticipating conforming the livestream footage before pulling it into the timeline, since Wirecast uses variable frame rates.3\nWhat Wirecast does is adjust frame duration so timing remains constant.\nSo the first step is to conform the variable frame rate footage into fixed frame rate footage using Compressor. The ProRes to ProRes conversion is virtually lossless.\n30p vs 29.97p Wirecast\u0026rsquo;s default ProRes settings actually record to 30p. The Sony AX100s however record to 29.97p, our good ol\u0026rsquo; drop frame rate. This means for the same exact duration, the Wirecast file has less frames, which throws off frame precise edit lists.\nThe easiest way to solve this would have been to change Wirecast\u0026rsquo;s ProRes preset to actually record at 29.97 fps. However, now the footage I have also needs to change framerates from 30p to 29.97p.\nThe solution? Use Compressor again for a second ProRes to ProRes render, this time from fixed 30p file to fixed 29.97p.\nDouble Check Your Work Pro tip: check the 30p to 29.97p conforming worked correctly by ensuring:\nThe duration of the clips are the same (otherwise there will be audio sync issues). In my case both were 51 min and 53 sec (using regular QuickTime Player X to verify). The number of frames is different between the two files. The original 30p Wirecast file had 93387 frames and the conformed 29.97p version had less, as expected, 93294.4 Haste Makes Waste Couldn\u0026rsquo;t we just use Compressor once and conform the 30p variable fps footage to 29.97 fixed fps footage? The \u0026ldquo;two hop\u0026rdquo; process inevitably recompresses the video twice\u0026hellip;although, again it\u0026rsquo;s ProRes and virtually lossless. (Oh and it\u0026rsquo;s just reference angle, too.)\nUnfortunately, combining the two conforming steps doesn\u0026rsquo;t seem to work. The famous Failed: 3x crash service down error pops up within a few seconds. In fact my previous self tweeted about this error back in 2018, anticipating it would take me nearly a year to typing a proper writeup.\nDon\u0026rsquo;t Use EditReady for This EditReady has a framerate adjustment feature, but is not meant for the above use case. As the manual states, the feature intentionally only \u0026ldquo;adjusts the playback rate of your media.\u0026rdquo; That is, EditReady makes all the frames spaced out evenly, even if some were held longer than others. The feature is basically meant for slow motion, etc.5\nIn fact, if EditReady were used to adjust from 30p to 29.97p, it would stretch the video longer. The 29.97p file would have the same number of frames as the original 30p but the frames would now play back 0.1% slower. Indeed when I tried that, the file stretched to to 51 min and 56 sec.\nInterestingly, when both the 30p and 29.97p EditReady exports were pulled into FCP X they claim the original duration of 51 min and 53 sec in the browser.\nHowever, when added to a 29.97p multicam sequence with the other actual 29.97 footage, the incorrectly stretched 29.97 file shows up as 51 min and 56 sec!\nSo ya, save yourself the headache and conform with Compressor the first time.\nReferences Worthy mentioning this tweet about checking the timeline frame rate in DaVinci Project Settings first before starting scene detection. It can\u0026rsquo;t be changed afterwards.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nOn a side note, DaVinci doesn\u0026rsquo;t use semicolons for indicating 29.97 drop frame timecode. Fascinating and confusing both at the same time.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nForum post by Craig at Telestream. Frame rate instability and dropped frames when recording to disk (scroll all the way to the end) http://forum.telestream.net/forum/messageview.aspx?catid=45\u0026threadid=5468\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThe frame count can be calculated from the command line using ffprobe -v error -select_streams v:0 -show_entries stream=nb_frames -of default=nokey=1:noprint_wrappers=1 [VIDEO.MP4] CinePlay and other GUIs can display the frame count as well. Special thanks to: https://stackoverflow.com/questions/2017843/fetch-frame-count-with-ffmpeg\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nCompressor instead should actually redraw/retime the footage. See this support thread with Colin from Divergent Media for more info https://divergentmedia.zendesk.com/hc/en-us/community/posts/360033207774-Conforming-variable-frame-rate-footage-best-practice\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2019-07-05T00:00:00Z","permalink":"http://localhost:1313/post/video/2019/conforming-livestream-footage/","title":"Conforming Livestream Video for NLEs"},{"content":"Mac Photos Export Fail Maybe I\u0026rsquo;m too used to rewriting history in Git, but sometimes I modify the create date of my pictures and videos. Metadata.\nIn any case, by doing this when an album is sorted chronologically, everything appears in order. I like that idea of everything organized neatly by time a lot, because that way an album\u0026rsquo;s story flows well.\nThe trouble is, when these pictures and videos are exported from Photos, re-importing them doesn\u0026rsquo;t necessarily pickup the change. This is true even when roundtripping with another Mac Photos album, let alone something like Google Photos or Flickr! How bizzare is that?\nHere\u0026rsquo;s a picture of the pre-export album.\nHere\u0026rsquo;s a snap of the re-imported album, also sorted by Oldest First. Everything in red is not in the right place. The pictures are in their original pre-modification locations, and all videos have been shifted to current timestamp—year 2019!\nFor the record, I\u0026rsquo;m using Mac Photos version 3.0 and here are the settings used during export.\nSo what\u0026rsquo;s going on?\nExiftool Detective Work Using exiftool it appears the photos did have their adjusted timestamp written but not to all fields. Here\u0026rsquo;s the printout from the first misordered photo.\n$ exiftool IMG_3422.jpg | grep 201 File Modification Date/Time : 2019:06:30 07:09:07-04:00 File Access Date/Time : 2019:06:30 07:30:07-04:00 File Inode Change Date/Time : 2019:06:30 07:11:15-04:00 Modify Date : 2017:07:01 11:35:00 Date/Time Original : 2017:07:01 11:13:49 Create Date : 2017:07:01 11:13:49 Date Created : 2017:07:01 Digital Creation Date : 2017:07:01 Date/Time Created : 2017:07:01 11:13:49 Digital Creation Date/Time : 2017:07:01 11:13:49 Create Date : 2017:07:01 11:13:49.785 Date/Time Original : 2017:07:01 11:13:49.785 The tag Modify Date has our changes.\nAs for the videos, everything gets changed to the current timestamp except Content Create Date.\n$ exiftool IMG_3453.m4v | grep 201 File Modification Date/Time : 2019:06:30 07:10:49-04:00 File Access Date/Time : 2019:06:30 07:35:20-04:00 File Inode Change Date/Time : 2019:06:30 07:11:15-04:00 Create Date : 2019:06:30 11:10:47 Modify Date : 2019:06:30 11:10:48 Track Create Date : 2019:06:30 11:10:47 Track Modify Date : 2019:06:30 11:10:48 Media Create Date : 2019:06:30 11:10:47 Media Modify Date : 2019:06:30 11:10:48 Content Create Date : 2017:07:01 13:16:35-04:00 Maybe Content Create Date is it? Nope. Even if the year is changed on the same file and re-exported, the Content Create Date doesn\u0026rsquo;t change! (Also it looks like the tag isn\u0026rsquo;t present on videos not shot from an iPhone.)\n$ exiftool IMG_3453\\ \\(1\\).m4v | grep 201 File Modification Date/Time : 2019:06:30 07:37:00-04:00 File Access Date/Time : 2019:06:30 07:37:00-04:00 File Inode Change Date/Time : 2019:06:30 07:37:00-04:00 Create Date : 2019:06:30 11:36:59 Modify Date : 2019:06:30 11:37:00 Track Create Date : 2019:06:30 11:36:59 Track Modify Date : 2019:06:30 11:37:00 Media Create Date : 2019:06:30 11:36:59 Media Modify Date : 2019:06:30 11:37:00 Content Create Date : 2017:07:01 13:16:35-04:00 Repair Commands The remedy? Use Modify Date tag to rewrite the Date/Time Original for photos, first. 1\n$ exiftool \u0026#34;-exif:DateTimeOriginal\u0026lt;Modifydate\u0026#34; \u0026lt;pictures\u0026gt; For videos, unfortunately the script must be manual since the timestamp was lost during export. Note that video timestamps must be GMT2, so I\u0026rsquo;m adjusting four hours for EDT.\n# for videos all times must be GMT zero $ exiftool -AllDates=\u0026#39;2017:07:01 15:37:30\u0026#39; \u0026lt;video1\u0026gt; \\ \u0026amp; exiftool -AllDates=\u0026#39;2017:07:01 16:08:28\u0026#39; \u0026lt;video2\u0026gt; \\ \u0026amp; exiftool -AllDates=\u0026#39;2017:07:01 16:43:29\u0026#39; \u0026lt;video3\u0026gt; \\ ... There was one picture that was strangely troublesome even after this, probably an internal Photos library problem. For that guy I adjusted the time again in the new Photos album, exported it, ran the exiftool command again, and pulled it into the new album to fix it.\nConclusion In general when rewriting timestamps of an album, I try my best to not modify video timestamps. Instead, move the pictures around and then run the bulk command for photos since videos are a manual process.\nP.S. Oh by the way, if you\u0026rsquo;re curious what that Sound Isolation Booth was\u0026hellip; check out the published album here on Flickr.\nFootnotes Exiftool syntax modified from http://u88.n24.queensu.ca/exiftool/forum/index.php/topic,8349.msg42878.html#msg42878\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nForum post on Changing Time Zone for Video http://u88.n24.queensu.ca/exiftool/forum/index.php?topic=8081.0\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2019-06-30T00:00:00Z","permalink":"http://localhost:1313/post/video/2019/mac-photos-timestamps/","title":"Adjusting Date and Time on Mac Photos Exports"},{"content":"Intro Recently, I found myself deinterlacing footage from two Blu-ray discs using some Red Giant After Effects plugins1. The two compositions were HD 1080 59.94i files2, 51 minutes and 94 minutes each. My jaw dropped when I saw the estimated time for just the first file start at 50 hours, and keep increase. Plenty of CPU was still available on the machine\u0026hellip;\nThat got me searching for a way to multithread After Effects renders.\nHello RenderGarden RenderGarden by Mekajiki is a neat way to chunk and multithread renders from After Effects. It invokes aerender which is a headless way of running After Effects. It costs $99 and comes with a 7 day trial.\nIn my case I had two computers (the MacBook Pro and the iMac) with the project files accessible via a Synology NAS. I installed After Effects on both machines and procured a render-only license from Red Giant via email (less than one business day) to use the iMac as a headless render node.\nThings to Keep in Mind 🌼 RenderGarden\u0026rsquo;s getting started videos are quite helpful3 and got me up and running in less than an hour. Here is a summary of some things I additionally learned from experience.\nA seed is an atomic unit of work. The number of seeds a composition is broken up into is set when generating the script files from After Effects. It cannot be changed afterwards. Cancelled renders that are later re-seeded/restarted do not pickup from where they left off. The file segment is overwritten and starts over from the beginning (the log file is appended to though). Having the Recycle Bin feature on the Synology is helpful in the event of recovering accidentally deleted segments. If the Launch Gardener window doesn\u0026rsquo;t appear after launching the app, it is probably hidden behind other windows. Use Expose to reveal it, or click on the Python launcher in the dock. The Launch Gardener window has four types of Gardener nodes. The ae node type is for actually running After Effects aerender in the background. The ffmpeg node type is only used for post-processing conversion to H.264, etc. and the combine node is to combine segments together. This was slightly confusing at first because RenderGarden technically also uses FFmpeg to stitch movie segments together, as noted in the documentation. The notify node type is for some type of notification system, which I didn\u0026rsquo;t use. The folder that you select for the ae node is essentially the Gardener watch folder. It will continually scan it for work, and it can either be the parent RenderGarden folder or that of an individual composition. I find it good practice to only launch ae type nodes and wait for them all to complete before running combine nodes. That way I can inspect logs and file sizes and preview the segments for issues before combining them. For network machines only running Gardener nodes, licensing After Effects is usually not necessary. As long as the composition and render are not using proprietary codecs first like MPEG-2 or AC3 audio aerender will run on the network node and the Adobe login is only needed on the primary machine. Double check the full list of formats first on this Adobe blog post. Performance Benchmarks Since I was running renders on both the MacBook Pro (MBP) as well as the iMac, I was curious how the two would compare in terms of speed and CPU usuage. Both compositions (A and B) where seeded to eight segments.\nThe following table is sorted by End Time ascending. As you can see both the Quad Core iMac i5 and Quad Core MBP i7 have an ideal throughput of roughly 20 frames/minute.\nComp Seed Machine Frames Start Frames End Num Frames Elapsed Mins Frames/Min End Time Graceful End A 1 MBP 0 11508 11509 570 20.19122807 4/5/19 1:14 TRUE A 4 MBP 34528 46037 11510 831 13.85078219 4/5/19 5:35 TRUE A 5 MBP 46038 57546 11509 824 13.96723301 4/5/19 5:38 TRUE A 3 MBP 23019 34527 11509 833 13.81632653 4/5/19 5:39 TRUE A 2 MBP 11509 23018 11510 847 13.58913813 4/5/19 5:52 TRUE A 6 MBP 57547 69055 11509 798 14.42230576 4/5/19 14:37 TRUE A 8 MBP 80566 92074 11509 794 14.49496222 4/5/19 18:55 TRUE A 7 MBP 69056 80565 11510 817 14.08812729 4/5/19 19:17 TRUE B 3 iMac 42560 63839 21280 1024 20.78125 4/6/19 5:34 TRUE B 4 MBP 63840 85119 21280 1498 14.20560748 4/7/19 1:43 TRUE B 8 MBP 148960 170239 21280 1575 13.51111111 4/7/19 3:01 TRUE A 2 MBP 11509 23018 11510 610 18.86885246 4/8/19 22:13 TRUE B 2 MBP 21280 42559 21280 1087 19.57681693 4/9/19 4:43 FALSE B 1 MBP 0 21279 21280 1104 19.27536232 4/9/19 4:59 FALSE A 3 MBP 23019 34527 11509 565 20.3699115 4/9/19 7:39 FALSE A 1 MBP 0 11508 11509 644 17.87111801 4/9/19 21:09 TRUE B 7 iMac 127680 148959 21280 998 21.32264529 4/10/19 3:11 TRUE B 5 MBP 85120 106399 21280 1021 20.84231146 4/10/19 3:25 FALSE B 6 MBP 106400 127679 21280 1082 19.66728281 4/10/19 4:27 FALSE What are \u0026ldquo;Graceful\u0026rdquo; renders? Read on\u0026hellip;\nSome Idle CPU is Good I initially started with the RenderGarden recommendation of no more Gardeners than the number of physical cores4, which is a maximum of four on each machines.\nHowever I saw via iStat Menus that the MacBook Pro had still roughly 20% idle CPU, so I added an additional fifth node\u0026hellip;\nSure enough, the idle CPU was now less than 10%. However, as the table showed above, doing so dropped the throughput drops to 13 frames/minute, which even with five processes is 100 - (13*5)/(20*4) = 20 percent slower. I later went back to three-four nodes max, and the throughput stabilized to 20 frames/minute.\niMac i5 vs MacBook Pro i7 To my delight, the iMac\u0026rsquo;s older i5 processor was more than enough to keep pace with the MacBook Pro\u0026rsquo;s i7. With two render nodes, it happily hummed along with comparable CPU usage. The time per frame as you can see is also about the same (two to three seconds each).\nComplete specs of each machine are listed on the Gear page.\nAdobe Licensing User Error Shout out to the folks at Mekajiki who even reached out to Adobe to help root cause this issue. Now that\u0026rsquo;s customer support!\nThe log file for a successful ae segment render looks like the following.\nPROGRESS: 1;34;40;09 (21280): 0 Seconds\rPROGRESS: 1;34;40;09 (21280): 1 Seconds\rPROGRESS: 4/7/19 3:01:44 AM EDT: Finished composition \u001c00003 (30p)\u001d.\rPROGRESS: Total Time Elapsed: 26 Hr, 15 Min\raerender version 16.1x204\rPROGRESS: Launching After Effects...\rPROGRESS: ...After Effects successfully launched\rRENDER COMPLETE\r2019-04-07 09:03:01.130557\rRenderGarden end 2019-04-07 09:03:01 The un-graceful renders however would also complete with Finished composition, but nothing else would be written. The Terminal window would just stay there without writing Total Time Elapsed ... RENDER COMPLETE ... etc. On some rare occassions, the filename also didn\u0026rsquo;t rename from rendering_ to complete_.\nI started to see these strange popup windows on the MBP but didn\u0026rsquo;t know what they meant at first.\nIt took me a while to realize this was because I never verified my email with by Adobe! If you notice from the table before, the ungraceful completions were (1) only on the main MacBook Pro which needed to be licensed and (2) only occured towards the end, probably when the check was failing. Opening up the actual After Effects program displayed the following prompt.\nIn either case, the actual segement completed. If you encounter this situation, before issuing CTRL+C to \u0026ldquo;gracefully\u0026rdquo; exit RenderGarden Terminal window, check if the file needs to be renamed to complete_ first. Otherwise another free node may overwrite the actually completed segment.\nBasically, make sure you verify your email with Adobe first or you\u0026rsquo;ll be a newb like me.\nFinal Thoughts RenderGarden is amazing. If you\u0026rsquo;re planning to use After Effects for a long render, definitely check it out and procure render-only licenses for any plugins you\u0026rsquo;ll be using on the network.\nIf it\u0026rsquo;s your first time, I suggest manually verify/scrub segments for proper length and sync issues before running combine nodes.\nHappy gardening! 🌱\nFootnotes In particular, I used Red Giant\u0026rsquo;s Deinterlace plugin and the Deartificater plugin, the latter of which really increases render time.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nYes, interlaced H.264 is a thing. See https://en.wikipedia.org/wiki/Blu-ray#Video for the full list of supported rates. The footage was from a dance recital, and 1080p is only possible at 24 fps. The original authors probably captured it at the higher frame rate for smoother motion.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nQuick Start and Submitting a Render were the two main important videos I watched. https://www.mekajiki.com/rendergarden/tutorials/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nIs there a formula to decide the best ratio of CPU cores to Seeds and Gardeners? https://www.mekajiki.com/rendergarden/faq/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2019-04-10T00:00:00Z","permalink":"http://localhost:1313/post/video/2019/tips-for-using-rendergarden/","title":"Using RenderGarden to Multithread After Effects Exports"},{"content":"The Dream With over twenty years of Indian classical music concert footage, I\u0026rsquo;ve always dreamt of tagging each file by raga, tala, artist, audio quality, etc. to quickly pull up footage based on smart bins. Looking for Śivarañjanī? No problem. Dhrupad? Got that too. How about all files that need audio synced up? Coming right up.\nYup, the dream.\nA Guiding Principle Great words from a 2012 discussion about media managment on Creative Cow:\nThe more effort you put into a MAM (media asset manager), the more value it has to your organization—and the more dependent you become upon it. If you can\u0026rsquo;t move your metadata freely in and out of a product, you are tying yourself to it. The more data you put in, the more expensive and painful it becomes to transition.\nWe\u0026rsquo;re still in the early days of metadata for media, so I think these standards are only just beginning to emerge.\nIs there a solution worth investing in which still leaves one\u0026rsquo;s workflow open and flexible?\nTwo Metadata Philosophies There are two approaches when tagging footage: library-based managers that tag reference footage in a catalog vs. file browser-based solutions that write metadata next to the originals as text files.\nKyno, a file browser-based program, articulates this difference really well in their FAQ.1 With sidecar programs:\n\u0026hellip; there is not really a concept of \u0026ldquo;inside\u0026rdquo; or \u0026ldquo;outside\u0026rdquo;\u0026hellip; which also means there is no global search of all content\u0026hellip;\nPros/Cons Here are the pros/cons of the two approaches.\nLibrary-based management\nGlobal search of all content Tag/search metadata even when footage is offline Catalog cloud footage before upload Use the catalog to download just the files you want, to save on bandwidth costs File-based management\nDepends on files being present locally Metadata is easier to share/backup (plaintext files are compatible on all systems) Sidecar content can also be searched via regular file searches No concept of \u0026ldquo;global searches\u0026rdquo; because the application does not itself store metadata What\u0026rsquo;s right for me? In my mind, file-based management seems best suited for preparing an edit. It is perfect for working with local drives, NAS drives, and even tagging footage while it\u0026rsquo;s still on SD cards.\nAs a cloud storage user and road warrior, I however want to have the ability to find footage when it\u0026rsquo;s not on my local machine and present it to stakeholders. The ability to browse and tag footage that is offline/in the cloud makes library-based management exactly what I\u0026rsquo;m looking for.\nYour use case may vary, so the best programs of both types will still be considered below.\nTwo Kids on the Block Kyno (File-based) Kyno is a really beautiful metadata tagging program. It writes all its metadata to JSON files hidden in the same folder as the original asset. The UI is a refreshing change from Adobe Bridge, and is PC/Mac compatible.\nKyno is in active development and bundles many features that are helpful for preparing an edit like transcoding, batch timecode changes, and so on. In that sense, Kyno could be a formidable replacement replacement your current offloading workflow.\nKyno doesn\u0026rsquo;t lock its metadata inside itself offers FCP X and Premiere exports. The advanced version will also export to Excel, etc.\nKyno\u0026rsquo;s pricing starts at $159. There is no subscription, but after 1 year you have you pay for another year of software updates.\nKeyFlow Pro (Catalog-based) KeyFlow Pro blew me out of the water. It definitely seems like a more-mature sibling of Kyno, and is particularly Mac-centric supporting popular NLE exports.\nClean and modern interface, indicates active product development. It\u0026rsquo;s received a lot of critical acclaim too.2 3 4 Roundtrips with FCP X like a boss. Drag and drop from KeyFlow to FCP X and back. For the Adobe folks, it supports Premiere exports. It can open FCP X libraries directly too. Subtitle import with SRT Generate proxy footage so you can take low res version of video files on the road! KeyFlow Pro 2\u0026rsquo;s pricing model is really attractive at $50 on the Mac App Store. In-App Purchases for client/server collaboration more, but since I\u0026rsquo;m a single user I would simply park the library file on Dropbox and let it sync that way across my machines.\nConclusion KeyFlow Pro 2 is now part of my software team, and I can\u0026rsquo;t wait to use it more and more. It has a lot of features for the price, and I feel like I\u0026rsquo;m just beginning to scratch the surface of what it can do. Their documentation isn\u0026rsquo;t always super polished (grammatical mistakes/typos, for example) but that\u0026rsquo;s something I will live with.\nTime will tell if a file-based solution like Kyno will also find a place.\nAppendix Here are some first attempts reviewing various other metadata management programs, aka the \u0026ldquo;No Thanks List.\u0026rdquo;\nNLEs Sometimes, I\u0026rsquo;ve found people advocate using editing programs5 for their media management as well. I find this to be too limiting for a few reasons.\nFCP X, for example, has undergone many iterations since its original 64-bit debut, and the support for multiple libraries in 10.16 was a real game changer for organizing footage. Yet, FCP X isn\u0026rsquo;t ideal for media management.\nThe layout of FCP X seems optimized for editing, rather than cataloguing media. While the Organize workspace is nice (^⇧1) I still find there is a lot of wasted screen space. Also, as soon as the clip width is increased (to see/add markers, etc.) it becomes very difficult to see other clips!\nMetadata is difficult to export outside of FCP X.\nRisk of accidentally modifying old projects! Projects cannot be locked.\nThere\u0026rsquo;s only one window for all libraries. Since previously-open libraries reappear on launch, closing and reopening them to keep content relevant is a little tedious.\nDaVinci Resolve suffers from similar limitations.\nMetadata is locked within the program until export.7 8 9 Metadata is exported as CSV files. Relinking media does not recursively search in folders for matches, which makes moving footage between drives extremely difficult. Does not allow for manual relinking to renamed files (unlike FCP X). In short, I find NLEs best for organizing metadata when working on a specific deliverable, but not for providing a landscape of one\u0026rsquo;s total media assets.\nBulletProof (Catalog-based) BulletProof was once a shiny new app from Red Giant. Red Giant makes awesome software and plugins, and I\u0026rsquo;m a heavy user of their Shooter Suite.\nBulletProof however was only designed for offloading footage from cards and did not support linking to reference media. Terabytes of existing footage on network drives can\u0026rsquo;t really be copied somewhere else.\nIt also had some video playback issues and lacked the ability of relinking files in the catalog. Makes it difficult to move media to different folders/drives. No support for smart bins either.\nAs of June 8, 2015 (v12.7.0 of the Shooter Suite), the application is retired, [due to lack of public interest](https://www.redgiant.com/products/shooter-suite/downloads/ http://www.provideocoalition.com/fare-thee-well-red-giant-bulletproof). It basically seems like it was whittled down into Offload, which is still part of the Suite. RIP.\nAdobe Bridge (File-based) Adobe Bridge is a file browser with XMP metadata tagging capabilities. Bridge was really attractive financially, since it is completely free for life.10\nBridge fails for making destructive edits to MOV files by embedding XMP metadata inside the container, among other formats. See below how the checksum of the file changes after a tag is applied.\nWhile FCP X is unaffected by these embedded XMP changes, modification of the original asset throws a major wrench in any kind of NAS/cloud archival strategy. Any type of resync will unneccessarily rewrite GBs of data for a few KB of metadata.\nXMP sidecars are also difficult to import into FCP X, so Bridge stays within the Adobe ecosystem. Let\u0026rsquo;s find another program.\nAdobe Prelude (Catalog/File hybrid) Prelude is a particularly curious application. Like Adobe Bridge, its fatal flaw is that it writes XMP metadata inside MOV containers, and this cannot be changed.11 12 13 14 Also note the \u0026ldquo;Write XMP ID to Files On Import\u0026rdquo; option does not have any bearing on this behavior.15\nPrelude also has the concept of projects, so each project is like a catalog. However, the project itself doesn\u0026rsquo;t store any metadata—it needs to read the XMP inside/beside each file to do so! Thus, Prelude needs all files at loading.\nPrelude is essentially like a poor man\u0026rsquo;s Premiere with some metadata features built-in. So long, farewell.\nHedge (File-based) Hedge is a modern, media offloading application. Its polished UI is really beautiful.\nHedge has the ability to write MHL metadata files on export (inspired by Silverstack). It does not have a browser for viewing footage, however, it does come with a Spotlight plugin that will read the MHL plaintext files for searching metadata.\nHedge\u0026rsquo;s main limitation as a media manager is it only tags media it imports and cannot tag existing footage.\nSilverstack (Catalog-based) Silverstack by Pomfort is a swiss-army knife for media management and markets itself as that. It however fell short for a few reasons.\nSilverstack provides checksum-based card offloading, ProRes transcoding, and other features like audio syncing, report genreation, and so on. Like Kyno, it\u0026rsquo;s the combination of many programs put together.\nThe sheer number of formats Silverstack exports is mind boggling (see them in the GIF below). They definitely seem to be targeting professional broadcasting stations and major feature films. It\u0026rsquo;s really nice how the trial allows you to download a sample library with media assets pre-populated.\nSilverstack dropped the ball for me when it did not export its tags as FCP X keywords. The program exports metadata like camera and labels to FCP X, but not tags—hopefully yet.\nThat\u0026rsquo;s alright for me, since their yearly subscription starts at $399. 🤤\nTagSpaces (File-based) TagSpaces is an open-source, cross-platform tagging program. It\u0026rsquo;s not particularly meant for video, but for tagging any kind of file in general.\nThe UI is implemented in JavaScript and HTML5 and has special modes for previewing video and pictures. The metadata by default is appended to the filename, but the PRO version writes to sidecar files.\nTagSpaces could be a really interesting competitor to Kyno, granted it may take some work to get it setup. It fell off the list, however, since it currently has no means of exporting its metadata to FCP X or Premiere. Maybe someone will contribute that feature one day as an extension, though it seems unlikely.\nHistory [This article was originally drafted in January 2016. As you can see, it has been quite a quest\u0026hellip;]\nFootnotes Explanation of Kyno\u0026rsquo;s role as a media management system https://lesspain.software/kyno/pages/faq/is-kyno-a-media-asset-management-system\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeyFlow Pro 2 review, April 2018 https://visualsproducer.wordpress.com/2018/04/23/keyflow-pro-2/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSmall Workgroup Asset Management Using KeyFlow Pro, June 2017 https://www.provideocoalition.com/matt-geller-small-workgroup-asset-management-using-keyflow-pro/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nFirst Look: KeyFlow Pro v1.8 by Larry Jordan, June 2017 https://larryjordan.com/articles/first-look-keyflow-pro-v1-8/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nEdit Faster and More Efficiently with FCPX’s Metadata https://blog.frame.io/2018/01/31/fcpx-metadata/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHow to Use Libraries in Final Cut Pro X version 10.1 http://www.izzyvideo.com/final-cut-pro-x-libraries/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWrite Metadata [from DaVinci Resolve] back to files? https://forum.blackmagicdesign.com/viewtopic.php?f=21\u0026t=66127\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nExporting Metadata from Resolve to Premiere https://forum.blackmagicdesign.com/viewtopic.php?f=21\u0026t=50031\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMetadata Import/Export [with DaVinci Resolve] \u0026amp; XMP https://forum.blackmagicdesign.com/viewtopic.php?f=21\u0026t=59160\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nIt’s True: Adobe Bridge CC Is 100% Free for You to Download \u0026amp; Use https://prodesigntools.com/free-adobe-bridge-cc.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHelpful summary of which containers support embedded XMP metadata https://forums.adobe.com/message/7518406\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nOfficial XMP Specification Whitepaper from Adobe, lists each format and whether or not the codec writes to sidecar XMP files https://wwwimages2.adobe.com/content/dam/acom/en/devnet/xmp/pdfs/XMP%20SDK%20Release%20cc-2016-08/XMPSpecificationPart3.pdf\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026ldquo;For some formats such as QuickTime (.mov) the XMP information is written into the media file. For formats that don\u0026rsquo;t support writing to the media file, like MXF, the XMP is written into a sidecar file. The sidecar file is stored at the same location as the media file.\u0026rdquo; https://forums.adobe.com/thread/1074392?start=0\u0026tstart=0\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nAdobe forums Anyway to default saving prelude metadata outside the video file\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026ldquo;The Write XMP IDs To Files On Import preference only controls whether unique ID values are automatically written to files during import. This preference does not control whether XMP metadata is written to a file under other circumstances, such as when you edit metadata in the Metadata panel.\u0026rdquo; https://helpx.adobe.com/prelude/using/prelude-set-preferences.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2018-09-24T00:00:00Z","permalink":"http://localhost:1313/post/video/2018/quest-for-media-management/","title":"The Quest for Media Management"},{"content":"The Scenario Earlier this year, I was livestreaming a music concert where there was no access to the soundboard\u0026rsquo;s mic output. It was a low-key, unlisted stream for family and friends, but I still wanted a find a way to improve the audio quality rather than using the camera\u0026rsquo;s built-in mic.\nI had my Apogee ONE with me, and it has an excellent built-in omni condenser mic. I connected it via USB and it was detected successfully in Wirecast. The latency was negligible, and so the stream was setup to use the camera\u0026rsquo;s video (via the Blackmagic Mini Recorder) and the Apogee\u0026rsquo;s audio.\nThe only trouble was, since the Apogee ONE appears as a stereo input, the omni mic is only on the L channel and the R channel is blank. Viewers of the stream would only hear audio coming out of the left channel.\nLoopback and Audio Hijack Pro Using a combination of Rogue Amoeba\u0026rsquo;s Loopback and Audio Hijack Pro the Apogee ONE\u0026rsquo;s omni mic can be re-routed to a new virtual audio device for Wirecast.\nFirst, create a new virtual audio interface in Loopback. Next, create a new Session in Audio Hijack Pro. Select the Apogee One as the Input Device. Under the Advanced settings, choose Channel 1 for both the left and right channels. This will setup dual channel mono. Add a new Output Device directly to the right of the input device. It will automatically connect. Select the virtual audio device under Audio Device. Use Wirecast (or similar) to add the virtual audio device onto a new, active layer. It should be receiving audio on both the L and R channels. Mute the original camera audio on the other layer and start streaming. What About Soundflower? Loopback and Audio Hijack Pro cost $130 bundled, so the first question might be to try Soundflower instead since it\u0026rsquo;s free. Soundflower is powerful and has been around for a long time 1 and it\u0026rsquo;s definitely worth a try.\nPersonally, I have found Soundflower\u0026rsquo;s interface less-intuitive than Audio Hijack\u0026rsquo;s. I was in a pinch to setup the livestream—a live show that was behind schedule—and was so grateful for the UX of Loopback and Audio Hijack to just work, and work perfectly. Worth every dollar.\nReferences History of Soundflower https://rogueamoeba.com/freebies/soundflower/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2018-09-17T00:00:00Z","permalink":"http://localhost:1313/post/video/2018/rerouting-an-apogee-one-with-loopback/","title":"Using an Apogee ONE for Livestream Audio"},{"content":"Upconverting 480p Footage This May, I tried something new and recorded a HD Wirecast livestream to disk as ProRes 422 @ 480p to help save on disk space/throughput.\nAll of the other raw, camera footage was in 1080p and I wondered if there was some way to \u0026ldquo;upconvert\u0026rdquo; the low res footage. (I especially needed to do so because some of the raw camera files got corrupted, and the livestream was the only way to salvage that angle.)\nInstant 4K Plugin and After Effects Despite the name, the Instant 4K plugin is more like \u0026ldquo;Up to 4K.\u0026rdquo; The plugin is part of the Red Giant Shooter Suite bundle and comes with support for Adobe Premiere and Adobe After Effects. From what I understand, the plugin uses some advanced interpolation algorithms to redraw each frame of the video as it expands it.\nI used Adobe After Effects CC 2018 and rendered out to ProRes 422.\nA/B Video Comparison \u0026ldquo;Seeing is believing.\u0026rdquo; Here\u0026rsquo;s a before/after test with the original 480 footage\nStill Frames Both files were opened in QuickTime Player X, and the 480p window was stretched to the same size as the 1080p window.1 Below is a looping slideshow of the before/after still frames (image cropped to make it easier to see).2\nNotice the difference in the clarity (text at top, violin bow) and richness of color (red blouse). This is even with the inherent compression in the screenshot.\nRunning Video If you have a 1920x1080 display, here\u0026rsquo;s a video clip also.\nBoth files were played in QT X at the same time via ⌘+Enter and are toggled back and forth with ⌘+` (filename changes at the top) during playback. The screen capture was exported as ProRes 4444 (from Camtasia 2) and compressed to H.264 by EditReady using default settings (visually lossless). The eight second clip is 24 MB.\nThere\u0026rsquo;s definitely some compression in the H.264 render (for example in the color red), but even then there\u0026rsquo;s a noticable difference in the clarity in the Instant 4K version. The greatest quality loss is likely in the screen capture (rather than Edit Ready), but it\u0026rsquo;s still a useful test. Real-world delivery formats will be compressed, after all!\nNote: if you\u0026rsquo;re hard to impress, you\u0026rsquo;ll definitely be underwhelmed when viewing this video at smaller screen resolutions. Be sure your display resolution \u0026gt; 1080p and use the HTML viewer to maximize it fullscreen.\nYour browser does not support the video tag. There\u0026rsquo;s nothing like looking at the original uncompressed footage though, so feel free to download the raw ProRes 422 videos to do your own comparison (190 MB).\nPlugin Workflow and Screenshots Drag and drop the footage into After Effects. Right-click a video file and create a new composition from it. Right-click the composition and select Composition Settings. Change the Preset to the target resolution (e.g. HDTV 1080 29.97 with Square Pixels). The source video should now be smaller than the canvas size. Use the Effects \u0026amp; Presets dropdown to find the **Red Giant Shooter Suite ** section. Drag and drop the Instant 4K plugin into the composition\u0026rsquo;s viewer to apply. It should automatically resize to the canvas size! Adjust the plugin settings as desired. I personally use Filter Type Best, Sharpness 6, Quality 10, and Anti-aliasing 3, based on Red Giant\u0026rsquo;s Getting Started with Instant 4K video3. Select the composition and choose Composition \u0026gt; Add to Render Queue from the menubar. Use Render Settings \u0026gt; Best Settings using the small drop down. Create a new Output Module to export to ProRes 422. For reference, the 17 second video clip earlier took 3 minutes and 43 seconds to export on the 2011 iMac with 12 GB of RAM. That is, 13x!\nRAM Requirements Resizing ProRes footage apparently can\u0026rsquo;t be done on all machines. Here\u0026rsquo;s why.\nAre You Hongry for RAM? Little did I know how incredibly RAM-intensive resizing footage is. This problem was particularly intensified by the sheer length of the video files: some were nearly 2 hours x 1 GB/min = 120 GB (classical music concert footage).\nThe 2011 MBP actually ran out of RAM. Like kaput. I tried a few things like increasing After Effect\u0026rsquo;s memory allocation, etc. but it was all essentially the same. Anything larger than 30 minutes would crash. Queuing up multiple renders wouldn\u0026rsquo;t work, because the program would need to be restarted before each one. The laptop was already maxxed out with 8 GB RAM.\nThis is when I remembered that nice desktop in the basement.\nReturn of the iMac Unlike the MBP, the iMac has four RAM slots. Both machines had 8 GB total at the start, but the iMac impressively cranked out the footage. It would seem that somehow this older iMac is just more stable, perhaps by virtue of it being a desktop.\nEventually the iMac also started freezing up for the larger files. However after upgrading the machine to 12 GB—two 2 GB chips and two 4 GB chips—it was invincible.\nObservations on RAM Pressure One thing I noticed was even after a render is complete, After Effects typically still holds onto the RAM. Some of it can be purged by manually by selecting Edit \u0026gt; Purge \u0026gt; All Memory \u0026amp; Disk Cache\u0026hellip; but it\u0026rsquo;s my observation that the RAM is only released completely after closing the program. Exiting the program usually takes a while too, sometimes of upwards of 2 minutes as it slowly siphons the RAM back.\nOn the iMac with 12 GB RAM however, I had no trouble queueing up multiple renders.\nHistory [Updated Sep. 16, 2018 with detailed After Effects walkthrough.]\n[Updated Sep. 26, 2018 with fast-loading ProRes 422 picture and video samples.]\nFootnotes The 853x480 file could only be resized to 1920x1079 in QuickTime Player X because of roundoff error. Hence the slight 1 pixel height difference when cycling between the two files.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThis slideshow is not a GIF. It\u0026rsquo;s rendered with Javascript with two PNG images, in order to minimize compression losses.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nRed Giant\u0026rsquo;s video guide for the Instant 4K plugin, from where my default settings were taken from. https://www.redgiant.com/tutorial/getting-started-with-instant-4k/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2018-07-17T00:00:00Z","permalink":"http://localhost:1313/post/video/2018/resizing-videos-in-after-effects/","title":"Resizing Video with After Effects and Instant 4K"},{"content":"Always Record to an External Hard Drive Apparently I forgot my own advice.\nUse fast external disks as the destination.\nEven if recording to an uncompressed format like ProRes, always use a different drive than the OS\u0026rsquo; hard drive.\nEven if it\u0026rsquo;s an SSD.\nWhat Happened? The result was particularly bad. Large dropped frames, audio/video sync issues, the works. And by works, I mean it\u0026rsquo;s going to be a ton of work to cleanup too.\nI didn\u0026rsquo;t catch the error until after coming home, because all I was paying attention to was the CPU usage. I wasn\u0026rsquo;t even streaming and merely using Wirecast as a multicam monitor. CPU usage was always around 30%, and so I thought, \u0026ldquo;Oh we\u0026rsquo;re doing really good.\u0026rdquo;\nWirecast Record to Disk Best Practices Here are the recommendations from Craig over on a post1 at the Wirecast forums from Nov 2017:\nMake sure you have the best possible throughput. Avoid using the system disk. Separate internal SCSI drives are OK. Avoid using USB2 drives. If USB3 it should, ideally, be the only device on the bus. Even separate ports may be on the same bus. Best is to use SSD or RAID0 striped drives. 7200 RPM disks may be OK though. Avoid spinning disks below 7200rpm Keep CPU below 80% and below 70% is even better. Make sure the drive never gets filled beyond 80% capacity. Especially for spinning disks, they can slow as they fill. Make sure you\u0026rsquo;re not confusing variable frame rate with dropped frames. Wirecast records a variable frame rate to avoid dropped frames and keep motion smooth. If you\u0026rsquo;re going to do post editing consider using MJPEG MOV instead of H.264. Interestingly, another forum post2 suggests USB3 can be temperamental. One person had dropped frames from a bad cable!\nWhy It Worked Last Month Back in May 2018 (during the All-Night concert), I was connected via Thunderbolt to a RAID 0 striped LaCie 4 TB drive. Recording the livestream + HDV camera via Wirecast worked just fine.\nHowever this time, the internal Scratch disk was actually on the same physical SSD as the OS. It did have 500 GB free, but free space was irrelevant.\nOne Strike and You\u0026rsquo;re Out\u0026hellip; to Make it Better Next Time Not recording to a dedicated, write disk is a fatal flaw. Let\u0026rsquo;s put on that growth mindset, shall we?\nReferences Dropped Frames when recording to disc https://telestreamforum.forumbee.com/r/m2knvp\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nISO Dropping Frames https://telestreamforum.forumbee.com/t/80tr9x/iso-dropping-frames\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2018-06-28T00:00:00Z","permalink":"http://localhost:1313/post/video/2018/livestreaming-lessons-re-learned/","title":"Livestream Lessons Learned, Again"},{"content":"Finder Folder Icons vs. Bucket Storage I often use Finder labels colors to manage media, specifically colors. These can easily indicate statuses: green for complete, blue for \u0026ldquo;cold storage\u0026rdquo; projects, red for abandoned projects, etc. These labels however are not supported on many popular bucket storage, e.g. Amazon S3 and Backblaze B2.\nWhat this means is one day, when I decide to restore a project, all the Finder folder colors will be gone. Instead, I\u0026rsquo;d drain a lot of time trying to remember where the project was. It\u0026rsquo;s almost like losing a document that\u0026rsquo;s never saved! Ya, that kind of feeling.\nWhat about if we wrote our own script to do that instead?\nCheck it out on GitHub!\nLet\u0026rsquo;s Go, Automator Automator Services are awesome. This little guy can be triggered in any application from a single folder. Here\u0026rsquo;s the overview:\nCopy the workflow into ~/Library/Services/ Tag folders with Finder colors (green, orange, etc.) Invoke the Convert Finder Labels to Icons service (e.g. from Finder\u0026rsquo;s context menu) A little gear will spin the menu bar as the workflow executes The script writes a file green.icon.png, orange.icon.png etc. into all folders with labels, and sets the icon of the folder to that new icon (to indicate it did work) Folders are archived in bucket storage. The icon and label are lost, but the png file remains! After restoring from bucket storage, run the program on the parent folder again. The script sets the icon of the folder based on the png file and also sets the Finder label again! This approach is rock solid! Automator only provides the folder list, which means the shell script can be invoked on a single folder for testing.\nFurthermore, since the png file is named with the same color, the status of projects is easily understood browsing around the storage bucket, without needed to download and run the script.\nThe only tradeoffs are:\nIt is not an automatic process.\nIn order to completely remove a color, the icon, label, and png file must be manually deleted. (Changing a label to another color is supported automatically.)\nAppendix: But what about\u0026hellip; Automator wasn\u0026rsquo;t the first idea! Here are some others that didn\u0026rsquo;t work out.\nFolder Actions OS X comes built-in with Folder Actions that can trigger scripts when something changes inside a folder. However, Folder Actions cannot recursively monitor a folder, so any solution would require adding an action for each subfolder. Too cumbersome.\nHazel Hazel is an amazing piece of software that scans folders and can perform tasks automatically. Using Hazel, it\u0026rsquo;s possible to script up a trigger to convert our Finder tag/color to an icon file, and restore that icon file automatically.\nThe workflow would look something like this, either triggering a shell script, Automator action, etc.\nHowever, after numerous attempts, Hazel seems a bit buggy for this particular effort. It doesn\u0026rsquo;t always detect when a folder\u0026rsquo;s color label has changed, and even when the log says it does the rules don\u0026rsquo;t fire. The same script run manually however does work!\nSeveral support pages on Hazel\u0026rsquo;s forum also indicate bugs:\nRules frequency Add file to iTunes when added to folder Hazel Rules Not working Note: by default, the output of the shell scripts is not written to the Hazel log. To do so run Hazel in Debug Mode.\nSo although Hazel could do the job, it doesn\u0026rsquo;t seem stable enough.\n","date":"2018-05-25T00:00:00Z","permalink":"http://localhost:1313/post/video/2018/cloud-storage-and-finder-folder-icons/","title":"Persisting Finder Labels in Cloud Storage"},{"content":"The Challenge Sometimes, when collaborating on projects virtually, file storage becomes a problem. Professional studios can probably run highly performant SFTP servers or bucket storage systems, but when you\u0026rsquo;re working with other freelancers on tight budgets—who may not be as tech savvy—a 30 GB file starts becoming a big problem.\nFree, Simple File Sends Filemail.com is a really convenient web service that allows for sends of up to 50 GB at a time in their free tier. Receipients can either download files in the web browser or can torrent them for convenient pause/resumes.\nFilemail is typically the service I\u0026rsquo;ve asked others to send me raw video files through.\nAnd I always ask the files be zipped up first\u0026hellip; why?\nRepairing HTTP Header Corruption One time, a person sent raw MTS (MPEG Transport Stream) video files from an AVCHD camera. I did ask them to zip it up first, but for whatever reason that was overlooked. \u0026ldquo;How bad could it be?\u0026rdquo; I thought. I\u0026rsquo;d already downloaded about 40 GB of footage!\nI fired up Edit Ready to rewrap the MPEG-2 Transport Stream into a MOV container for editing. However, the conversion would keep failing after a certain point\u0026hellip;\nI reached out the main man of Divergent Media, Colin McFadden, and he replied back super promptly with the following:\nAt that point in the file where it fails, there\u0026rsquo;s a hunk of HTTP header, which definitely shouldn\u0026rsquo;t be in an MTS file. Seems like something went really wrong in however these were transferred.\nSure enough, there was some Content Disposition HTTP headers slapped in between!\nDeleting these with a hex editor and rewrapping the new file did the trick beautifully!\nInterestingly (and this could very well be my own error) not all the headers were the same length: 444 bytes, 428 bytes, 456 bytes, and 453 bytes. Screenshots of the other three are below.\nAlways Zip Take home lesson? Always ask files to be zipped before sending through web upload services. Compression isn\u0026rsquo;t important really—storage-only zips or tars would do just fine.\nAnd to salvage footage, don\u0026rsquo;t be afraid to open a hex editor!\n","date":"2017-03-14T00:00:00Z","permalink":"http://localhost:1313/post/video/2017/best-practices-for-large-web-transfers/","title":"Best Practices for Large Web Transfers"},{"content":"The Rub We\u0026rsquo;ll start with a quote from Larry Jordan:\nX.264 and H.264 should only be used when creating files for the web. If you plan to edit the resulting file, convert it to ProRes instead. AVCHD files compressed into H.264 for editing will look just awful.\nOops.\nThe Flawed Setup I still use a Sony FX7 for some setups. It has a Firewire out which makes it perfect for livestreaming.\nFor this event, I wanted to (1) use the FX7 for livestreaming and (2) also record the raw HDV video itself for editing afterwards.\nIn order to avoid those awful MiniDV tapes—whose tape changes I feared also might cause the live feed to that meant recording to disk. It wasn\u0026rsquo;t possible to share the video source with both Wirecast and ScopeBox, so I thought, \u0026ldquo;Hey, why not try recording straight to disk in Wirecast instead?\u0026rdquo;\nWhile this post details many other general livestreaming lessons learned, there are a few major downsides to relying on Wirecast for raw footage which I now realize. Wirecast doesn\u0026rsquo;t know how to \u0026ldquo;automatically\u0026rdquo; record as HDV; instead it manually requires setting the codec format, frame rate, etc. which felt too easy for me to mess up. For example: since HDV is technically a 4:3 1440x1080 image that\u0026rsquo;s then stretched out, I wasn\u0026rsquo;t sure whether I should record to 1920x1080 or 1440x1080.\nSo rather than deal with all that I said instead, \u0026ldquo;Let\u0026rsquo;s just save H.264 in Wirecast to disk!\u0026rdquo; (It was a pretty neat setup actually, using two Wirecast documents open simultaneously, one for the livestream and one just for the camera\u0026rsquo;s archive stream.) Just in case 1080p would create an upscale, I thought going 720p would be better.\nThus the Nightmare Before Recording began.\nThe Rescue Contenders Three approaches to \u0026ldquo;uncomb\u0026rdquo;1 the baked in interlaced footage were tried:\nHandbrake (v 0.10.5 x86_64) Compressor 4 via forcing the field order to interlaced PHYX Cleaner plugin as suggested on a Wirecast forum2 Of these three, Compressor was the clear winner.\nThe Compressor Trick Compressor, it seems, has a handy feature that allows \u0026ldquo;forcing\u0026rdquo; an input file\u0026rsquo;s field order. By carefully clicking on the input file\u0026rsquo;s box, the Inspector window on the right shows a little section called File Properties.\nSince the file is actually H.264, Compressor reads the metadata and selects Progressive by default. Changing this to Top First forces it to treat it as interlaced (since HDV is top field first).\nDeinterlace Tests All files, a total of 2.68 GB, are available here for reference. Compressing them for web would precisely alter what we\u0026rsquo;re trying to observe!\nNote: please be considerate and only download them sparingly as needed.\n1080iHDVSavedAs720pH264Clip1.mov\n57 second clip, 30 MB.\nOutput file Size Program used Result Apple Devices HD (Best Quality).m4v 49M Compressor BEST Apple ProRes 422 Retiming Better.mov 498M Compressor FAIL Apple ProRes 422 Stock.mov 498M Compressor FAIL H.264 for Archival.mov 94M Compressor BEST HandbrakeHighProfileDecombBob.mp4 30M Handbrake FAIL HandbrakeHighProfileDecombBob60fps.mp4 30M Handbrake FAIL HandbrakeHighProfileDecombBobTff.mp4 31M Handbrake FAIL HandbrakeHighProfileDeinterflaceBobTff.mp4 37M Handbrake FAIL HandbrakeHighProfileDeinterlaceBob.mp4 36M Handbrake FAIL HandbrakeHighProfileDeinterlaceBob60fps.mp4 36M Handbrake FAIL PhyxCleanerMasterFileH264.mov 49M PHYX + FCPX OK PhyxCleanerMasterFileProRes.mov 499M PHYX + FCPX OK Up to 4K Stock.mov 69M Compressor OK x264 Jan Ozer-esque.mov 48M Compressor + x264 FAIL x264 Larry Jordan-esque.mov 47M Compressor + x264 FAIL From these experiments, it seems Handbrake\u0026rsquo;s decombing/deinterlacing algorithms can\u0026rsquo;t be forced on progressive video files. Even forcing the footage with tff as top-field-first3 yielded zero discernible difference. Handbrake\u0026rsquo;s just meant to work on actual interlaced footage.\nAlso interesting to note is Handbrake seems to start video earlier from the GOP, even though the file itself started many frames later. Hence the audio is blank at the beginning of the output render file!\nPHYX Cleaner\u0026rsquo;s output was better than the original, but it\u0026rsquo;s still rather comby. Both H.264 and ProRes master files appear identical in deinterlacing quality. Perhaps the plugin can be refined further from the stock plugin settings, but even if that were the case there are so many disadvantages:\nit\u0026rsquo;s a paid plugin each clip would require a separate Project in FCPX exporting from FCPX can\u0026rsquo;t be batched easily (like Compressor) Compressor however is the clear champion! In particular, the only passing Compressor renders were by forcing the field order and using Apple\u0026rsquo;s stock H.264 codec. Forcing the field order and using an x264 codec4 made no difference—and rather looked like the poor output from Handbrake (likely because Handbrake uses x264 too).\nSummary of Repair Solution 1080iHDVSavedAs720pH264Clip2.mov\nFinal confirmation with a 11 sec, 9 MB segment instead.\nOriginal especially note the combing during fast hand movements\nYour browser does not support the video tag. Output file Size Program used Result Up to 4K Stock.mov 14M Compressor BEST Up to 4K Better Retiming.mov 14M Compressor BEST It\u0026rsquo;s hard for me to tell if there\u0026rsquo;s an appreciable difference between the two retiming settings, but for sure the combing is no more!\nRepaired (Up to 4K Better Retiming) look Ma, no lines!\nYour browser does not support the video tag. So at the end of the day, forcing Compressor\u0026rsquo;s input field order and exporting using Apple\u0026rsquo;s H.264 codec works like a champ.\nPhew!\nAppendix: Custom Encoding Presets Tried Details of all the presets used. All audio settings left as default.\nx264 Larry Jordan-esque (Compressor) Inspired by: https://larryjordan.com/articles/compressor-x264-improve-video/\nQuickTime settings Compression Type set to x264 Encoder Key Frames set to Automatic (instead of Every 24 frames) Data Rate set to Automatic (instead of 6400 kbps) Encoding set to Best quality (Multi-pass) Quality moved to High Options \u0026hellip; Flags \u0026gt; crf turned on. Everything else left as is Retiming quality set to Better (Motion Adaptive) x264 Jan Ozer-esque (Compressor) Inspired by: http://www.streaminglearningcenter.com/articles/first-look-apple-compressor-41.html and http://www.streaminglearningcenter.com/articles/encoding-with-the-x264-codec-with-compressor-4.html\nQuickTimeSettings Set Compression Type to x264 Encoder Options \u0026hellip; \u0026gt; Load preset \u0026gt; Use Library native preset/tune x264 preset left as Medium (default) x264 tune left as None Hit OK H.264 Profile limit left as up to High Profile Hit OK Changed Key Frames to Automatic Compressor Quality to High Encoding to Best quality (Multi-pass) Data Rate set to Automatic (instead of 6400 kbps) Hit OK Retiming quality set to Better (Motion Adaptive) x264 Deinterlace (HandBrake) Started with High Profile Picture Settings \u0026gt; Filters Deinterlace: Bob x264 Decomb (HandBrake) Started with High Profile Picture Settings \u0026gt; Filters Decomb: Bob x264 Deinterlace, Top Field First (HandBrake) Started with High Profile Picture Settings \u0026gt; Filters Deinterlace: Bob Add :tff under Additional Options x264 Decomb, Top Field First (HandBrake) Started with High Profile Picture Settings \u0026gt; Filters Decomb: Bob Add :tff under Additional Options Apple ProRes 422 (Compressor) Started with stock preset Retiming quality set to Better (Motion Adaptive) H.264 for Archival (Compressor) Duplicate stock Up to 4K preset (can be found under either Publish to Vimeo or Publish to YouTube) Rename as H.264 for Archival Change Data rate from Web publishing (19531 kbps) to Computer playback (29296 kbps). Note rates listed in Compressor are for actual 4K footage and will be smaller for 720p footage. Change retiming quality from Fast to Better (Motion Adaptive) Change audio from AAC to Linear PCM 48kHz, Best Quality, 16-bit Little Endian (the Intel Default)5 PHYX Cleaner References Examples of combing https://en.wikipedia.org/wiki/Interlaced_video#Interlacing_problems\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nRecorded Interlaced Source as Progressive file - now what? http://forum.telestream.net/forum/messageview.aspx?catid=45\u0026threadid=23213\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nTip to use :tff in Handbrake http://stackoverflow.com/questions/9287122/how-do-i-set-the-interlaced-flag-on-an-mkv-file-so-that-vlc-can-automatically-pl\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://larryjordan.com/articles/compressor-x264-improve-video/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://larryjordan.com/articles/it-aint-the-endian-of-the-world/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2017-02-04T00:00:00Z","permalink":"http://localhost:1313/post/video/2017/repairing-h264-interlaced-footage/","title":"Repairing H.264 Interlaced Footage"},{"content":"Where Has Timecode Gone? Newer, prosumer codecs these days like Sony XAVC-S don\u0026rsquo;t seem to record video with timecode. It\u0026rsquo;s one of the chief drawbacks that knocks the otherwise brilliant Sony AX100 from solid professional use. Timecode tracks can save mountains of time when editing multicamera shots, relinking media files, trimming clips precisely and so on—which, ostensibly, most home video footage won\u0026rsquo;t call upon.\nProsumer camera codecs like AVCHD and XAVC-S write H.264 video in MP4 containers. H.264 is a compressed video format originally intended for delivery, not editing, but its role has slowly evolved. Prosumer cameras really benefit from the compression because then 4 hrs of 4K can still fit on a 128 GB SD card.\nMP4 containers don\u0026rsquo;t traditionally support timecode which may help to explain why the recent trend in dropping timecode. Although Apple supports timecode in MP4 containers since 2013, other software may exhibit side-effects reading timecode-rich MP4s if they do not expect it.\nMOV to the Rescue MOV containers are like the Swiss army knife of containers. Unlike MP4, MOV supports timecode tracks full out, and rewrapping from MP4 to MOV can be done in a number of ways! But which are robust and which go bust?\nShort answer: EditReady is the most robust rewrapper out there, and can even be scripted from the command line. Read on for the details and why others didn\u0026rsquo;t cut it (no pun intended).\nThe Setup The following tests were performed using AVCHD files already in MOV format as imported on a MBP with Photos. They however, did not have timecode.\nAfter timecode was added to the MOV container, the file was opened with QuickTime Player 7 and Compressor 4 to verify timecode. The file was then transcoded with Compressor to check its integrity.\nEditReady Lives up to Its Name EditReady is a champion at rewrapping footage. Divergent Media makes excellent products and their customer service is bar none. When I had written regarding the ghost render, Colin at Divergent Media explained:\nCompressor isn\u0026rsquo;t good at recovering from bad frames, so that\u0026rsquo;s the mostly likely problem. You hit one bad segment and it just gives up. EditReady is a little better about moving past those segments. It could have been a bad SD card or something during the original shoot.\nEditReady\u0026rsquo;s algorithms can correct this, so it\u0026rsquo;s really the most versatile program out there. Rewrapping with EditReady makes Compressor super, super happy.\nEditReady\u0026rsquo;s rewrap affected the FCP X date at first, but turns out it was because there were conflicting dates inside the container\u0026rsquo;s metadata!\nEditReady\u0026rsquo;s Metadata window calls this to your attention and allows you to select and/or set which date you would like.\nAs you can see the original file does not have any timecode. By default, EditReady will preserve timecode if present, but not generate it if absent on the original. However, clicking the + icon in the upper right allows one to add a timecode tag as well! (By default, if the field is blank, timecode will start at 00:00:00:00).\nThe size of the rewrapped, timecode footage is the same within a few bytes. Strangely enough, QuickTime Player 7 did crash a few times when scrubbing both.\nThe rewrapped video however was larger in the number of frames: without timecode generation, it was 159165 frames instead of 159164 and with timecode it was 159166. Thinking this might have been the potential missing frame correction, I checked against another clip that rendered properly in Compressor, but the EditReady rewrap (without timecode) was again greater in frames: 174150 vs 174149.\nWhile the cause is unknown (roundoff error maybe?), the implication of the change in number of frames is clear: rewrapping footage will make relinking offline media a nightmare! Attempting to relink the timecode version with the original brings this lovely dialog:\nThus, always rewrap footage first before beginning editing.\nConclusion At the end of the day, EditReady is the most reliable way of rewrapping and adding timecode to any footage. Repairing even small nicks from original footage, it serves a a trustworthy partner in the initial post-processing logging and transfer workflow.\nAppendix: The \u0026ldquo;B\u0026rdquo; List Sometimes \u0026ldquo;B\u0026rdquo; is generous. Here\u0026rsquo;s what doesn\u0026rsquo;t work.\nffmpeg Woes ffmpeg is the open source king for video compression. Many programs like Handbrake are built on it, so I was excited to learn it can add timecode as well! To rewrap a container with timecode the syntax is like so:\nffmpeg -i Day_1.mov -codec copy -timecode 04:25:50.00 Day_1.ffmpeg.mov\nNote: the timecode seems to be automatically calculated based on the framerate of the video track. Also, by default, ffmpeg only preserves 1 video and 1 audio track.\nWhile ffmpeg successfully added timecode, the resulting file was a disaster for editing. The file systematically quits @ 20 seconds on any render in Compressor, suggesting some kind of container corruption.\nFurthermore, although the file did play in QuickTime Player X and QuickTime Player 7, scrubbing the playhead sometimes caused the application to crash!\nThe file crashed when scrubbing in Compressor as well.\nLastly, the first frame is often black. Note in particular the strange, red vertical lines in Compressor\u0026rsquo;s preview window.\nIn a way, ffmpeg is a video delivery king, but perhaps not an editing king.\nVideoToolShed MP4 to QuickTime Videotoolshed\u0026rsquo;s MP4 to QuickTime was another contender, but starting from version 6 the program uses ffmpeg under the hood, to increase compatibility with other programs. So it too exhibits the same problems and failed to render with Compressor.\nAlso, the VideoToolShed GUI is very rough around the edges:\nOnly detects MP4 files. So to add timecode to existing MOVs, the files first have to be renamed to trick the program to open them. When processing the program won\u0026rsquo;t come back to the foreground. Hovering with the mouse shows the little color pinwheel\u0026hellip; Files also can\u0026rsquo;t be dragged and dropped, etc. So ya, the little things—and some big things as well.\nCinePlay CinePlay by Digital Rebellion is almost like QuickTime X Pro and could serve as a solid competitor to SimpleMovieX. CinePlay offers numerous vital features for editing:\nTimecode display Text input of timecode location Add markers and annotations—including drawings! (Chapters not visible automatically in Compressor/FCP X, but can be exported to text files and imported manually) Set ins and outs (standard FCP7 keyboard shortcuts) Many others like video rotation, timecode and titlesafe overlays, etc. Moreover, CinePlay\u0026rsquo;s Export window offers a rewrapping option (see their own blog post here) which automatically adds NDF timecode starting at 00:00:00:00—perfect for changing MP4 containers to MOV. The process however cannot be scripted from the CLI, but could be, in principle, via AppleScript to queue multiple files for export at at time.\nThe rewrapped MOV itself appears to have full structural integrity. No funny glitches and crashes when processing the file. It does however start with a black image sometimes—but unlike the ffmpeg one, this doesn\u0026rsquo;t show any funny red lines in Compressor\u0026rsquo;s preview window.\nIt also passes the Compressor test: no crash at the lovely 20 second mark.\nThe rewrapped MOV is roughly the same size, within a few bytes.\nHowever, while the original was 159164 frames, the rewrapped one is 159111.\nThe first setback is CinePlay changes the File Creation Date of the file (i.e. the one that\u0026rsquo;s read from GetFileInfo from the Terminal) so the date in FCP X is changed from the original to the date of the rewrapping. Also note, though how the timecode duration appears longer in FCP X. This I reckon is because the timecode track is NDF but the FR is 29.97, and/or some metadata is incorrect in CinePlay\u0026rsquo;s rewrap. (In Compressor, the last frame\u0026rsquo;s timecode is 01:28:23:21.)\nAlso, the frame rate of the rewrapped footage is no longer 29.97 but instead 30, as told to Compressor.\nAnother rather serious hiccup was\u0026hellip; the Compressor render never completed!\nTurns out the original movie file I inherited was somehow corrupt. (Photos probably isn\u0026rsquo;t the best tool to import AVCHD footage.) Not CinePlay\u0026rsquo;s fault at all but it does knock it out of first place for fault tolerance!\nHistory [Updated July 5, 2019 with wording and ordering changes.]\n","date":"2016-01-24T00:00:00Z","permalink":"http://localhost:1313/post/video/2016/rewrapping-and-adding-timecode-to-mp4s/","title":"How to Add Timecode to MP4 Files"},{"content":"Introduction Last May, for Chhandayan\u0026rsquo;s All-Night Concert 2015 in NYC, I cut between two cameras in the livestream for the first time. Little did I know, there was a lot to learn.\nHere\u0026rsquo;s what I\u0026rsquo;d do differently next time.\nTransfer SD Card Footage with a Separate Laptop Red Giant\u0026rsquo;s neat software Offload made it really simple to transfer footage from the Sony AX100 cam. Since it also compares checksums of these giant video files, I suspect it spiked the CPU and caused some dropped frames—especially since Wirecast was writing to the same disk!\nBest to use another machine like a MacBook Air to dump SD footage. Any machine with a fast, built-in or USB 3.0 SD card reader really.\nAlways Ingest HDV Cams as Uncompressed HDMI Outputs If the streaming laptop had another Thunderbolt port, this would have been a no-brainer a long time ago: rock two Blackmagic Mini Recorders via Thunderbolt and call it a day. However my 2012 MacBook Pro 9,1 has only one port, and the Mini Recorder is an endpoint with no daisy chaining (why o why).\nWhen the livestream source is HDV over FireWire, the camera actually compresses the video before it sends it over 1 2 3; DV video on the other hand, is at a low enough bitrate to be uncompressed. So compressed HDV has to be decompressed by the receiving side, i.e. Wirecast, which takes a few milliseconds. This makes the HDV FireWire feed lag slightly behind the other HDMI camera and creates an audio-video sync problem—especially when cutting/mixing with another camera live.\nForums at Telestream suggest HDV video always lags uncompressed video/audio streams, but some users don\u0026rsquo;t experience significant lag when using HDV as the only source for both audio and video (probably the case for me because of the MBP\u0026rsquo;s high specs)4.\nHere is an example of the AV sync issue. The stationary center cam is HDV via FireWire and the panning closeup cam is uncompressed HDMI via a Blackmagic Mini Recorder. Audio is not switched and is always taken from the closeup camera (fed from the mixer). Note how the center cam\u0026rsquo;s video is approximately 0.5 sec behind the audio—i.e. the time for the data to decompress!!\n\u0026ldquo;Is it possible to delay the video of one source so that it\u0026rsquo;s in sync with the other?\u0026rdquo; Although Wirecast allows for an audio delay offset, there\u0026rsquo;s no \u0026ldquo;source offset\u0026rdquo; option. One way might be to pipe the video through VLC to timeshift it with the play/pause button5, but that\u0026rsquo;s not precise enough here to say the least for starters. [Update] As of Wirecast 7.0, sources now have a separate video delay feature. It would probably take some tuning though to get it right, and still might not be worth it since the decompression would still result in higher CPU usage.\nThe solution? Thankfully now6, unlike when it was first released in 20117, the Blackmagic Intensity Shuttle USB 3.0 is compatible with Macs! Both are recognized by Wirecast which means one camera can use it via HDMI as a streaming input using Desktop Video 10.5.4 (released January 5, 2016). It\u0026rsquo;s also the goto workflow at Harvard University Athletics (in fact, they use two Mini Recorders and one Intensity Shuttle USB on a MBP with success)!8\nWirecast\u0026rsquo;s Record To Disk ≠ Edit Grade Footage Wirecast drops frames and even adjusts the frame rate on the fly9 to serve live content. In live video, performance takes priority over data integrity. Dropping a few frames here or there won\u0026rsquo;t make a visible difference to the end user. Wirecast does exactly this, typically around 80% CPU usage10 11. However for frame-precise editing and multitrack syncing of any kind, every frame is vital. So using Record to Disk is not the right tool for raw footage at all. Wirecast won\u0026rsquo;t save timecode. Kinda makes sense, given the dropped frames. This makes it impossible to detect drops via any kind of timecode-break detection program. Thus the saved stream is super tedious to chop and fix if it is to be synced with another track. There\u0026rsquo;s no way to save HDV footage as HDV footage in Wirecast. It\u0026rsquo;s no ScopeBox. As far as I can tell, the incoming stream would have to be recompressed on the fly to some other format like H.264, which causes more CPU cycles. Better would be to either:\nSave to MiniDV tape and transfer afterwards. Cumbersome, but it technically works. Tapes are about $3 each on Amazon and transferring after takes time, but the main setback is sporadic dropouts during captures when every moment counts. (Stay in school folks.) Save to disk via FireWire and leave the HDMI for streaming. ScopeBox has been my tried and tested approach for \u0026gt; 5 years, and it preserves timecode. (Maybe the streaming laptop could even handle it if it saved to a separate disk\u0026hellip;saving an m2t stream doesn\u0026rsquo;t take much CPU.) Save to disk via Wirecast using uncompressed formats like ProRes. The way this works is by opening a separate, simultaneous project that only has the input from the HDV camera\u0026rsquo;s HDMI output. The file size is kind of overkill, but this approach could definitely work if another laptop is not available. However the inherent risk of dropped frames is still lingering, and timecode is is still not saved. Note: recording to SSD via Blackmagic HyperDeck Shuttle won\u0026rsquo;t work, because we need the uncompressed HDMI output for the livestream and the camera has only 1 HDMI output.\nBest Practices for Record To Disk Saving the livestream feed to disk is still helpful. Such footage is not a substitute for actual footage from the camera but can be used for quick YouTube posts or as a rough outline for post-production work. (For example, cuts can be detected automatically using programs like Edit Detector and applied to post-production timelines, saving hours of multicam editing work.)\nWhen doing so the following tricks minimize dropped frames:\nEither save in ProRes or in the same format as the livestream. As this Wirecast forum post12 explains, each output format results in an additional real time encoder thus more CPU usage. H.264 can be particularly CPU intensive, especially when the settings specified cannot take advantage of hardware codecs. ProRes however is extremely light on the CPU, since it\u0026rsquo;s uncompressed.\nUse fast external disks as the destination. As the same post12 explains, writing to disk on slow external drives can also result in dropped frames. I find writing to the same internal disk can also cause performance degredation, interfering with the livestream. However USB 3 and Lightning drives have more than enough bandwidth and don\u0026rsquo;t spike CPU usage—even for ProRes. And that\u0026rsquo;s a good thing, because ProRes files can run really big! Here\u0026rsquo;s a rough guide for choosing the right size drive.\nCodec Resolution Size on Disk ProRes 422 1080p 1.02 GB/min = 61.2 GB/hr ProRes 422 720p 0.53 GB/min = 31.8 GB/hr ProRes 422 480p 0.36 GB/min = 21.6 GB/hr Split files often. Rather than saving a single five-hour file to disk, start/stop the file recording for each song, set, etc. Doing so limits inevitable dropped frames to a smaller percentage of the duration of the video, making audio drift less noticable and increasing the chance for multicam syncing.\nHistory [Updated Feb. 4, 2017 with additional Wirecast Record to Disk information.]\n[Updated May 14, 2018 with renamed titles, edits, and updated Wirecast best practices.]\nFootnotes http://forum.telestream.net/forum/messageview.aspx?catid=45\u0026threadid=8362 HDV, because it's a GOP based codec, takes longer to decode than the audio, hence the sync delay.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nConfirms HDV buffering on output of ~ 1 sec. https://obsproject.com/forum/threads/ability-to-synchronize-cameras.23166/ Now I'm using also HDV cameras - Canon HX-A1 and Sony Z1. They are connected via firewire*, attached using Video source plugin (as it's m2ts (mpeg2) stream so can't be used directly at least in old OBS codebase). But this cameras has about 1 second of lag on firewire output, and that's how it works by design on most hdv cameras.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nAnother thread on explaining HDV video lag. http://forum.telestream.net/forum/messageview.aspx?catid=45\u0026threadid=10289 HDV will lag because of the time it takes to decode the codec. Make sure your camera is in DV mode. Audio will tend to be ahead of the video from HDV camera due to the aforementioned lag.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttp://forum.telestream.net/forum/messageview.aspx?catid=45\u0026threadid=13312 HDV decode would lag behind HDMI/SDI input decode. Additionally HDV video may decode ahead of HDV audio. As others have mentioned I would not mix the two if sync were critical.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttp://forum.telestream.net/forum/messageview.aspx?catid=44\u0026threadid=10185\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nLooks like public beta for the Blackmagic Intensity Shuttle USB 3.0 support started with Desktop Video 9.7.3 on June 16, 2013 but was still in beta through May 28, 2014 at least.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nIntensity Shuttle USB 3.0 unsupported on Macs initially http://forum.blackmagicdesign.com/viewtopic.php?f=3\u0026t=3518\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttp://stretchinternet.com/blog/2013/07/high-definition-three-camera-inputs-one-laptop-3500/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWirecast recommends always keeping the CPU under 80% http://forum.telestream.net/forum/messageview.aspx?catid=45\u0026threadid=18511\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWirecast frame rate loss suggested around 85-90% CPU http://forum.telestream.net/forum/messageview.aspx?catid=45\u0026threadid=19731\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThis Wirecast post suggests frame rate loss one says 80% CPU http://forum.telestream.net/forum/messageview.aspx?catid=45\u0026threadid=17012\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nAnother 80% CPU, also external HD very little impact on disk http://forum.telestream.net/forum/messageview.aspx?catid=45\u0026threadid=16048 Basically streaming and recording are using the same encoder rather than two encoders in that case...CPU above 80% can result in problems. External hard drives have very little impact with overall CPU use. Apple ProRes is a professional post production codec. H.264 is generally not best for post workflow. It can take significant CPU resources to encode (and decode in post).\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2016-01-24T00:00:00Z","permalink":"http://localhost:1313/post/video/2016/live-streaming-lessons/","title":"Livestreaming Lessons Learned"},{"content":"Introduction There is quite a bit of literature1 2 3 4 5 on the net how Adobe applications can embed XMP metadata and modify original footage on import—wreaking havoc for other NLEs like FCP. Posts range as far back as 2011, the year FCP X was released, to even one in mid 2014. However, for those that roundtrip between FCP X and Adobe with XMP metadata, turns out things have changed—for the better!\nThe takeaway of all them, rightly so, was to uncheck the nasty Write XMP ID to Files in Import setting in Adobe Premiere, After Effects, etc. which is on by default! 6\nThe Write XMP ID To Files On Import option tells Premiere Pro to add a single piece of XMP metadata to the source file itself. This is basically a unique identifying number that can then be used by the various applications that understand XMP metadata [namely, the Adobe Suite] to tell which files is being used where. So, yes, it does modify the source file. If you don\u0026rsquo;t want that to happen, then make sure that checkbox is unchecked.\nBy unchecking this option, the checksums and file sizes of the raw assets do not change, and projects in other NLEs like FCP X will not force re-linking because of an incompatible media file.\nSetup The following experiment was conducted using the following:\n15\u0026quot; Mid 2012 MBP 9,1 OS X 10.11.1 El Capitan, released 2015-09-307 FCP X 10.2.2, released 2015-09-048 Adobe Premiere Pro CC 2015 9.1.0(174) Build \u0026ldquo;Original Gravity\u0026rdquo;9 XAVC-S 720p MOV file from a Sony AX100 Procedure Import video (as a linked file) into FCP X. Use ExifTool and save linked file metadata. Note the System File Date/Time values at the top. $ exiftool -api largefilesupport=1 -G1 XAVCS-sample.mov ​\t[ExifTool] ExifTool Version Number : 10.08 ​\t[System] File Name : XAVCS-sample.mov ​\t[System] Directory : /Volumes/Scratch/est ​\t[System] File Size : 3156 MB ​\t[System] File Modification Date/Time : 2014:05:22 03:25:30-04:00 ​\t[System] File Access Date/Time : 2016:01:09 20:28:35-05:00 ​\t[System] File Inode Change Date/Time : 2016:01:09 19:47:23-05:00 ​\t[System] File Permissions : rwxrwxrwx ​\t[File] File Type : MOV ​\t[File] File Type Extension : mov ​\t[File] MIME Type : video/quicktime ​\t[QuickTime] Major Brand : Apple QuickTime (.MOV/QT) ​\t[QuickTime] Minor Version : 2005.3.0 ​\t[QuickTime] Compatible Brands : qt ​\t[QuickTime] Movie Data Size : 3307975773 ​\t[QuickTime] Movie Data Offset : 48 ​\t[QuickTime] Movie Header Version : 0 ​\t[QuickTime] Create Date : 2014:05:11 04:50:09 ​\t[QuickTime] Modify Date : 2014:05:11 05:31:53 ​\t[QuickTime] Time Scale : 600 ​\t[QuickTime] Duration : 0:41:43 ​\t[QuickTime] Preferred Rate : 1 ​\t[QuickTime] Preferred Volume : 100.00% ​\t[QuickTime] Preview Time : 0 s ​\t[QuickTime] Preview Duration : 0 s ​\t[QuickTime] Poster Time : 0 s ​\t[QuickTime] Selection Time : 0 s ​\t[QuickTime] Selection Duration : 0 s ​\t[QuickTime] Current Time : 0 s ​\t[QuickTime] Next Track ID : 3 ​\t[Track1] Track Header Version : 0 ​\t[Track1] Track Create Date : 2014:05:11 04:50:09 ​\t[Track1] Track Modify Date : 2014:05:11 05:31:53 ​\t[Track1] Track ID : 1 ​\t[Track1] Track Duration : 0:41:43 ​\t[Track1] Track Layer : 0 ​\t[Track1] Track Volume : 100.00% ​\t[Track1] Image Width : 1280 ​\t[Track1] Image Height : 720 ​\t[Track1] Graphics Mode : ditherCopy ​\t[Track1] Op Color : 32768 32768 32768 ​\t[Track1] Compressor ID : avc1 ​\t[Track1] Vendor ID : Apple ​\t[Track1] Source Image Width : 1280 ​\t[Track1] Source Image Height : 720 ​\t[Track1] X Resolution : 72 ​\t[Track1] Y Resolution : 72 ​\t[Track1] Compressor Name : H.264 ​\t[Track1] Bit Depth : 24 ​\t[Track1] Video Frame Rate : 29.87 ​\t[Track2] Matrix Structure : 1 0 0 0 1 0 0 0 1 ​\t[Track2] Media Header Version : 0 ​\t[Track2] Media Create Date : 2014:05:11 04:50:09 ​\t[Track2] Media Modify Date : 2014:05:11 05:31:53 ​\t[Track2] Media Time Scale : 44100 ​\t[Track2] Media Duration : 0:41:43 ​\t[Track2] Balance : 0 ​\t[Track2] Handler Class : Data Handler ​\t[Track2] Handler Type : Alias Data ​\t[Track2] Handler Vendor ID : Apple ​\t[Track2] Handler Description : Apple Alias Data Handler ​\t[Track2] Audio Format : mp4a ​\t[Track2] Audio Channels : 2 ​\t[Track2] Audio Bits Per Sample : 16 ​\t[Track2] Audio Sample Rate : 44100 ​\t[Track2] Purchase File Format : mp4a ​\t[Composite] Avg Bitrate : 10.6 Mbps ​\t[Composite] Image Size : 1280x720 ​\t[Composite] Megapixels : 0.922 ​\t[Composite] Rotation : 0 ​\t$ Launch Premiere Pro. Enable the setting in Preferences to Write XMP ID to Files in Import which is now off by default!! Import the same clip into Premiere Pro. Run ExifTool again to confirm the file has been modified. Note how the System File Date/Time values are updated and the new XMP info at the bottom! $ exiftool -api largefilesupport=1 -G1 XAVCS-sample.mov ​\t[ExifTool] ExifTool Version Number : 10.08 ​\t[System] File Name : XAVCS-sample.mov ​\t[System] Directory : /Volumes/Scratch/est ​\t[System] File Size : 3156 MB ​\t[System] File Modification Date/Time : 2016:01:09 20:30:04-05:00 ​\t[System] File Access Date/Time : 2016:01:09 20:30:22-05:00 ​\t[System] File Inode Change Date/Time : 2016:01:09 20:30:04-05:00 ​\t[System] File Permissions : rwxrwxrwx ​\t[File] File Type : MOV ​\t[File] File Type Extension : mov ​\t[File] MIME Type : video/quicktime ​\t[QuickTime] Major Brand : Apple QuickTime (.MOV/QT) ​\t[QuickTime] Minor Version : 2005.3.0 ​\t[QuickTime] Compatible Brands : qt ​\t[QuickTime] Movie Data Size : 3307975773 ​\t[QuickTime] Movie Data Offset : 48 ​\t[QuickTime] Movie Header Version : 0 ​\t[QuickTime] Time Scale : 600 ​\t[QuickTime] Duration : 0:41:43 ​\t[QuickTime] Preferred Rate : 1 ​\t[QuickTime] Preferred Volume : 100.00% ​\t[QuickTime] Preview Time : 0 s ​\t[QuickTime] Preview Duration : 0 s ​\t[QuickTime] Poster Time : 0 s ​\t[QuickTime] Selection Time : 0 s ​\t[QuickTime] Selection Duration : 0 s ​\t[QuickTime] Current Time : 0 s ​\t[QuickTime] Next Track ID : 3 ​\t[Track1] Track Header Version : 0 ​\t[Track1] Track Create Date : 2014:05:11 04:50:09 ​\t[Track1] Track Modify Date : 2014:05:11 05:31:53 ​\t[Track1] Track ID : 1 ​\t[Track1] Track Duration : 0:41:43 ​\t[Track1] Track Layer : 0 ​\t[Track1] Track Volume : 100.00% ​\t[Track1] Image Width : 1280 ​\t[Track1] Image Height : 720 ​\t[Track1] Graphics Mode : ditherCopy ​\t[Track1] Op Color : 32768 32768 32768 ​\t[Track1] Compressor ID : avc1 ​\t[Track1] Vendor ID : Apple ​\t[Track1] Source Image Width : 1280 ​\t[Track1] Source Image Height : 720 ​\t[Track1] X Resolution : 72 ​\t[Track1] Y Resolution : 72 ​\t[Track1] Compressor Name : H.264 ​\t[Track1] Bit Depth : 24 ​\t[Track2] Matrix Structure : 1 0 0 0 1 0 0 0 1 ​\t[Track2] Media Header Version : 0 ​\t[Track2] Media Create Date : 2014:05:11 04:50:09 ​\t[Track2] Media Modify Date : 2014:05:11 05:31:53 ​\t[Track2] Media Time Scale : 44100 ​\t[Track2] Media Duration : 0:41:43 ​\t[Track2] Balance : 0 ​\t[Track2] Handler Class : Data Handler ​\t[Track2] Handler Type : Alias Data ​\t[Track2] Handler Vendor ID : Apple ​\t[Track2] Handler Description : Apple Alias Data Handler ​\t[Track2] Audio Format : mp4a ​\t[Track2] Audio Channels : 2 ​\t[Track2] Audio Bits Per Sample : 16 ​\t[Track2] Purchase File Format : mp4a ​\t[XMP-x] XMP Toolkit : Adobe XMP Core 5.6-c111 79.158325, 2015/09/10-01:10:20 ​\t[XMP-xmp] Create Date : 2014:05:11 04:50:09Z ​\t[XMP-xmp] Modify Date : 2016:01:09 20:30:03-05:00 ​\t[XMP-xmp] Metadata Date : 2016:01:09 20:30:04-05:00 ​\t[XMP-xmpDM] Video Alpha Mode : None ​\t[XMP-xmpDM] Audio Sample Rate : 44100 ​\t[XMP-xmpDM] Audio Sample Type : Compressed ​\t[XMP-xmpDM] Audio Channel Type : Stereo ​\t[XMP-xmpDM] Video Frame Rate : 29.970030 ​\t[XMP-xmpDM] Duration Value : 1502300 ​\t[XMP-xmpDM] Duration Scale : 0.00166666666666667 ​\t[XMP-xmpDM] Video Frame Size W : 1280 ​\t[XMP-xmpDM] Video Frame Size H : 720 ​\t[XMP-xmpDM] Video Frame Size Unit : pixel ​\t[XMP-xmpMM] Instance ID : xmp.iid:f876396c-36cd-46bb-8e10-198ec05bf13c ​\t[XMP-xmpMM] Document ID : xmp.did:0b184efa-54f1-404a-91a9-e1a5be69375d ​\t[XMP-xmpMM] Original Document ID : xmp.did:0b184efa-54f1-404a-91a9-e1a5be69375d ​\t[XMP-xmpMM] History Action : saved, saved ​\t[XMP-xmpMM] History Instance ID : xmp.iid:4b09e22c-62ee-4df5-b4c0-c6ae3db78df7, xmp.iid:f876396c-36cd-46bb-8e10-198ec05bf13c ​\t[XMP-xmpMM] History When : 2016:01:09 20:30:03-05:00, 2016:01:09 20:30:04-05:00 ​\t[XMP-xmpMM] History Software Agent : Adobe Premiere Pro CC (Macintosh), Adobe Premiere Pro CC (Macintosh) ​\t[XMP-xmpMM] History Changed : /, /metadata ​\t[Composite] Avg Bitrate : 10.6 Mbps ​\t[Composite] Image Size : 1280x720 ​\t[Composite] Megapixels : 0.922 ​\t[Composite] Rotation : 0 ​\t$ Switch back to FCP X. No red media missing icon! Perhaps FCP X is working off the audio and video track lengths themselves, which did not change (as the ExifTool printouts showed). A Whole New World While it\u0026rsquo;d be nice to know which version of FCP X finally became immune to embedded XMP metadata changes, the fact is 10.2.2 now is. Doing so opens a fresh range of possibilities for those organizing footage and roundtripping the Adobe and Apple ecosystems.\nSome people wait a lifetime for a moment like this.\nIndescribable feelings.\nHit the road, Jack!\nHistory [Updated September 28, 2018 wording changes for clarity.]\nFootnotes 2011-08-15 Opening clips in Premiere Pro makes them go offline in FCX\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n2012-07-17 Relinking this!\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n2012-04-19 https://forums.creativecow.net/thread/344/19594\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n2013-06-21 How to Transfer a Project from Final Cut Pro to After Effects\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n2014-06-25 FCP X: Relinking Media [u] (see comment by SadMac)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nUnderstanding \u0026ldquo;Write XMP ID to Files on Import\u0026rdquo; https://forums.adobe.com/thread/682174\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://en.wikipedia.org/wiki/OS_X_El_Capitan#Releases\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://en.wikipedia.org/wiki/Final_Cut_Pro_X#Evolution\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://en.wikipedia.org/wiki/Adobe_Premiere_Pro#Release_history\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2016-01-09T00:00:00Z","permalink":"http://localhost:1313/post/video/2016/fcpx-unaffected-by-xmp/","title":"FCP X 10.2.2 Unaffected by XMP Metadata Changes"},{"content":"Introduction For a long time, Sony\u0026rsquo;s XAVC-S codec was completely a mystery to me. It was the new format the Sony CX900 and AX100 use, and when those cameras originally shipped, the files could not be edited natively with FCP X. (Version 10.2 added that functionality.)\nWhat was particularly perplexing was after the software update, QuickTime Player X and FCP X would open the files, but QuickTime Player 7 and Compressor 4.2 wouldn\u0026rsquo;t. QT7 was understandably written on legacy 32-bit frameworks1, but shouldn\u0026rsquo;t Compressor 4.2 use the same new 64-bit frameworks (AVFoundation, CoreMediaIO, etc.) that QT X and FCP X used?\n\u0026ldquo;Invalid sample description\u0026rdquo; \u0026hellip; \u0026ldquo;can\u0026rsquo;t find video or audio tracks\u0026rdquo; \u0026hellip; very interesting. Almost suggests the programs can\u0026rsquo;t read some header metadata. Thanks to the folks folks at Divergent Media, now I know XAVC-S is just H.264 video inside the container.2 Should be no reason QT7 can\u0026rsquo;t open it.\nIndeed that\u0026rsquo;s the case!\nSolution The fix? Rename the extension from mp4 to m4v.\nNow QT7, Compressor 4, and MPEG Streamclip all open the file once again. Hooray!\nThis means Final Cut Pro 7 will open such renamed files too, like QT7.\nBut Why? Um, ya.\nMy guess is, in the old days any file that ended in MP4 was thought to conform the MP4 standard. Makes sense, right? That implies the audio stream for MP4 files should be AAC, MP3 or a few other audio codecs.3 In that bucket list is not PCM audio! This strict convention is what I surmise QT7 and Compressor 4.2 adhere to and therefore could not open the XAVC-S file from the video camera.\nThe renaming hint came from a StackExchange4 and FFMPEG page5 after searching for the QT7 error message An invalid sample description was found in the movie.\nIn the OP\u0026rsquo;s case, a masquerading MP4 file contained both AAC and AC3 audio tracks—the latter which is not allowed per the MP4 spec. It\u0026rsquo;s interesting to note Handbrake (version 0.10.2 x86_64 (2015061100)) now automatically renames the destination file extension from mp4 to m4v upon adding an AC3 audio track! It seems programs like VLC, which have always played the file, and now QT X and FCP X, probably do not give much importance to the actual file extension but instead to the stream data inside and are thus more lenient.\nM4V is like Apple\u0026rsquo;s New MOV Like the standard quicktime mov container, m4v seems to have more for flexibility for packaging MP4 streams—in this case, for PCM audio. After all, like mov, the m4v container is developed by Apple.6\nFor a long time, I placed the emphasis on the v of m4v—that it\u0026rsquo;s MP4 video. But in a way, perhaps the emphasis is really on the 4: it\u0026rsquo;s like mov but just with the middle letter changed for mp4 files.\nAppendix XAVC-S sample file For posterity! Original 50 MB video file from the Sony AX-100 camera available here for download and experimentation.\nAudio credit: Raga Pahadi - Alaap by Ashwin Batish from album Morning Meditation Ragas on Sitar.\nXAVC-S Stream Info Stream information from the original 4K MP4 file from the Sony AX-100 using ffprobe -show_streams. Note how the H.264 profile is High but the audio is PCM 48 kHz 16-bit.\nKrish-MBP-2012-en1:Desktop Krish$ ffprobe -show_streams XAVCS-4K-29.97fps.MP4 ffprobe version 2.8 Copyright (c) 2007-2015 the FFmpeg developers built with Apple LLVM version 6.1.0 (clang-602.0.53) (based on LLVM 3.6.0svn) configuration: --prefix=/usr/local/Cellar/ffmpeg/2.8 --enable-shared --enable-pthreads --enable-gpl --enable-version3 --enable-hardcoded-tables --enable-avresample --cc=clang --host-cflags= --host-ldflags= --enable-opencl --enable-libx264 --enable-libmp3lame --enable-libvo-aacenc --enable-libxvid --enable-vda libavutil 54. 31.100 / 54. 31.100 libavcodec 56. 60.100 / 56. 60.100 libavformat 56. 40.101 / 56. 40.101 libavdevice 56. 4.100 / 56. 4.100 libavfilter 5. 40.101 / 5. 40.101 libavresample 2. 1. 0 / 2. 1. 0 libswscale 3. 1.101 / 3. 1.101 libswresample 1. 2.101 / 1. 2.101 libpostproc 53. 3.100 / 53. 3.100 Input #0, mov,mp4,m4a,3gp,3g2,mj2, from \u0026#39;XAVCS-4K-29.97fps.MP4\u0026#39;: Metadata: major_brand : XAVC minor_version : 16785407 compatible_brands: XAVCmp42iso2 creation_time : 2016-01-09 00:44:11 Duration: 00:00:07.01, start: 0.000000, bitrate: 55039 kb/s Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709/bt709/iec61966-2-4), 3840x2160 [SAR 1:1 DAR 16:9], 53251 kb/s, 29.97 fps, 29.97 tbr, 30k tbn, 59.94 tbc (default) Metadata: creation_time : 2016-01-09 00:44:11 handler_name : Video Media Handler encoder : AVC Coding Stream #0:1(und): Audio: pcm_s16be (twos / 0x736F7774), 48000 Hz, 2 channels, s16, 1536 kb/s (default) Metadata: creation_time : 2016-01-09 00:44:11 handler_name : Sound Media Handler Stream #0:2(und): Data: none (rtmd / 0x646D7472), 245 kb/s (default) Metadata: creation_time : 2016-01-09 00:44:11 handler_name : Non-Real Time Metadata Unsupported codec with id 0 for input stream 2 [STREAM] index=0 codec_name=h264 codec_long_name=H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 profile=High codec_type=video codec_time_base=1001/60000 codec_tag_string=avc1 codec_tag=0x31637661 width=3840 height=2160 coded_width=3840 coded_height=2160 has_b_frames=1 sample_aspect_ratio=1:1 display_aspect_ratio=16:9 pix_fmt=yuv420p level=51 color_range=tv color_space=bt709 color_transfer=iec61966-2-4 color_primaries=bt709 chroma_location=left timecode=N/A refs=2 is_avc=1 nal_length_size=4 id=N/A r_frame_rate=30000/1001 avg_frame_rate=30000/1001 time_base=1/30000 start_pts=2002 start_time=0.066733 duration_ts=210210 duration=7.007000 bit_rate=53251849 max_bit_rate=N/A bits_per_raw_sample=8 nb_frames=210 nb_read_frames=N/A nb_read_packets=N/A DISPOSITION:default=1 DISPOSITION:dub=0 DISPOSITION:original=0 DISPOSITION:comment=0 DISPOSITION:lyrics=0 DISPOSITION:karaoke=0 DISPOSITION:forced=0 DISPOSITION:hearing_impaired=0 DISPOSITION:visual_impaired=0 DISPOSITION:clean_effects=0 DISPOSITION:attached_pic=0 TAG:creation_time=2016-01-09 00:44:11 TAG:language=und TAG:handler_name=Video Media Handler TAG:encoder=AVC Coding [/STREAM] [STREAM] index=1 codec_name=pcm_s16be codec_long_name=PCM signed 16-bit big-endian profile=unknown codec_type=audio codec_time_base=1/48000 codec_tag_string=twos codec_tag=0x736f7774 sample_fmt=s16 sample_rate=48000 channels=2 channel_layout=unknown bits_per_sample=16 id=N/A r_frame_rate=0/0 avg_frame_rate=0/0 time_base=1/48000 start_pts=0 start_time=0.000000 duration_ts=336336 duration=7.007000 bit_rate=1536000 max_bit_rate=N/A bits_per_raw_sample=N/A nb_frames=336336 nb_read_frames=N/A nb_read_packets=N/A DISPOSITION:default=1 DISPOSITION:dub=0 DISPOSITION:original=0 DISPOSITION:comment=0 DISPOSITION:lyrics=0 DISPOSITION:karaoke=0 DISPOSITION:forced=0 DISPOSITION:hearing_impaired=0 DISPOSITION:visual_impaired=0 DISPOSITION:clean_effects=0 DISPOSITION:attached_pic=0 TAG:creation_time=2016-01-09 00:44:11 TAG:language=und TAG:handler_name=Sound Media Handler [/STREAM] [STREAM] index=2 codec_name=unknown codec_long_name=unknown profile=unknown codec_type=data codec_time_base=0/1 codec_tag_string=rtmd codec_tag=0x646d7472 id=N/A r_frame_rate=0/0 avg_frame_rate=0/0 time_base=1/30000 start_pts=0 start_time=0.000000 duration_ts=210210 duration=7.007000 bit_rate=245514 max_bit_rate=N/A bits_per_raw_sample=N/A nb_frames=210 nb_read_frames=N/A nb_read_packets=N/A DISPOSITION:default=1 DISPOSITION:dub=0 DISPOSITION:original=0 DISPOSITION:comment=0 DISPOSITION:lyrics=0 DISPOSITION:karaoke=0 DISPOSITION:forced=0 DISPOSITION:hearing_impaired=0 DISPOSITION:visual_impaired=0 DISPOSITION:clean_effects=0 DISPOSITION:attached_pic=0 TAG:creation_time=2016-01-09 00:44:11 TAG:language=und TAG:handler_name=Non-Real Time Metadata [/STREAM] History [Updated September 28, 2018 wording changes for clarity.]\nFootnotes Shout out to Divergent Media for creating such awesome software—and informative articles!\nDealing with Codecs on Modern Macs\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nUnderstand XAVC\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMPEG-4 Part 14\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHow do I fix Handbrake mp4s that produce Error -2041 when loaded in QuickTime?\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nQuicktime error: invalid sample description\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nM4V\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2016-01-09T00:00:00Z","permalink":"http://localhost:1313/post/video/2016/masquerading-mp4-files/","title":"Renaming MP4 to M4V to open with QT7 \u0026 Compressor"},{"content":"Introduction Many new Sony video cameras (like the FDR-AX100 and HDR-CX900) record into the XAVC-S format. XAVC-S writes to MP4 containers, and alongside them sit nice little XML files with metadata. The following is what I\u0026rsquo;ve unearthed from poking around the SD card.\nThis post mainly serves as a log of observations.\nTest Setup The AX100 has three FPS settings when recording to the XAVC-S HD file format (60p, 30p and 24p) and two when recording to XAVS-S 4K (30p and 24p).\nFor this test there were five shots:\nXAVC-S HD, 60 fps XAVC-S HD, 30 fps XAVC-S HD, 24 fps XAVC-S 4K, 30 fps XAVC-S 4K, 24 fps MEDIAPRO.XML This file is located inside the PRIVATE/M4ROOT/ folder and contains a summary of all files on the card and their bitrates. The resolution is inside the videoType attribute i.e. 1920_1080 for HD and 3840_2160 for 4K. Note how @L41 and @L42 seem to indicate 50 Mbps and @L51 indicates 60 Mbps.\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;MediaProfile xmlns=\u0026#34;http://xmlns.sony.net/pro/metadata/mediaprofile\u0026#34; createdAt=\u0026#34;2016-01-03T06:10:17-04:00\u0026#34; version=\u0026#34;2.10\u0026#34;\u0026gt; \u0026lt;Properties\u0026gt; \u0026lt;System systemId=\u0026#34;784B87FFFEBA9815\u0026#34; systemKind=\u0026#34;FDR-AX100\u0026#34; masterVersion=\u0026#34;XAVC-M4@1.10.00\u0026#34;/\u0026gt; \u0026lt;Attached mediaId=\u0026#34;1EEAD341907305C09815784B87FFFEBA\u0026#34; mediaKind=\u0026#34;AffordableMemoryCard\u0026#34; mediaName=\u0026#34;\u0026#34;/\u0026gt; \u0026lt;/Properties\u0026gt; \u0026lt;Contents\u0026gt; \u0026lt;Material uri=\u0026#34;./CLIP/C0001.MP4\u0026#34; type=\u0026#34;MP4\u0026#34; videoType=\u0026#34;AVC_1920_1080_HP@L42\u0026#34; audioType=\u0026#34;LPCM16\u0026#34; fps=\u0026#34;59.94p\u0026#34; dur=\u0026#34;210\u0026#34; ch=\u0026#34;2\u0026#34; aspectRatio=\u0026#34;16:9\u0026#34; offset=\u0026#34;0\u0026#34; umid=\u0026#34;060A2B340101010501010D43130000004E41F241907305CE784B87FFFEBA9815\u0026#34; status=\u0026#34;OK\u0026#34;\u0026gt; \u0026lt;RelevantInfo uri=\u0026#34;./CLIP/C0001M01.XML\u0026#34; type=\u0026#34;XML\u0026#34;/\u0026gt; \u0026lt;RelevantInfo uri=\u0026#34;./THMBNL/C0001T01.JPG\u0026#34; type=\u0026#34;JPG\u0026#34;/\u0026gt; \u0026lt;/Material\u0026gt; \u0026lt;Material uri=\u0026#34;./CLIP/C0002.MP4\u0026#34; type=\u0026#34;MP4\u0026#34; videoType=\u0026#34;AVC_1920_1080_HP@L41\u0026#34; audioType=\u0026#34;LPCM16\u0026#34; fps=\u0026#34;29.97p\u0026#34; dur=\u0026#34;165\u0026#34; ch=\u0026#34;2\u0026#34; aspectRatio=\u0026#34;16:9\u0026#34; offset=\u0026#34;0\u0026#34; umid=\u0026#34;060A2B340101010501010D431300000008DF1242907305DF784B87FFFEBA9815\u0026#34; status=\u0026#34;OK\u0026#34;\u0026gt; \u0026lt;RelevantInfo uri=\u0026#34;./CLIP/C0002M01.XML\u0026#34; type=\u0026#34;XML\u0026#34;/\u0026gt; \u0026lt;RelevantInfo uri=\u0026#34;./THMBNL/C0002T01.JPG\u0026#34; type=\u0026#34;JPG\u0026#34;/\u0026gt; \u0026lt;/Material\u0026gt; \u0026lt;Material uri=\u0026#34;./CLIP/C0003.MP4\u0026#34; type=\u0026#34;MP4\u0026#34; videoType=\u0026#34;AVC_1920_1080_HP@L41\u0026#34; audioType=\u0026#34;LPCM16\u0026#34; fps=\u0026#34;23.98p\u0026#34; dur=\u0026#34;120\u0026#34; ch=\u0026#34;2\u0026#34; aspectRatio=\u0026#34;16:9\u0026#34; offset=\u0026#34;0\u0026#34; umid=\u0026#34;060A2B340101010501010D4313000000A00A2242907305C0784B87FFFEBA9815\u0026#34; status=\u0026#34;OK\u0026#34;\u0026gt; \u0026lt;RelevantInfo uri=\u0026#34;./CLIP/C0003M01.XML\u0026#34; type=\u0026#34;XML\u0026#34;/\u0026gt; \u0026lt;RelevantInfo uri=\u0026#34;./THMBNL/C0003T01.JPG\u0026#34; type=\u0026#34;JPG\u0026#34;/\u0026gt; \u0026lt;/Material\u0026gt; \u0026lt;Material uri=\u0026#34;./CLIP/C0004.MP4\u0026#34; type=\u0026#34;MP4\u0026#34; videoType=\u0026#34;AVC_3840_2160_HP@L51\u0026#34; audioType=\u0026#34;LPCM16\u0026#34; fps=\u0026#34;29.97p\u0026#34; dur=\u0026#34;105\u0026#34; ch=\u0026#34;2\u0026#34; aspectRatio=\u0026#34;16:9\u0026#34; offset=\u0026#34;0\u0026#34; umid=\u0026#34;060A2B340101010501010D4313000000AEA46349907305C9784B87FFFEBA9815\u0026#34; status=\u0026#34;OK\u0026#34;\u0026gt; \u0026lt;RelevantInfo uri=\u0026#34;./CLIP/C0004M01.XML\u0026#34; type=\u0026#34;XML\u0026#34;/\u0026gt; \u0026lt;RelevantInfo uri=\u0026#34;./THMBNL/C0004T01.JPG\u0026#34; type=\u0026#34;JPG\u0026#34;/\u0026gt; \u0026lt;/Material\u0026gt; \u0026lt;Material uri=\u0026#34;./CLIP/C0005.MP4\u0026#34; type=\u0026#34;MP4\u0026#34; videoType=\u0026#34;AVC_3840_2160_HP@L51\u0026#34; audioType=\u0026#34;LPCM16\u0026#34; fps=\u0026#34;23.98p\u0026#34; dur=\u0026#34;84\u0026#34; ch=\u0026#34;2\u0026#34; aspectRatio=\u0026#34;16:9\u0026#34; offset=\u0026#34;0\u0026#34; umid=\u0026#34;060A2B340101010501010D4313000000B0398149907305CE784B87FFFEBA9815\u0026#34; status=\u0026#34;OK\u0026#34;\u0026gt; \u0026lt;RelevantInfo uri=\u0026#34;./CLIP/C0005M01.XML\u0026#34; type=\u0026#34;XML\u0026#34;/\u0026gt; \u0026lt;RelevantInfo uri=\u0026#34;./THMBNL/C0005T01.JPG\u0026#34; type=\u0026#34;JPG\u0026#34;/\u0026gt; \u0026lt;/Material\u0026gt; \u0026lt;/Contents\u0026gt; \u0026lt;/MediaProfile\u0026gt; Sidecar XML These files are located inside PRIVATE/M4ROOT/CLIP and sit alongside the actual XAVC-S MP4 files themselves. Interestingly, only FPS information is present in these sidecar XMLs. Bitrate information is only present in the M4ROOT/MEDIAPRO.XML file!\nXAVC-S HD, 60 fps tcFps=\u0026quot;30\u0026quot; halfStep=\u0026quot;true\u0026quot; indicates 60 fps (i.e. 30 halved)\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;NonRealTimeMeta xmlns=\u0026#34;urn:schemas-professionalDisc:nonRealTimeMeta:ver.2.00\u0026#34; xmlns:lib=\u0026#34;urn:schemas-professionalDisc:lib:ver.2.00\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; lastUpdate=\u0026#34;2016-01-03T06:10:57-04:00\u0026#34;\u0026gt; \u0026lt;TargetMaterial umidRef=\u0026#34;060A2B340101010501010D43130000004E41F241907305CE784B87FFFEBA9815\u0026#34; status=\u0026#34;OK\u0026#34;/\u0026gt; \u0026lt;Duration value=\u0026#34;210\u0026#34;/\u0026gt; \u0026lt;LtcChangeTable tcFps=\u0026#34;30\u0026#34; halfStep=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;LtcChange frameCount=\u0026#34;0\u0026#34; value=\u0026#34;40000000\u0026#34; status=\u0026#34;increment\u0026#34;/\u0026gt; \u0026lt;LtcChange frameCount=\u0026#34;209\u0026#34; value=\u0026#34;54830000\u0026#34; status=\u0026#34;end\u0026#34;/\u0026gt; \u0026lt;/LtcChangeTable\u0026gt; \u0026lt;CreationDate value=\u0026#34;2016-01-03T06:10:57-04:00\u0026#34;/\u0026gt; \u0026lt;Device manufacturer=\u0026#34;Sony\u0026#34; modelName=\u0026#34;FDR-AX100\u0026#34; serialNo=\u0026#34;1234567890\u0026#34;/\u0026gt; \u0026lt;RecordingMode type=\u0026#34;normal\u0026#34; cacheRec=\u0026#34;false\u0026#34;/\u0026gt; \u0026lt;/NonRealTimeMeta\u0026gt; XAVC-S HD, 30 fps tcFps=\u0026quot;30\u0026quot; halfStep=\u0026quot;false\u0026quot; indicates 30 fps (i.e. 30 divided by 1)\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;NonRealTimeMeta xmlns=\u0026#34;urn:schemas-professionalDisc:nonRealTimeMeta:ver.2.00\u0026#34; xmlns:lib=\u0026#34;urn:schemas-professionalDisc:lib:ver.2.00\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; lastUpdate=\u0026#34;2016-01-03T06:11:40-04:00\u0026#34;\u0026gt; \u0026lt;TargetMaterial umidRef=\u0026#34;060A2B340101010501010D431300000008DF1242907305DF784B87FFFEBA9815\u0026#34; status=\u0026#34;OK\u0026#34;/\u0026gt; \u0026lt;Duration value=\u0026#34;165\u0026#34;/\u0026gt; \u0026lt;LtcChangeTable tcFps=\u0026#34;30\u0026#34; halfStep=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;LtcChange frameCount=\u0026#34;0\u0026#34; value=\u0026#34;40000000\u0026#34; status=\u0026#34;increment\u0026#34;/\u0026gt; \u0026lt;LtcChange frameCount=\u0026#34;164\u0026#34; value=\u0026#34;54050000\u0026#34; status=\u0026#34;end\u0026#34;/\u0026gt; \u0026lt;/LtcChangeTable\u0026gt; \u0026lt;CreationDate value=\u0026#34;2016-01-03T06:11:40-04:00\u0026#34;/\u0026gt; \u0026lt;Device manufacturer=\u0026#34;Sony\u0026#34; modelName=\u0026#34;FDR-AX100\u0026#34; serialNo=\u0026#34;1234567890\u0026#34;/\u0026gt; \u0026lt;RecordingMode type=\u0026#34;normal\u0026#34; cacheRec=\u0026#34;false\u0026#34;/\u0026gt; \u0026lt;/NonRealTimeMeta\u0026gt; XAVC-S HD, 24 fps tcFps=\u0026quot;24\u0026quot; halfStep=\u0026quot;false\u0026quot; indicates 24 fps\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;NonRealTimeMeta xmlns=\u0026#34;urn:schemas-professionalDisc:nonRealTimeMeta:ver.2.00\u0026#34; xmlns:lib=\u0026#34;urn:schemas-professionalDisc:lib:ver.2.00\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; lastUpdate=\u0026#34;2016-01-03T06:12:00-04:00\u0026#34;\u0026gt; \u0026lt;TargetMaterial umidRef=\u0026#34;060A2B340101010501010D4313000000A00A2242907305C0784B87FFFEBA9815\u0026#34; status=\u0026#34;OK\u0026#34;/\u0026gt; \u0026lt;Duration value=\u0026#34;120\u0026#34;/\u0026gt; \u0026lt;LtcChangeTable tcFps=\u0026#34;24\u0026#34; halfStep=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;LtcChange frameCount=\u0026#34;0\u0026#34; value=\u0026#34;00000000\u0026#34; status=\u0026#34;increment\u0026#34;/\u0026gt; \u0026lt;LtcChange frameCount=\u0026#34;119\u0026#34; value=\u0026#34;23040000\u0026#34; status=\u0026#34;end\u0026#34;/\u0026gt; \u0026lt;/LtcChangeTable\u0026gt; \u0026lt;CreationDate value=\u0026#34;2016-01-03T06:12:00-04:00\u0026#34;/\u0026gt; \u0026lt;Device manufacturer=\u0026#34;Sony\u0026#34; modelName=\u0026#34;FDR-AX100\u0026#34; serialNo=\u0026#34;1234567890\u0026#34;/\u0026gt; \u0026lt;RecordingMode type=\u0026#34;normal\u0026#34; cacheRec=\u0026#34;false\u0026#34;/\u0026gt; \u0026lt;/NonRealTimeMeta\u0026gt; XAVC-S 4K, 30 fps tcFps=\u0026quot;30\u0026quot; halfStep=\u0026quot;false\u0026quot; indicates 30 fps, same as before\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;NonRealTimeMeta xmlns=\u0026#34;urn:schemas-professionalDisc:nonRealTimeMeta:ver.2.00\u0026#34; xmlns:lib=\u0026#34;urn:schemas-professionalDisc:lib:ver.2.00\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; lastUpdate=\u0026#34;2016-01-03T06:52:49-04:00\u0026#34;\u0026gt; \u0026lt;TargetMaterial umidRef=\u0026#34;060A2B340101010501010D4313000000AEA46349907305C9784B87FFFEBA9815\u0026#34; status=\u0026#34;OK\u0026#34;/\u0026gt; \u0026lt;Duration value=\u0026#34;105\u0026#34;/\u0026gt; \u0026lt;LtcChangeTable tcFps=\u0026#34;30\u0026#34; halfStep=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;LtcChange frameCount=\u0026#34;0\u0026#34; value=\u0026#34;40000000\u0026#34; status=\u0026#34;increment\u0026#34;/\u0026gt; \u0026lt;LtcChange frameCount=\u0026#34;104\u0026#34; value=\u0026#34;54030000\u0026#34; status=\u0026#34;end\u0026#34;/\u0026gt; \u0026lt;/LtcChangeTable\u0026gt; \u0026lt;CreationDate value=\u0026#34;2016-01-03T06:52:49-04:00\u0026#34;/\u0026gt; \u0026lt;Device manufacturer=\u0026#34;Sony\u0026#34; modelName=\u0026#34;FDR-AX100\u0026#34; serialNo=\u0026#34;1234567890\u0026#34;/\u0026gt; \u0026lt;RecordingMode type=\u0026#34;normal\u0026#34; cacheRec=\u0026#34;false\u0026#34;/\u0026gt; \u0026lt;/NonRealTimeMeta\u0026gt; XAVC-S 4K, 24 fps tcFps=\u0026quot;24\u0026quot; halfStep=\u0026quot;false\u0026quot; indicates 24 fps, same as before\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;NonRealTimeMeta xmlns=\u0026#34;urn:schemas-professionalDisc:nonRealTimeMeta:ver.2.00\u0026#34; xmlns:lib=\u0026#34;urn:schemas-professionalDisc:lib:ver.2.00\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; lastUpdate=\u0026#34;2016-01-03T06:53:28-04:00\u0026#34;\u0026gt; \u0026lt;TargetMaterial umidRef=\u0026#34;060A2B340101010501010D4313000000B0398149907305CE784B87FFFEBA9815\u0026#34; status=\u0026#34;OK\u0026#34;/\u0026gt; \u0026lt;Duration value=\u0026#34;84\u0026#34;/\u0026gt; \u0026lt;LtcChangeTable tcFps=\u0026#34;24\u0026#34; halfStep=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;LtcChange frameCount=\u0026#34;0\u0026#34; value=\u0026#34;00000000\u0026#34; status=\u0026#34;increment\u0026#34;/\u0026gt; \u0026lt;LtcChange frameCount=\u0026#34;83\u0026#34; value=\u0026#34;11030000\u0026#34; status=\u0026#34;end\u0026#34;/\u0026gt; \u0026lt;/LtcChangeTable\u0026gt; \u0026lt;CreationDate value=\u0026#34;2016-01-03T06:53:28-04:00\u0026#34;/\u0026gt; \u0026lt;Device manufacturer=\u0026#34;Sony\u0026#34; modelName=\u0026#34;FDR-AX100\u0026#34; serialNo=\u0026#34;1234567890\u0026#34;/\u0026gt; \u0026lt;RecordingMode type=\u0026#34;normal\u0026#34; cacheRec=\u0026#34;false\u0026#34;/\u0026gt; \u0026lt;/NonRealTimeMeta\u0026gt; History [Updated May 14, 2018 with wording changes.]\n","date":"2016-01-03T00:00:00Z","permalink":"http://localhost:1313/post/video/2016/reverse-engineering-xavcs-xml/","title":"Reverse Engineering XAVC-S XML Files"}]